{
  "version": 4,
  "terraform_version": "1.5.4",
  "serial": 104,
  "lineage": "d4a8081e-a84f-c899-29ef-2d0d41aeb842",
  "outputs": {},
  "resources": [
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "airflow_operator",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "airflow",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "airflow-prd",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "2.8.4",
                "chart": "airflow",
                "name": "airflow-prd",
                "namespace": "datalake",
                "revision": 3,
                "values": "{\"airflow\":{\"clusterDomain\":\"cluster.local\",\"config\":{\"AIRFLOW__CORE__LOAD_EXAMPLES\":\"False\",\"AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL\":\"30\",\"AIRFLOW__WEBSERVER__BASE_URL\":\"http://192.168.36.90\"},\"connections\":[],\"connectionsTemplates\":{},\"connectionsUpdate\":true,\"dbMigrations\":{\"affinity\":{},\"annotations\":{},\"checkInterval\":300,\"enabled\":true,\"labels\":{},\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"resources\":{},\"runAsJob\":false,\"safeToEvict\":true,\"securityContext\":{},\"tolerations\":[]},\"defaultAffinity\":{},\"defaultNodeSelector\":{},\"defaultSecurityContext\":{\"fsGroup\":0},\"defaultTolerations\":[],\"executor\":\"CeleryExecutor\",\"extraContainers\":[],\"extraEnv\":[],\"extraPipPackages\":[\"apache-airflow-providers-apache-kafka\",\"apache-airflow-providers-mysql\",\"apache-airflow-providers-common-sql\",\"airflow-providers-clickhouse\",\"apache-airflow\",\"clickhouse-driver\",\"airflow-clickhouse-plugin\",\"airflow-provider-kafka\",\"influxdb-client\",\"pymongo\",\"pysnmp\",\"sqlalchemy\",\"boto3\",\"pysftp\",\"apache-airflow-providers-mongo\",\"snakebite\",\"pyarrow\",\"hdfs\",\"psycopg2-binary\",\"minio\",\"eloquent\",\"redis\",\"pandas\",\"mysql-connector-python\",\"requests\",\"datetime\"],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"fernetKey\":\"7T512UXSSmBOkpWimFHIVb8jK6lfmSAvx4mO6Arehnc=\",\"image\":{\"gid\":0,\"pullPolicy\":\"IfNotPresent\",\"pullSecret\":\"\",\"repository\":\"jackt72xp/airflowsnmp\",\"tag\":\"v01\",\"uid\":50000},\"kubernetesPodTemplate\":{\"affinity\":{},\"extraContainers\":[],\"extraInitContainers\":[{\"command\":[\"/bin/sh\",\"-c\",\"apt-get update \\u0026\\u0026 apt-get install -y snmp \\u0026\\u0026 apt-get clean #magic___^_^___line\\n\"],\"image\":\"debian:buster\",\"name\":\"install-snmp\"}],\"extraPipPackages\":[\"apache-airflow-providers-apache-kafka\",\"apache-airflow-providers-mysql\",\"apache-airflow-providers-common-sql\",\"airflow-providers-clickhouse\",\"apache-airflow\",\"clickhouse-driver\",\"airflow-clickhouse-plugin\",\"airflow-provider-kafka\",\"influxdb-client\",\"pymongo\",\"pysnmp\",\"sqlalchemy\",\"boto3\",\"pysftp\",\"apache-airflow-providers-mongo\",\"snakebite\",\"pyarrow\",\"hdfs\",\"psycopg2-binary\",\"minio\",\"eloquent\",\"redis\",\"pandas\",\"mysql-connector-python\",\"requests\",\"datetime\"],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"resources\":{},\"securityContext\":{},\"shareProcessNamespace\":false,\"stringOverride\":\"\",\"tolerations\":[]},\"legacyCommands\":false,\"localSettings\":{\"existingSecret\":\"\",\"stringOverride\":\"\"},\"podAnnotations\":{},\"pools\":[],\"poolsUpdate\":true,\"protectedPipPackages\":[\"apache-airflow\"],\"sync\":{\"affinity\":{},\"annotations\":{},\"labels\":{},\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"resources\":{},\"safeToEvict\":true,\"securityContext\":{},\"tolerations\":[]},\"users\":[{\"email\":\"admin@example.com\",\"firstName\":\"admin\",\"lastName\":\"admin\",\"password\":\"admin\",\"role\":\"Admin\",\"username\":\"admin\"}],\"usersTemplates\":{},\"usersUpdate\":true,\"variables\":[],\"variablesTemplates\":{},\"variablesUpdate\":true,\"webserverSecretKey\":\"MySecretKey123!\"},\"dags\":{\"gitSync\":{\"branch\":\"main\",\"depth\":1,\"enabled\":true,\"httpSecret\":\"airflow-git-https-secret\",\"httpSecretPasswordKey\":\"httpSecretPasswordKey\",\"httpSecretUsernameKey\":\"httpSecretUsernameKey\",\"image\":{\"gid\":65533,\"pullPolicy\":\"IfNotPresent\",\"repository\":\"registry.k8s.io/git-sync/git-sync\",\"tag\":\"v3.6.5\",\"uid\":65533},\"maxFailures\":0,\"repo\":\"https://github.com/Bifrost3-0/airflow-dags.git\",\"repoSubPath\":\"DAGS/Production\",\"resources\":{},\"revision\":\"HEAD\",\"submodules\":\"recursive\",\"syncTimeout\":120,\"syncWait\":60},\"path\":\"/opt/airflow/dags\",\"persistence\":{\"accessMode\":\"ReadOnlyMany\",\"enabled\":false,\"existingClaim\":\"\",\"size\":\"1Gi\",\"storageClass\":\"\",\"subPath\":\"\"}},\"externalDatabase\":{\"database\":\"airflow\",\"host\":\"localhost\",\"password\":\"\",\"passwordSecret\":\"\",\"passwordSecretKey\":\"postgresql-password\",\"port\":5432,\"properties\":\"\",\"type\":\"postgres\",\"user\":\"airflow\",\"userSecret\":\"\",\"userSecretKey\":\"postgresql-user\"},\"externalRedis\":{\"databaseNumber\":1,\"host\":\"localhost\",\"password\":\"\",\"passwordSecret\":\"\",\"passwordSecretKey\":\"redis-password\",\"port\":6379,\"properties\":\"\"},\"extraManifests\":[],\"flower\":{\"affinity\":{},\"annotations\":{},\"basicAuthSecret\":\"\",\"basicAuthSecretKey\":\"\",\"enabled\":true,\"extraPipPackages\":[\"apache-airflow-providers-apache-kafka\",\"apache-airflow-providers-mysql\",\"apache-airflow-providers-common-sql\",\"airflow-providers-clickhouse\",\"apache-airflow\",\"clickhouse-driver\",\"airflow-clickhouse-plugin\",\"airflow-provider-kafka\",\"influxdb-client\",\"pymongo\",\"pysnmp\",\"sqlalchemy\",\"boto3\",\"pysftp\",\"apache-airflow-providers-mongo\",\"snakebite\",\"pyarrow\",\"hdfs\",\"psycopg2-binary\",\"minio\",\"eloquent\",\"redis\",\"pandas\",\"mysql-connector-python\",\"requests\",\"datetime\"],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"timeoutSeconds\":5},\"nodeSelector\":{},\"podAnnotations\":{},\"podDisruptionBudget\":{\"apiVersion\":\"policy/v1\",\"enabled\":false,\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podLabels\":{},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"timeoutSeconds\":5},\"replicas\":8,\"resources\":{},\"safeToEvict\":true,\"securityContext\":{},\"service\":{\"annotations\":{},\"externalPort\":5555,\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":{\"http\":null},\"type\":\"ClusterIP\"},\"tolerations\":[]},\"ingress\":{\"apiVersion\":\"networking.k8s.io/v1\",\"enabled\":false,\"flower\":{\"annotations\":{},\"host\":\"\",\"ingressClassName\":\"\",\"labels\":{},\"path\":\"\",\"precedingPaths\":[],\"succeedingPaths\":[],\"tls\":{\"enabled\":false,\"secretName\":\"\"}},\"web\":{\"annotations\":{},\"host\":\"192.168.36.90\",\"ingressClassName\":\"\",\"labels\":{},\"path\":\"\",\"precedingPaths\":[],\"succeedingPaths\":[],\"tls\":{\"enabled\":false,\"secretName\":\"\"}}},\"logs\":{\"path\":\"/opt/airflow/logs\",\"persistence\":{\"accessMode\":\"ReadWriteMany\",\"enabled\":false,\"existingClaim\":\"\",\"size\":\"5Gi\",\"storageClass\":\"\",\"subPath\":\"\"}},\"pgbouncer\":{\"affinity\":{},\"annotations\":{},\"authType\":\"md5\",\"clientSSL\":{\"caFile\":{\"existingSecret\":\"\",\"existingSecretKey\":\"root.crt\"},\"certFile\":{\"existingSecret\":\"\",\"existingSecretKey\":\"client.crt\"},\"ciphers\":\"normal\",\"keyFile\":{\"existingSecret\":\"\",\"existingSecretKey\":\"client.key\"},\"mode\":\"prefer\"},\"enabled\":true,\"image\":{\"gid\":1001,\"pullPolicy\":\"IfNotPresent\",\"repository\":\"ghcr.io/airflow-helm/pgbouncer\",\"tag\":\"1.18.0-patch.1\",\"uid\":1001},\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":5,\"periodSeconds\":30,\"timeoutSeconds\":60},\"logConnections\":0,\"logDisconnections\":0,\"maxClientConnections\":1000,\"nodeSelector\":{},\"podAnnotations\":{},\"podDisruptionBudget\":{\"apiVersion\":\"policy/v1\",\"enabled\":false,\"maxUnavailable\":null,\"minAvailable\":null},\"podLabels\":{},\"poolSize\":20,\"resources\":{},\"safeToEvict\":true,\"securityContext\":{},\"serverSSL\":{\"caFile\":{\"existingSecret\":\"\",\"existingSecretKey\":\"root.crt\"},\"certFile\":{\"existingSecret\":\"\",\"existingSecretKey\":\"server.crt\"},\"ciphers\":\"normal\",\"keyFile\":{\"existingSecret\":\"\",\"existingSecretKey\":\"server.key\"},\"mode\":\"prefer\"},\"startupProbe\":{\"enabled\":true,\"failureThreshold\":30,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"timeoutSeconds\":15},\"terminationGracePeriodSeconds\":120,\"tolerations\":[]},\"postgresql\":{\"enabled\":true,\"existingSecret\":\"\",\"existingSecretKey\":\"postgresql-password\",\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"ghcr.io\",\"repository\":\"airflow-helm/postgresql-bitnami\",\"tag\":\"11.16-patch.0\"},\"master\":{\"affinity\":{},\"nodeSelector\":{},\"podAnnotations\":{\"cluster-autoscaler.kubernetes.io/safe-to-evict\":\"true\"},\"tolerations\":[]},\"metrics\":{\"enabled\":true},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"enabled\":true,\"size\":\"25Gi\",\"storageClass\":\"\"},\"postgresqlDatabase\":\"airflow\",\"postgresqlPassword\":\"airflow\",\"postgresqlUsername\":\"postgres\"},\"prometheusRule\":{\"additionalLabels\":{},\"enabled\":false,\"groups\":[]},\"rbac\":{\"create\":true,\"events\":true},\"redis\":{\"cluster\":{\"enabled\":false,\"slaveCount\":1},\"enabled\":true,\"existingSecret\":\"\",\"existingSecretPasswordKey\":\"redis-password\",\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"docker.io\",\"repository\":\"bitnami/redis\",\"tag\":\"5.0.14-debian-10-r173\"},\"master\":{\"affinity\":{},\"nodeSelector\":{},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"enabled\":false,\"size\":\"8Gi\",\"storageClass\":\"\"},\"podAnnotations\":{\"cluster-autoscaler.kubernetes.io/safe-to-evict\":\"true\"},\"resources\":{},\"tolerations\":[]},\"password\":\"airflow\",\"slave\":{\"affinity\":{},\"nodeSelector\":{},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"enabled\":false,\"size\":\"8Gi\",\"storageClass\":\"\"},\"podAnnotations\":{\"cluster-autoscaler.kubernetes.io/safe-to-evict\":\"true\"},\"resources\":{},\"tolerations\":[]}},\"scheduler\":{\"affinity\":{},\"annotations\":{},\"extraInitContainers\":[],\"extraPipPackages\":[\"apache-airflow-providers-apache-kafka\",\"apache-airflow-providers-mysql\",\"apache-airflow-providers-common-sql\",\"airflow-providers-clickhouse\",\"apache-airflow\",\"clickhouse-driver\",\"airflow-clickhouse-plugin\",\"airflow-provider-kafka\",\"influxdb-client\",\"pymongo\",\"pysnmp\",\"sqlalchemy\",\"boto3\",\"pysftp\",\"apache-airflow-providers-mongo\",\"snakebite\",\"pyarrow\",\"hdfs\",\"psycopg2-binary\",\"minio\",\"eloquent\",\"redis\",\"pandas\",\"mysql-connector-python\",\"requests\",\"datetime\"],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":5,\"initialDelaySeconds\":10,\"periodSeconds\":30,\"taskCreationCheck\":{\"enabled\":false,\"schedulerAgeBeforeCheck\":180,\"thresholdSeconds\":300},\"timeoutSeconds\":60},\"logCleanup\":{\"enabled\":true,\"intervalSeconds\":600,\"resources\":{},\"retentionMinutes\":6000},\"nodeSelector\":{},\"numRuns\":-1,\"podAnnotations\":{},\"podDisruptionBudget\":{\"apiVersion\":\"policy/v1\",\"enabled\":false,\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podLabels\":{},\"replicas\":8,\"resources\":{\"limits\":{\"cpu\":\"1500m\",\"memory\":\"2Gi\"},\"requests\":{\"cpu\":\"800m\",\"memory\":\"1200Mi\"}},\"safeToEvict\":true,\"securityContext\":{},\"tolerations\":[]},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":\"\"},\"serviceMonitor\":{\"enabled\":false,\"interval\":\"30s\",\"path\":\"/admin/metrics\",\"selector\":{\"prometheus\":\"kube-prometheus\"}},\"triggerer\":{\"affinity\":{},\"annotations\":{},\"capacity\":1000,\"enabled\":true,\"extraPipPackages\":[\"apache-airflow-providers-apache-kafka\",\"apache-airflow-providers-mysql\",\"apache-airflow-providers-common-sql\",\"airflow-providers-clickhouse\",\"apache-airflow\",\"clickhouse-driver\",\"airflow-clickhouse-plugin\",\"airflow-provider-kafka\",\"influxdb-client\",\"pymongo\",\"pysnmp\",\"sqlalchemy\",\"boto3\",\"pysftp\",\"apache-airflow-providers-mongo\",\"snakebite\",\"pyarrow\",\"hdfs\",\"psycopg2-binary\",\"minio\",\"eloquent\",\"redis\",\"pandas\",\"mysql-connector-python\",\"requests\",\"datetime\"],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":5,\"initialDelaySeconds\":10,\"periodSeconds\":30,\"timeoutSeconds\":60},\"nodeSelector\":{},\"podAnnotations\":{},\"podDisruptionBudget\":{\"apiVersion\":\"policy/v1\",\"enabled\":false,\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podLabels\":{},\"replicas\":5,\"resources\":{\"limits\":{\"cpu\":\"500m\",\"memory\":\"600Mi\"},\"requests\":{\"cpu\":\"200m\",\"memory\":\"400Mi\"}},\"safeToEvict\":true,\"securityContext\":{},\"tolerations\":[]},\"web\":{\"affinity\":{},\"annotations\":{},\"extraPipPackages\":[\"apache-airflow-providers-apache-kafka\",\"apache-airflow-providers-mysql\",\"apache-airflow-providers-common-sql\",\"airflow-providers-clickhouse\",\"apache-airflow\",\"clickhouse-driver\",\"airflow-clickhouse-plugin\",\"airflow-provider-kafka\",\"influxdb-client\",\"pymongo\",\"pysnmp\",\"sqlalchemy\",\"boto3\",\"pysftp\",\"apache-airflow-providers-mongo\",\"snakebite\",\"pyarrow\",\"hdfs\",\"psycopg2-binary\",\"minio\",\"eloquent\",\"redis\",\"pandas\",\"mysql-connector-python\",\"requests\",\"datetime\"],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"timeoutSeconds\":5},\"nodeSelector\":{},\"podAnnotations\":{},\"podDisruptionBudget\":{\"apiVersion\":\"policy/v1\",\"enabled\":false,\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podLabels\":{},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"timeoutSeconds\":5},\"replicas\":1,\"resources\":{},\"safeToEvict\":true,\"securityContext\":{},\"service\":{\"annotations\":{},\"externalPort\":8080,\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":{\"http\":\"\"},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"tolerations\":[],\"webserverConfig\":{\"enabled\":true,\"existingSecret\":\"\",\"stringOverride\":\"from airflow import configuration as conf\\nfrom flask_appbuilder.security.manager import AUTH_DB\\n\\n# the SQLAlchemy connection string\\nSQLALCHEMY_DATABASE_URI = conf.get('core', 'SQL_ALCHEMY_CONN')\\n\\n# use embedded DB for auth\\nAUTH_TYPE = AUTH_DB\\n\"}},\"workers\":{\"affinity\":{},\"annotations\":{},\"autoscaling\":{\"apiVersion\":\"autoscaling/v2\",\"enabled\":true,\"maxReplicas\":40,\"metrics\":[]},\"celery\":{\"gracefullTermination\":true,\"gracefullTerminationPeriod\":600},\"enabled\":true,\"extraPipPackages\":[\"apache-airflow-providers-apache-kafka\",\"apache-airflow-providers-mysql\",\"apache-airflow-providers-common-sql\",\"airflow-providers-clickhouse\",\"apache-airflow\",\"clickhouse-driver\",\"airflow-clickhouse-plugin\",\"airflow-provider-kafka\",\"influxdb-client\",\"pymongo\",\"pysnmp\",\"sqlalchemy\",\"boto3\",\"pysftp\",\"apache-airflow-providers-mongo\",\"snakebite\",\"pyarrow\",\"hdfs\",\"psycopg2-binary\",\"minio\",\"eloquent\",\"redis\",\"pandas\",\"mysql-connector-python\",\"requests\",\"datetime\"],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"labels\":{},\"logCleanup\":{\"enabled\":true,\"intervalSeconds\":600,\"resources\":{},\"retentionMinutes\":6000},\"nodeSelector\":{},\"podAnnotations\":{},\"podDisruptionBudget\":{\"apiVersion\":\"policy/v1\",\"enabled\":false,\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podLabels\":{},\"replicas\":10,\"resources\":{\"limits\":{\"cpu\":\"2000m\",\"memory\":\"2Gi\"},\"requests\":{\"cpu\":\"700m\",\"memory\":\"1200Mi\"}},\"safeToEvict\":true,\"securityContext\":{},\"terminationPeriod\":60,\"tolerations\":[]}}",
                "version": "8.9.0"
              }
            ],
            "name": "airflow-prd",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://airflow-helm.github.io/charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "airflow:\n  ## if we use legacy 1.10 airflow commands\n  ##\n  legacyCommands: false\n\n  ## configs for the airflow container image\n  ##\n  image:\n    repository: jackt72xp/airflowsnmp\n    tag: v01\n    pullPolicy: IfNotPresent\n    pullSecret: \"\"\n    uid: 50000\n    gid: 0\n\n  ## the airflow executor type to use\n  ## - allowed values: \"CeleryExecutor\", \"KubernetesExecutor\", \"CeleryKubernetesExecutor\"\n  ## - customize the \"KubernetesExecutor\" pod-template with `airflow.kubernetesPodTemplate.*`\n  ##\n  executor: CeleryExecutor\n\n  ## the fernet encryption key (sets `AIRFLOW__CORE__FERNET_KEY`)\n  ## - [WARNING] you must change this value to ensure the security of your airflow\n  ## - set `AIRFLOW__CORE__FERNET_KEY` with `airflow.extraEnv` from a Secret to avoid storing this in your values\n  ## - use this command to generate your own fernet key:\n  ##   python -c \"from cryptography.fernet import Fernet; FERNET_KEY = Fernet.generate_key().decode(); print(FERNET_KEY)\"\n  ##\n  fernetKey: \"7T512UXSSmBOkpWimFHIVb8jK6lfmSAvx4mO6Arehnc=\"\n\n  ## the secret_key for flask (sets `AIRFLOW__WEBSERVER__SECRET_KEY`)\n  ## - [WARNING] you must change this value to ensure the security of your airflow\n  ## - set `AIRFLOW__WEBSERVER__SECRET_KEY` with `airflow.extraEnv` from a Secret to avoid storing this in your values\n  ##\n  webserverSecretKey: \"MySecretKey123!\"\n\n  ## environment variables for airflow configs\n  ## - airflow env-vars are structured: \"AIRFLOW__{config_section}__{config_name}\"\n  ## - airflow configuration reference:\n  ##   https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html\n  ##\n  ## ____ EXAMPLE _______________\n  ##   config:\n  ##     # dag configs\n  ##     AIRFLOW__CORE__LOAD_EXAMPLES: \"False\"\n  ##     AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: \"30\"\n  ##\n  ##     # email configs\n  ##     AIRFLOW__EMAIL__EMAIL_BACKEND: \"airflow.utils.email.send_email_smtp\"\n  ##     AIRFLOW__SMTP__SMTP_HOST: \"smtpmail.example.com\"\n  ##     AIRFLOW__SMTP__SMTP_MAIL_FROM: \"admin@example.com\"\n  ##     AIRFLOW__SMTP__SMTP_PORT: \"25\"\n  ##     AIRFLOW__SMTP__SMTP_SSL: \"False\"\n  ##     AIRFLOW__SMTP__SMTP_STARTTLS: \"False\"\n  ##\n  ##     # domain used in airflow emails\n  ##     AIRFLOW__WEBSERVER__BASE_URL: \"http://airflow.example.com\"\n  ##\n  ##     # ether environment variables\n  ##     HTTP_PROXY: \"http://proxy.example.com:8080\"\n  ##\n  config:\n    AIRFLOW__CORE__LOAD_EXAMPLES: \"False\"\n    AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: \"30\"\n    AIRFLOW__WEBSERVER__BASE_URL: \"http://192.168.36.90\"\n\n\n  ## a list of users to create\n  ## - templates can ONLY be used in: `password`, `email`, `firstName`, `lastName`\n  ## - templates used a bash-like syntax: ${MY_USERNAME}, $MY_USERNAME\n  ## - templates are defined in `usersTemplates`\n  ## - `role` can be a single role or a list of roles\n  ##\n  users:\n  - username: admin\n    password: admin\n    role: Admin\n    email: admin@example.com\n    firstName: admin\n    lastName: admin\n\n  ## bash-like templates to be used in `airflow.users`\n  ## - [WARNING] if a Secret or ConfigMap is missing, the sync Pod will crash\n  ## - [WARNING] all keys must match the regex: ^[a-zA-Z_][a-zA-Z0-9_]*$\n  ##\n  ## ____ EXAMPLE _______________\n  ##   usersTemplates\n  ##     MY_USERNAME:\n  ##       kind: configmap\n  ##       name: my-configmap\n  ##       key: username\n  ##     MY_PASSWORD:\n  ##       kind: secret\n  ##       name: my-secret\n  ##       key: password\n  ##\n  usersTemplates: {}\n\n  ## if we create a Deployment to perpetually sync `airflow.users`\n  ## - when `true`, users are updated in real-time, as ConfigMaps/Secrets change\n  ## - when `true`, users changes from the WebUI will be reverted automatically\n  ## - when `false`, users will only update one-time, after each `helm upgrade`\n  ##\n  usersUpdate: true\n\n  ## a list airflow connections to create\n  ## - templates can ONLY be used in: `host`, `login`, `password`, `schema`, `extra`\n  ## - templates used a bash-like syntax: ${AWS_ACCESS_KEY} or $AWS_ACCESS_KEY\n  ## - templates are defined in `connectionsTemplates`\n  ##\n  ## ____ EXAMPLE _______________\n  ##   connections:\n  ##     - id: my_aws\n  ##       type: aws\n  ##       description: my AWS connection\n  ##       extra: |-\n  ##         { \"aws_access_key_id\": \"${AWS_KEY_ID}\",\n  ##           \"aws_secret_access_key\": \"${AWS_ACCESS_KEY}\",\n  ##           \"region_name\":\"eu-central-1\" }\n  ##\n  connections: []\n\n  ## bash-like templates to be used in `airflow.connections`\n  ## - see docs for `airflow.usersTemplates`\n  ##\n  connectionsTemplates: {}\n\n  ## if we create a Deployment to perpetually sync `airflow.connections`\n  ## - see docs for `airflow.usersUpdate`\n  ##\n  connectionsUpdate: true\n\n  ## a list airflow variables to create\n  ## - templates can ONLY be used in: `value`\n  ## - templates used a bash-like syntax: ${MY_VALUE} or $MY_VALUE\n  ## - templates are defined in `connectionsTemplates`\n  ##\n  ## ____ EXAMPLE _______________\n  ##   variables:\n  ##     - key: \"var_1\"\n  ##       value: \"my_value_1\"\n  ##     - key: \"var_2\"\n  ##       value: \"my_value_2\"\n  ##\n  variables: []\n\n  ## bash-like templates to be used in `airflow.variables`\n  ## - see docs for `airflow.usersTemplates`\n  ##\n  variablesTemplates: {}\n\n  ## if we create a Deployment to perpetually sync `airflow.variables`\n  ## - see docs for `airflow.usersUpdate`\n  ##\n  variablesUpdate: true\n\n  ## a list airflow pools to create\n  ##\n  ## ____ EXAMPLE _______________\n  ##   pools:\n  ##     - name: \"pool_1\"\n  ##       description: \"example pool with 5 slots\"\n  ##       slots: 5\n  ##     - name: \"pool_2\"\n  ##       description: \"example pool with 2 cron policies\"\n  ##       slots: 0\n  ##       ## at each sync interval, the policy with the most recently past `recurrence` is applied\n  ##       policies:\n  ##         - name: \"scale up at 7pm UTC\"\n  ##           slots: 50\n  ##           recurrence: \"0 19 * * *\"\n  ##         - name: \"scale down at 6am UTC\"\n  ##           slots: 10\n  ##           recurrence: \"0 6 * * *\"\n  ##\n  pools: []\n\n  ## if we create a Deployment to perpetually sync `airflow.pools`\n  ## - see docs for `airflow.usersUpdate`\n  ##\n  poolsUpdate: true\n\n  ## default nodeSelector for airflow Pods (is overridden by pod-specific values)\n  ## - docs for nodeSelector:\n  ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n  ##\n  defaultNodeSelector: {}\n\n  ## default affinity configs for airflow Pods (is overridden by pod-specific values)\n  ## - spec for Affinity:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n  ##\n  defaultAffinity: {}\n\n  ## default toleration configs for airflow Pods (is overridden by pod-specific values)\n  ## - spec for Toleration:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n  ##\n  defaultTolerations: []\n\n  ## default securityContext configs for airflow Pods (is overridden by pod-specific values)\n  ## - spec for PodSecurityContext:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n  ##\n  defaultSecurityContext:\n    ## sets the filesystem owner group of files/folders in mounted volumes\n    ## this does NOT give root permissions to Pods, only the \"root\" group\n    fsGroup: 0\n\n  ## extra annotations for airflow Pods\n  ##\n  podAnnotations: {}\n\n  ## extra pip packages to install in airflow Pods\n  ##\n  ## ____ EXAMPLE _______________\n  ##   extraPipPackages:\n  ##     - \"SomeProject==1.0.0\"\n  ##\n  extraPipPackages:\n  - \"apache-airflow-providers-apache-kafka\"\n  - \"apache-airflow-providers-mysql\"\n  - \"apache-airflow-providers-common-sql\"\n  - \"airflow-providers-clickhouse\"\n  - \"apache-airflow\"\n  - \"clickhouse-driver\"\n  - \"airflow-clickhouse-plugin\"\n  - \"airflow-provider-kafka\"\n  - \"influxdb-client\"\n  - \"pymongo\"\n  - \"pysnmp\"\n  - \"sqlalchemy\"\n  - \"boto3\"\n  - \"pysftp\"\n  - \"apache-airflow-providers-mongo\"\n  - \"snakebite\"\n  - \"pyarrow\"\n  - \"hdfs\"\n  - \"psycopg2-binary\"\n  - \"minio\"\n  - \"eloquent\"\n  - \"redis\"\n  - \"pandas\"\n  - \"mysql-connector-python\"\n  - \"requests\"\n  - \"datetime\"\n\n  ## pip packages that are protected from upgrade/downgrade by `extraPipPackages`\n  ## - [WARNING] Pods will fail to start if `extraPipPackages` would cause these packages to change versions\n  ##\n  protectedPipPackages:\n  - \"apache-airflow\"\n\n  ## extra environment variables for the airflow Pods\n  ## - spec for EnvVar:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#envvar-v1-core\n  ##\n  extraEnv: []\n\n  ## extra containers for the airflow Pods\n  ## - spec for Container:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core\n  ##\n  extraContainers: []\n\n  ## extra VolumeMounts for the airflow Pods\n  ## - spec for VolumeMount:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volumemount-v1-core\n  ##\n  extraVolumeMounts: []\n\n  ## extra Volumes for the airflow Pods\n  ## - spec for Volume:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volume-v1-core\n  ##\n  extraVolumes: []\n\n  ## kubernetes cluster domain name\n  ## - configured in the kubelet with `--cluster-domain` flag (deprecated):\n  ##   https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/\n  ## - or configured in the kubelet with configuration file `clusterDomain` option:\n  ##   https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/\n  ##\n  clusterDomain: \"cluster.local\"\n\n  ########################################\n  ## FILE | airflow_local_settings.py\n  ########################################\n  ##\n  localSettings:\n    ## the full content of the `airflow_local_settings.py` file (as a string)\n    ## - docs for airflow cluster policies:\n    ##   https://airflow.apache.org/docs/apache-airflow/stable/concepts/cluster-policies.html\n    ##\n    ## ____ EXAMPLE _______________\n    ##    stringOverride: |\n    ##      # use a custom `xcom_sidecar` image for KubernetesPodOperator()\n    ##      from airflow.kubernetes.pod_generator import PodDefaults\n    ##      PodDefaults.SIDECAR_CONTAINER.image = \"gcr.io/PROJECT-ID/custom-sidecar-image\"\n    ##\n    stringOverride: \"\"\n\n    ## the name of a Secret containing a `airflow_local_settings.py` key\n    ## - if set, this disables `airflow.localSettings.stringOverride`\n    ##\n    existingSecret: \"\"\n\n  ########################################\n  ## FILE | pod_template.yaml\n  ########################################\n  ## - generates a file for `AIRFLOW__KUBERNETES__POD_TEMPLATE_FILE`\n  ## - the `dags.gitSync` values will create a git-sync init-container in the pod\n  ## - the `airflow.extraPipPackages` will NOT be installed\n  ##\n  kubernetesPodTemplate:\n    ## the full content of the pod-template file (as a string)\n    ## - [WARNING] all other `kubernetesPodTemplate.*` are disabled when this is set\n    ## - docs for pod-template file:\n    ##   https://airflow.apache.org/docs/apache-airflow/stable/executor/kubernetes.html#pod-template-file\n    ##\n    ## ____ EXAMPLE _______________\n    ##   stringOverride: |-\n    ##     apiVersion: v1\n    ##     kind: Pod\n    ##     spec: ...\n    ##\n    stringOverride: \"\"\n\n    ## resource requests/limits for the Pod template \"base\" container\n    ## - spec for ResourceRequirements:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n    ##\n    resources: {}\n\n    ## the nodeSelector configs for the Pod template\n    ## - docs for nodeSelector:\n    ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n    ##\n    nodeSelector: {}\n\n    ## the affinity configs for the Pod template\n    ## - spec for Affinity:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n    ##\n    affinity: {}\n\n    ## the toleration configs for the Pod template\n    ## - spec for Toleration:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n    ##\n    tolerations: []\n\n    ## labels for the Pod template\n    ##\n    podLabels: {}\n\n    ## annotations for the Pod template\n    ##\n    podAnnotations: {}\n\n    ## the security context for the Pod template\n    ## - spec for PodSecurityContext:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n    ##\n    securityContext: {}\n\n    ## the shareProcessNamespace config for the Pod template\n    ## - docs for shareProcessNamespace:\n    ##   https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/\n    ##\n    shareProcessNamespace: false\n\n    ## extra pip packages to install in the Pod template\n    ##\n    ## ____ EXAMPLE _______________\n    ##   extraPipPackages:\n    ##     - \"SomeProject==1.0.0\"\n    ##\n    extraPipPackages:\n    - \"apache-airflow-providers-apache-kafka\"\n    - \"apache-airflow-providers-mysql\"\n    - \"apache-airflow-providers-common-sql\"\n    - \"airflow-providers-clickhouse\"\n    - \"apache-airflow\"\n    - \"clickhouse-driver\"\n    - \"airflow-clickhouse-plugin\"\n    - \"airflow-provider-kafka\"\n    - \"influxdb-client\"\n    - \"pymongo\"\n    - \"pysnmp\"\n    - \"sqlalchemy\"\n    - \"boto3\"\n    - \"pysftp\"\n    - \"apache-airflow-providers-mongo\"\n    - \"snakebite\"\n    - \"pyarrow\"\n    - \"hdfs\"\n    - \"psycopg2-binary\"\n    - \"minio\"\n    - \"eloquent\"\n    - \"redis\"\n    - \"pandas\"\n    - \"mysql-connector-python\"\n    - \"requests\"\n    - \"datetime\"\n\n\n    ## extra containers for the pod template\n    ## - spec for Container:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core\n    ##\n    extraContainers: []\n\n    ## extra init-containers for the Pod template\n    ## - spec of Container:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core\n    ##\n    extraInitContainers:\n    - name: install-snmp\n      image: debian:buster\n      command:\n      - \"/bin/sh\"\n      - \"-c\"\n      - \u003e\n        apt-get update \u0026\u0026 apt-get install -y snmp \u0026\u0026 apt-get clean #magic___^_^___line\n      ## extra VolumeMounts for the Pod template\n    ## - spec for VolumeMount:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volumemount-v1-core\n    ##\n    extraVolumeMounts: []\n\n    ## extra Volumes for the Pod template\n    ## - spec for Volume:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volume-v1-core\n    ##\n    extraVolumes: []\n\n  ########################################\n  ## COMPONENT | db-migrations Deployment\n  ########################################\n  dbMigrations:\n    ## if the db-migrations Deployment/Job is created\n    ## - [WARNING] if `false`, you have to MANUALLY run `airflow db upgrade` when required\n    ##\n    enabled: true\n\n    ## if a post-install helm Job should be used (instead of a Deployment)\n    ## - [WARNING] setting `true` will NOT work with the helm `--wait` flag,\n    ##   this is because post-install helm Jobs run AFTER the main resources become Ready,\n    ##   which will cause a deadlock, as other resources require db-migrations to become Ready\n    ##\n    runAsJob: false\n\n    ## resource requests/limits for the db-migrations Pods\n    ## - spec for ResourceRequirements:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n    ##\n    resources: {}\n\n    ## the nodeSelector configs for the db-migrations Pods\n    ## - docs for nodeSelector:\n    ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n    ##\n    nodeSelector: {}\n\n    ## the affinity configs for the db-migrations Pods\n    ## - spec for Affinity:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n    ##\n    affinity: {}\n\n    ## the toleration configs for the db-migrations Pods\n    ## - spec for Toleration:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n    ##\n    tolerations: []\n\n    ## the security context for the db-migrations Pods\n    ## - spec for PodSecurityContext:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n    ##\n    securityContext: {}\n\n    ## Labels for the db-migrations Deployment\n    ##\n    labels: {}\n\n    ## Pod labels for the db-migrations Deployment\n    ##\n    podLabels: {}\n\n    ## annotations for the db-migrations Deployment/Job\n    ##\n    annotations: {}\n\n    ## Pod annotations for the db-migrations Deployment/Job\n    ##\n    podAnnotations: {}\n\n    ## if we add the annotation: \"cluster-autoscaler.kubernetes.io/safe-to-evict\" = \"true\"\n    ##\n    safeToEvict: true\n\n    ## the number of seconds between checks for unapplied db migrations\n    ## - only applies if `airflow.dbMigrations.runAsJob` is `false`\n    ##\n    checkInterval: 300\n\n  ########################################\n  ## COMPONENT | Sync Deployments\n  ########################################\n  ## - used by the Deployments/Jobs used by `airflow.{connections,pools,users,variables}`\n  ##\n  sync:\n    ## resource requests/limits for the sync Pods\n    ## - spec for ResourceRequirements:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n    ##\n    resources: {}\n\n    ## the nodeSelector configs for the sync Pods\n    ## - docs for nodeSelector:\n    ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n    ##\n    nodeSelector: {}\n\n    ## the affinity configs for the sync Pods\n    ## - spec for Affinity:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n    ##\n    affinity: {}\n\n    ## the toleration configs for the sync Pods\n    ## - spec for Toleration:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n    ##\n    tolerations: []\n\n    ## the security context for the sync Pods\n    ## - spec for PodSecurityContext:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n    ##\n    securityContext: {}\n\n    ## Labels for the sync Deployments/Jobs\n    ##\n    labels: {}\n\n    ## Pod labels for the sync Deployments/Jobs\n    ##\n    podLabels: {}\n\n    ## annotations for the sync Deployments/Jobs\n    ##\n    annotations: {}\n\n    ## Pod annotations for the sync Deployments/Jobs\n    ##\n    podAnnotations: {}\n\n    ## if we add the annotation: \"cluster-autoscaler.kubernetes.io/safe-to-evict\" = \"true\"\n    ##\n    safeToEvict: true\nscheduler:\n  ## the number of scheduler Pods to run\n  ## - if you set this \u003e1 we recommend defining a `scheduler.podDisruptionBudget`\n  ##\n  replicas: 8\n\n  ## resource requests/limits for the scheduler Pod\n  ## - spec of ResourceRequirements:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n  ##\n  resources:\n    requests:\n      cpu: \"800m\" # Solicita 100 milicore, 0.1 core\n      memory: \"1200Mi\" # Solicita 200 MiB de memoria\n    limits:\n      cpu: \"1500m\" # Límite de 500 milicore, 0.5 core\n      memory: \"2Gi\" # Límite de 500 MiB de memoria\n\n\n  ## the nodeSelector configs for the scheduler Pods\n  ## - docs for nodeSelector:\n  ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n  ##\n  nodeSelector: {}\n\n  ## the affinity configs for the scheduler Pods\n  ## - spec of Affinity:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n  ##\n  affinity: {}\n\n  ## the toleration configs for the scheduler Pods\n  ## - spec of Toleration:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n  ##\n  tolerations: []\n\n  ## the security context for the scheduler Pods\n  ## - spec of PodSecurityContext:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n  ##\n  securityContext: {}\n\n  ## labels for the scheduler Deployment\n  ##\n  labels: {}\n\n  ## Pod labels for the scheduler Deployment\n  ##\n  podLabels: {}\n\n  ## annotations for the scheduler Deployment\n  ##\n  annotations: {}\n\n  ## Pod annotations for the scheduler Deployment\n  ##\n  podAnnotations: {}\n\n  ## if we add the annotation: \"cluster-autoscaler.kubernetes.io/safe-to-evict\" = \"true\"\n  ##\n  safeToEvict: true\n\n  ## configs for the PodDisruptionBudget of the scheduler\n  ##\n  podDisruptionBudget:\n    ## if a PodDisruptionBudget resource is created for the scheduler\n    ##\n    enabled: false\n\n    ## the `apiVersion` to use for PodDisruptionBudget resources\n    ## - for Kubernetes 1.21 and later: \"policy/v1\"\n    ## - for Kubernetes 1.20 and before: \"policy/v1beta1\"\n    ##\n    apiVersion: policy/v1\n\n    ## the maximum unavailable pods/percentage for the scheduler\n    ##\n    maxUnavailable: \"\"\n\n    ## the minimum available pods/percentage for the scheduler\n    ##\n    minAvailable: \"\"\n\n  ## configs for the log-cleanup sidecar of the scheduler\n  ## - helps prevent excessive log buildup by regularly deleting old files\n  ##\n  logCleanup:\n    ## if the log-cleanup sidecar is enabled\n    ## - [WARNING] must be disabled if `logs.persistence.enabled` is `true`\n    ##\n    enabled: true\n\n    ## resource requests/limits for the log-cleanup container\n    ## - spec of ResourceRequirements:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n    ##\n    resources: {}\n\n    ## the number of minutes to retain log files (by last-modified time)\n    ##\n    retentionMinutes: 6000\n\n    ## the number of seconds between each check for files to delete\n    ##\n    intervalSeconds: 600\n\n  ## sets `airflow --num_runs` parameter used to run the airflow scheduler\n  ##\n  numRuns: -1\n\n  ## configs for the scheduler Pods' liveness probe\n  ## - \"unhealthy\" means the SchedulerJob has not had a heartbeat for\n  ##   AIRFLOW__SCHEDULER__SCHEDULER_HEALTH_CHECK_THRESHOLD seconds\n  ## - `periodSeconds` x `failureThreshold` = max seconds a scheduler can be in an \"unhealthy\" state\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 30\n    timeoutSeconds: 60\n    failureThreshold: 5\n\n    ## configs for an additional check that ensures tasks are being created by the scheduler\n    ## - this check works by ensuring that the most recent LocalTaskJob had a `start_date` no more than\n    ##   `taskCreationCheck.thresholdSeconds` seconds ago\n    ## - this check is useful because the scheduler can deadlock with a heartbeat, but not be scheduling new tasks:\n    ##   https://github.com/apache/airflow/issues/7935 - patched in airflow `2.0.2`\n    ##   https://github.com/apache/airflow/issues/15938 - patched in airflow `2.1.1`\n    ##\n    taskCreationCheck:\n      ## if the task creation check is enabled\n      ##\n      enabled: false\n\n      ## the maximum number of seconds since the start_date of the most recent LocalTaskJob\n      ## - [WARNING] must be AT LEAST equal to your shortest DAG schedule_interval\n      ## - [WARNING] DummyOperator tasks will NOT be seen by this probe\n      ##\n      thresholdSeconds: 300\n\n      ## minimum number of seconds the scheduler must have run before the task creation check begins\n      ## - [WARNING] must be long enough for the scheduler to boot and create a task\n      ##\n      schedulerAgeBeforeCheck: 180\n\n  ## extra pip packages to install in the scheduler Pods\n  ##\n  ## ____ EXAMPLE _______________\n  ##   extraPipPackages:\n  ##     - \"SomeProject==1.0.0\"\n  ##\n  extraPipPackages:\n  - \"apache-airflow-providers-apache-kafka\"\n  - \"apache-airflow-providers-mysql\"\n  - \"apache-airflow-providers-common-sql\"\n  - \"airflow-providers-clickhouse\"\n  - \"apache-airflow\"\n  - \"clickhouse-driver\"\n  - \"airflow-clickhouse-plugin\"\n  - \"airflow-provider-kafka\"\n  - \"influxdb-client\"\n  - \"pymongo\"\n  - \"pysnmp\"\n  - \"sqlalchemy\"\n  - \"boto3\"\n  - \"pysftp\"\n  - \"apache-airflow-providers-mongo\"\n  - \"snakebite\"\n  - \"pyarrow\"\n  - \"hdfs\"\n  - \"psycopg2-binary\"\n  - \"minio\"\n  - \"eloquent\"\n  - \"redis\"\n  - \"pandas\"\n  - \"mysql-connector-python\"\n  - \"requests\"\n  - \"datetime\"\n\n  ## extra VolumeMounts for the scheduler Pods\n  ## - spec of VolumeMount:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volumemount-v1-core\n  ##\n  extraVolumeMounts: []\n\n  ## extra Volumes for the scheduler Pods\n  ## - spec of Volume:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volume-v1-core\n  ##\n  extraVolumes: []\n\n  ## extra init containers to run in the scheduler Pods\n  ## - spec of Container:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core\n  ##\n  extraInitContainers: []\nweb:\n  ########################################\n  ## FILE | webserver_config.py\n  ########################################\n  ##\n  webserverConfig:\n    ## if the `webserver_config.py` file is mounted\n    ## - set to false if you wish to mount your own `webserver_config.py` file\n    ##\n    enabled: true\n\n    ## the full content of the `webserver_config.py` file (as a string)\n    ## - docs for Flask-AppBuilder security configs:\n    ##   https://flask-appbuilder.readthedocs.io/en/latest/security.html\n    ##\n    ## ____ EXAMPLE _______________\n    stringOverride: |\n      from airflow import configuration as conf\n      from flask_appbuilder.security.manager import AUTH_DB\n\n      # the SQLAlchemy connection string\n      SQLALCHEMY_DATABASE_URI = conf.get('core', 'SQL_ALCHEMY_CONN')\n\n      # use embedded DB for auth\n      AUTH_TYPE = AUTH_DB\n    ##\n    # stringOverride: \"\"\n\n    ## the name of a Secret containing a `webserver_config.py` key\n    ##\n    existingSecret: \"\"\n\n  ## the number of web Pods to run\n  ## - if you set this \u003e1 we recommend defining a `web.podDisruptionBudget`\n  ##\n  replicas: 1\n\n  ## resource requests/limits for the web Pod\n  ## - spec for ResourceRequirements:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n  ##\n  resources: {}\n\n  ## the nodeSelector configs for the web Pods\n  ## - docs for nodeSelector:\n  ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n  ##\n  nodeSelector: {}\n\n  ## the affinity configs for the web Pods\n  ## - spec for Affinity:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n  ##\n  affinity: {}\n\n  ## the toleration configs for the web Pods\n  ## - spec for Toleration:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n  ##\n  tolerations: []\n\n  ## the security context for the web Pods\n  ## - spec for PodSecurityContext:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n  ##\n  securityContext: {}\n\n  ## labels for the web Deployment\n  ##\n  labels: {}\n\n  ## Pod labels for the web Deployment\n  ##\n  podLabels: {}\n\n  ## annotations for the web Deployment\n  ##\n  annotations: {}\n\n  ## Pod annotations for the web Deployment\n  ##\n  podAnnotations: {}\n\n  ## if we add the annotation: \"cluster-autoscaler.kubernetes.io/safe-to-evict\" = \"true\"\n  ##\n  safeToEvict: true\n\n  ## configs for the PodDisruptionBudget of the web Deployment\n  ##\n  podDisruptionBudget:\n    ## if a PodDisruptionBudget resource is created for the web Deployment\n    ##\n    enabled: false\n\n    ## the `apiVersion` to use for PodDisruptionBudget resources\n    ## - for Kubernetes 1.21 and later: \"policy/v1\"\n    ## - for Kubernetes 1.20 and before: \"policy/v1beta1\"\n    ##\n    apiVersion: policy/v1\n\n    ## the maximum unavailable pods/percentage for the web Deployment\n    ##\n    maxUnavailable: \"\"\n\n    ## the minimum available pods/percentage for the web Deployment\n    ##\n    minAvailable: \"\"\n\n  ## configs for the Service of the web Pods\n  ##\n  service:\n    annotations: {}\n    sessionAffinity: \"None\"\n    sessionAffinityConfig: {}\n    type: ClusterIP\n    externalPort: 8080\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    nodePort:\n      http: \"\"\n\n  ## configs for the web Pods' readiness probe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n\n  ## configs for the web Pods' liveness probe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n\n  ## extra pip packages to install in the web Pods\n  ##\n  ## ____ EXAMPLE _______________\n  ##   extraPipPackages:\n  ##     - \"SomeProject==1.0.0\"\n  ##\n  extraPipPackages:\n  - \"apache-airflow-providers-apache-kafka\"\n  - \"apache-airflow-providers-mysql\"\n  - \"apache-airflow-providers-common-sql\"\n  - \"airflow-providers-clickhouse\"\n  - \"apache-airflow\"\n  - \"clickhouse-driver\"\n  - \"airflow-clickhouse-plugin\"\n  - \"airflow-provider-kafka\"\n  - \"influxdb-client\"\n  - \"pymongo\"\n  - \"pysnmp\"\n  - \"sqlalchemy\"\n  - \"boto3\"\n  - \"pysftp\"\n  - \"apache-airflow-providers-mongo\"\n  - \"snakebite\"\n  - \"pyarrow\"\n  - \"hdfs\"\n  - \"psycopg2-binary\"\n  - \"minio\"\n  - \"eloquent\"\n  - \"redis\"\n  - \"pandas\"\n  - \"mysql-connector-python\"\n  - \"requests\"\n  - \"datetime\"\n\n  ## extra VolumeMounts for the web Pods\n  ## - spec for VolumeMount:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volumemount-v1-core\n  ##\n  extraVolumeMounts: []\n\n  ## extra Volumes for the web Pods\n  ## - spec for Volume:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volume-v1-core\n  ##\n  extraVolumes: []\nworkers:\n  ## if the airflow workers StatefulSet should be deployed\n  ##\n  enabled: true\n\n  ## the number of worker Pods to run\n  ## - if you set this \u003e1 we recommend defining a `workers.podDisruptionBudget`\n  ## - this is the minimum when `workers.autoscaling.enabled` is true\n  ##\n  replicas: 10\n\n  ## resource requests/limits for the worker Pod\n  ## - spec for ResourceRequirements:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n  ##\n  resources:\n    requests:\n      cpu: \"700m\" # Solicita 100 milicore, 0.1 core\n      memory: \"1200Mi\" # Solicita 200 MiB de memoria\n    limits:\n      cpu: \"2000m\" # Límite de 500 milicore, 0.5 core\n      memory: \"2Gi\" # Límite de 500 MiB de memoria\n\n\n  ## the nodeSelector configs for the worker Pods\n  ## - docs for nodeSelector:\n  ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n  ##\n  nodeSelector: {}\n\n  ## the affinity configs for the worker Pods\n  ## - spec for Affinity:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n  ##\n  affinity: {}\n\n  ## the toleration configs for the worker Pods\n  ## - spec for Toleration:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n  ##\n  tolerations: []\n\n  ## the security context for the worker Pods\n  ## - spec for PodSecurityContext:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n  ##\n  securityContext: {}\n\n  ## labels for the worker StatefulSet\n  ##\n  labels: {}\n\n  ## Pod labels for the worker StatefulSet\n  ##\n  podLabels: {}\n\n  ## annotations for the worker StatefulSet\n  ##\n  annotations: {}\n\n  ## Pod annotations for the worker StatefulSet\n  ##\n  podAnnotations: {}\n\n  ## if we add the annotation: \"cluster-autoscaler.kubernetes.io/safe-to-evict\" = \"true\"\n  ##\n  safeToEvict: true\n\n  ## configs for the PodDisruptionBudget of the worker StatefulSet\n  ##\n  podDisruptionBudget:\n    ## if a PodDisruptionBudget resource is created for the worker StatefulSet\n    ##\n    enabled: false\n\n    ## the `apiVersion` to use for PodDisruptionBudget resources\n    ## - for Kubernetes 1.21 and later: \"policy/v1\"\n    ## - for Kubernetes 1.20 and before: \"policy/v1beta1\"\n    ##\n    apiVersion: policy/v1\n\n    ## the maximum unavailable pods/percentage for the worker StatefulSet\n    ##\n    maxUnavailable: \"\"\n\n    ## the minimum available pods/percentage for the worker StatefulSet\n    ##\n    minAvailable: \"\"\n\n  ## configs for the HorizontalPodAutoscaler of the worker Pods\n  ## - [WARNING] if using git-sync, ensure `dags.gitSync.resources` is set\n  ## - [WARNING] if using worker log-cleanup, ensure `workers.logCleanup.resources` is set\n  ##\n  ## ____ EXAMPLE _______________\n  ##   autoscaling:\n  ##     enabled: true\n  ##     maxReplicas: 16\n  ##     metrics:\n  ##     - type: Resource\n  ##       resource:\n  ##         name: memory\n  ##         target:\n  ##           type: Utilization\n  ##           averageUtilization: 80\n  ##\n  autoscaling:\n    enabled: true\n    maxReplicas: 40\n    metrics: []\n\n    ## the `apiVersion` to use for HorizontalPodAutoscaler resources\n    ## - for Kubernetes 1.23 and later: \"autoscaling/v2\"\n    ## - for Kubernetes 1.22 and before: \"autoscaling/v2beta2\"\n    ##\n    apiVersion: autoscaling/v2\n\n  ## configs for the celery worker Pods\n  ##\n  celery:\n    ## if celery worker Pods are gracefully terminated\n    ## - consider defining a `workers.podDisruptionBudget` to prevent there not being\n    ##   enough available workers during graceful termination waiting periods\n    ##\n    ## graceful termination process:\n    ##  1. prevent worker accepting new tasks\n    ##  2. wait AT MOST `workers.celery.gracefullTerminationPeriod` for tasks to finish\n    ##  3. send SIGTERM to worker\n    ##  4. wait AT MOST `workers.terminationPeriod` for kill to finish\n    ##  5. send SIGKILL to worker\n    ##\n    gracefullTermination: true\n\n    ## how many seconds to wait for tasks to finish before SIGTERM of the celery worker\n    ##\n    gracefullTerminationPeriod: 600\n\n  ## how many seconds to wait after SIGTERM before SIGKILL of the celery worker\n  ## - [WARNING] tasks that are still running during SIGKILL will be orphaned, this is important\n  ##   to understand with KubernetesPodOperator(), as Pods may continue running\n  ##\n  terminationPeriod: 60\n\n  ## configs for the log-cleanup sidecar of the worker Pods\n  ## - helps prevent excessive log buildup by regularly deleting old files\n  ##\n  logCleanup:\n    ## if the log-cleanup sidecar is enabled\n    ## - [WARNING] must be disabled if `logs.persistence.enabled` is `true`\n    ##\n    enabled: true\n\n    ## resource requests/limits for the log-cleanup container\n    ## - spec of ResourceRequirements:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n    ##\n    resources: {}\n\n    ## the number of minutes to retain log files (by last-modified time)\n    ##\n    retentionMinutes: 6000\n\n    ## the number of seconds between each check for files to delete\n    ##\n    intervalSeconds: 600\n\n  ## extra pip packages to install in the worker Pod\n  ##\n  ## ____ EXAMPLE _______________\n  ##   extraPipPackages:\n  ##     - \"SomeProject==1.0.0\"\n  ##\n  extraPipPackages:\n  - \"apache-airflow-providers-apache-kafka\"\n  - \"apache-airflow-providers-mysql\"\n  - \"apache-airflow-providers-common-sql\"\n  - \"airflow-providers-clickhouse\"\n  - \"apache-airflow\"\n  - \"clickhouse-driver\"\n  - \"airflow-clickhouse-plugin\"\n  - \"airflow-provider-kafka\"\n  - \"influxdb-client\"\n  - \"pymongo\"\n  - \"pysnmp\"\n  - \"sqlalchemy\"\n  - \"boto3\"\n  - \"pysftp\"\n  - \"apache-airflow-providers-mongo\"\n  - \"snakebite\"\n  - \"pyarrow\"\n  - \"hdfs\"\n  - \"psycopg2-binary\"\n  - \"minio\"\n  - \"eloquent\"\n  - \"redis\"\n  - \"pandas\"\n  - \"mysql-connector-python\"\n  - \"requests\"\n  - \"datetime\"\n  ## extra VolumeMounts for the worker Pods\n  ## - spec for VolumeMount:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volumemount-v1-core\n  ##\n  extraVolumeMounts: []\n\n  ## extra Volumes for the worker Pods\n  ## - spec for Volume:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volume-v1-core\n  ##\n  extraVolumes: []\ntriggerer:\n  ## if the airflow triggerer should be deployed\n  ## - [WARNING] the triggerer component was added in airflow 2.2.0\n  ## - [WARNING] if `airflow.legacyCommands` is `true` the triggerer will NOT be deployed\n  ##\n  enabled: true\n\n  ## the number of triggerer Pods to run\n  ## - if you set this \u003e1 we recommend defining a `triggerer.podDisruptionBudget`\n  ##\n  replicas: 5\n\n  ## resource requests/limits for the triggerer Pods\n  ## - spec for ResourceRequirements:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n  ##\n  resources:\n    requests:\n      cpu: \"200m\" # Solicita 100 milicore, 0.1 core\n      memory: \"400Mi\" # Solicita 200 MiB de memoria\n    limits:\n      cpu: \"500m\" # Límite de 500 milicore, 0.5 core\n      memory: \"600Mi\" # Límite de 500 MiB de memoria\n\n  ## the nodeSelector configs for the triggerer Pods\n  ## - docs for nodeSelector:\n  ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n  ##\n  nodeSelector: {}\n\n  ## the affinity configs for the triggerer Pods\n  ## - spec for Affinity:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n  ##\n  affinity: {}\n\n  ## the toleration configs for the triggerer Pods\n  ## - spec for Toleration:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n  ##\n  tolerations: []\n\n  ## the security context for the triggerer Pods\n  ## - spec for PodSecurityContext:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n  ##\n  securityContext: {}\n\n  ## labels for the triggerer Deployment\n  ##\n  labels: {}\n\n  ## Pod labels for the triggerer Deployment\n  ##\n  podLabels: {}\n\n  ## annotations for the triggerer Deployment\n  ##\n  annotations: {}\n\n  ## Pod annotations for the triggerer Deployment\n  ##\n  podAnnotations: {}\n\n  ## if we add the annotation: \"cluster-autoscaler.kubernetes.io/safe-to-evict\" = \"true\"\n  ##\n  safeToEvict: true\n\n  ## configs for the PodDisruptionBudget of the triggerer Deployment\n  ##\n  podDisruptionBudget:\n    ## if a PodDisruptionBudget resource is created for the triggerer Deployment\n    ##\n    enabled: false\n\n    ## the `apiVersion` to use for PodDisruptionBudget resources\n    ## - for Kubernetes 1.21 and later: \"policy/v1\"\n    ## - for Kubernetes 1.20 and before: \"policy/v1beta1\"\n    ##\n    apiVersion: policy/v1\n\n    ## the maximum unavailable pods/percentage for the triggerer Deployment\n    ##\n    maxUnavailable: \"\"\n\n    ## the minimum available pods/percentage for the triggerer Deployment\n    ##\n    minAvailable: \"\"\n\n  ## maximum number of triggers each triggerer will run at once (sets `AIRFLOW__TRIGGERER__DEFAULT_CAPACITY`)\n  ##\n  capacity: 1000\n\n  ## configs for the triggerer Pods' liveness probe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 30\n    timeoutSeconds: 60\n    failureThreshold: 5\n\n  ## extra pip packages to install in the triggerer Pod\n  ##\n  ## ____ EXAMPLE _______________\n  ##   extraPipPackages:\n  ##     - \"SomeProject==1.0.0\"\n  ##\n  extraPipPackages:\n  - \"apache-airflow-providers-apache-kafka\"\n  - \"apache-airflow-providers-mysql\"\n  - \"apache-airflow-providers-common-sql\"\n  - \"airflow-providers-clickhouse\"\n  - \"apache-airflow\"\n  - \"clickhouse-driver\"\n  - \"airflow-clickhouse-plugin\"\n  - \"airflow-provider-kafka\"\n  - \"influxdb-client\"\n  - \"pymongo\"\n  - \"pysnmp\"\n  - \"sqlalchemy\"\n  - \"boto3\"\n  - \"pysftp\"\n  - \"apache-airflow-providers-mongo\"\n  - \"snakebite\"\n  - \"pyarrow\"\n  - \"hdfs\"\n  - \"psycopg2-binary\"\n  - \"minio\"\n  - \"eloquent\"\n  - \"redis\"\n  - \"pandas\"\n  - \"mysql-connector-python\"\n  - \"requests\"\n  - \"datetime\"\n\n  ## extra VolumeMounts for the triggerer Pods\n  ## - spec for VolumeMount:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volumemount-v1-core\n  ##\n  extraVolumeMounts: []\n\n  ## extra Volumes for the triggerer Pods\n  ## - spec for Volume:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volume-v1-core\n  ##\n  extraVolumes: []\nflower:\n  ## if the airflow flower UI should be deployed\n  ##\n  enabled: true\n\n  ## the number of flower Pods to run\n  ## - if you set this \u003e1 we recommend defining a `flower.podDisruptionBudget`\n  ##\n  replicas: 8\n\n  ## resource requests/limits for the flower Pod\n  ## - spec for ResourceRequirements:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n  ##\n  resources: {}\n\n  ## the nodeSelector configs for the flower Pods\n  ## - docs for nodeSelector:\n  ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n  ##\n  nodeSelector: {}\n\n  ## the affinity configs for the flower Pods\n  ## - spec for Affinity:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n  ##\n  affinity: {}\n\n  ## the toleration configs for the flower Pods\n  ## - spec for Toleration:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n  ##\n  tolerations: []\n\n  ## the security context for the flower Pods\n  ## - spec for PodSecurityContext:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n  ##\n  securityContext: {}\n\n  ## labels for the flower Deployment\n  ##\n  labels: {}\n\n  ## Pod labels for the flower Deployment\n  ##\n  podLabels: {}\n\n  ## annotations for the flower Deployment\n  ##\n  annotations: {}\n\n  ## Pod annotations for the flower Deployment\n  ##\n  podAnnotations: {}\n\n  ## if we add the annotation: \"cluster-autoscaler.kubernetes.io/safe-to-evict\" = \"true\"\n  ##\n  safeToEvict: true\n\n  ## configs for the PodDisruptionBudget of the flower Deployment\n  ##\n  podDisruptionBudget:\n    ## if a PodDisruptionBudget resource is created for the flower Deployment\n    ##\n    enabled: false\n\n    ## the `apiVersion` to use for PodDisruptionBudget resources\n    ## - for Kubernetes 1.21 and later: \"policy/v1\"\n    ## - for Kubernetes 1.20 and before: \"policy/v1beta1\"\n    ##\n    apiVersion: policy/v1\n\n    ## the maximum unavailable pods/percentage for the flower Deployment\n    ##\n    maxUnavailable: \"\"\n\n    ## the minimum available pods/percentage for the flower Deployment\n    ##\n    minAvailable: \"\"\n\n  ## the name of a pre-created secret containing the basic authentication value for flower\n  ## - this will override any value of `config.AIRFLOW__CELERY__FLOWER_BASIC_AUTH`\n  ##\n  basicAuthSecret: \"\"\n\n  ## the key within `flower.basicAuthSecret` containing the basic authentication string\n  ##\n  basicAuthSecretKey: \"\"\n\n  ## configs for the Service of the flower Pods\n  ##\n  service:\n    annotations: {}\n    type: ClusterIP\n    externalPort: 5555\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    nodePort:\n      http:\n\n  ## configs for the flower Pods' readinessProbe probe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n\n  ## configs for the flower Pods' liveness probe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n\n  ## extra pip packages to install in the flower Pod\n  ##\n  ## ____ EXAMPLE _______________\n  ##   extraPipPackages:\n  ##     - \"SomeProject==1.0.0\"\n  ##\n  extraPipPackages:\n  - \"apache-airflow-providers-apache-kafka\"\n  - \"apache-airflow-providers-mysql\"\n  - \"apache-airflow-providers-common-sql\"\n  - \"airflow-providers-clickhouse\"\n  - \"apache-airflow\"\n  - \"clickhouse-driver\"\n  - \"airflow-clickhouse-plugin\"\n  - \"airflow-provider-kafka\"\n  - \"influxdb-client\"\n  - \"pymongo\"\n  - \"pysnmp\"\n  - \"sqlalchemy\"\n  - \"boto3\"\n  - \"pysftp\"\n  - \"apache-airflow-providers-mongo\"\n  - \"snakebite\"\n  - \"pyarrow\"\n  - \"hdfs\"\n  - \"psycopg2-binary\"\n  - \"minio\"\n  - \"eloquent\"\n  - \"redis\"\n  - \"pandas\"\n  - \"mysql-connector-python\"\n  - \"requests\"\n  - \"datetime\"\n\n  ## extra VolumeMounts for the flower Pods\n  ## - spec for VolumeMount:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volumemount-v1-core\n  ##\n  extraVolumeMounts: []\n\n  ## extra Volumes for the flower Pods\n  ## - spec for Volume:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volume-v1-core\n  ##\n  extraVolumes: []\n\n\n\nlogs:\n  path: /opt/airflow/logs\n  persistence:\n    enabled: false\n    existingClaim: \"\"\n    subPath: \"\"\n    storageClass: \"\"\n    accessMode: ReadWriteMany\n    size: 5Gi\ndags:\n  path: /opt/airflow/dags\n  persistence:\n    enabled: false\n    existingClaim: \"\"\n    subPath: \"\"\n    storageClass: \"\"\n    accessMode: ReadOnlyMany\n    size: 1Gi\n  gitSync:\n    enabled: true\n    image:\n      repository: registry.k8s.io/git-sync/git-sync\n      tag: v3.6.5\n      pullPolicy: IfNotPresent\n      uid: 65533\n      gid: 65533\n    resources: {}\n    repo: \"https://github.com/Bifrost3-0/airflow-dags.git\"\n    repoSubPath: \"DAGS/Production\"\n    branch: main\n    revision: HEAD\n    depth: 1\n    syncWait: 60\n    syncTimeout: 120\n    submodules: recursive\n    httpSecret: airflow-git-https-secret\n    httpSecretUsernameKey: \"httpSecretUsernameKey\"\n    httpSecretPasswordKey: \"httpSecretPasswordKey\"\n    maxFailures: 0\ningress:\n  enabled: false\n  apiVersion: networking.k8s.io/v1\n  web:\n    annotations: {}\n    labels: {}\n    path: \"\"\n    host: \"192.168.36.90\"\n    ingressClassName: \"\"\n    tls:\n      enabled: false\n      secretName: \"\"\n    precedingPaths: []\n    succeedingPaths: []\n  flower:\n    annotations: {}\n\n    ## additional labels for the flower Ingress\n    ##\n    labels: {}\n\n    ## the path for the flower Ingress\n    ## - [WARNING] do NOT include the trailing slash (for root, set an empty string)\n    ##\n    ## ____ EXAMPLE _______________\n    ##   # flower URL: http://example.com/airflow/flower\n    ##   path: \"/airflow/flower\"\n    ##\n    path: \"\"\n\n    ## the hostname for the flower Ingress\n    ##\n    host: \"\"\n\n    ## the Ingress Class for the flower Ingress\n    ## - [WARNING] requires Kubernetes 1.18 or later, use \"kubernetes.io/ingress.class\" annotation for older versions\n    ##\n    ingressClassName: \"\"\n\n    ## configs for flower Ingress TLS\n    ##\n    tls:\n      ## enable TLS termination for the flower Ingress\n      ##\n      enabled: false\n\n      ## the name of a pre-created Secret containing a TLS private key and certificate\n      ##\n      secretName: \"\"\n\n    ## http paths to add to the flower Ingress before the default path\n    ##\n    ## ____ EXAMPLE _______________\n    ##   precedingPaths:\n    ##     - path: \"/*\"\n    ##       serviceName: \"my-service\"\n    ##       servicePort: \"port-name\"\n    ##\n    precedingPaths: []\n\n    ## http paths to add to the flower Ingress after the default path\n    ##\n    ## ____ EXAMPLE _______________\n    ##   succeedingPaths:\n    ##     - path: \"/extra-service\"\n    ##       serviceName: \"my-service\"\n    ##       servicePort: \"port-name\"\n    ##\n    succeedingPaths: []\n\n###################################\n## CONFIG | Kubernetes RBAC\n###################################\nrbac:\n  ## if Kubernetes RBAC resources are created\n  ## - these allow the service account to create/delete Pods in the airflow namespace,\n  ##   which is required for the KubernetesPodOperator() to function\n  ##\n  create: true\n\n  ## if the created RBAC Role has GET/LIST on Event resources\n  ## - this is needed for KubernetesPodOperator() to use `log_events_on_failure=True`\n  ##\n  events: true\n\n###################################\n## CONFIG | Kubernetes ServiceAccount\n###################################\nserviceAccount:\n  ## if a Kubernetes ServiceAccount is created\n  ## - if `false`, you must create the service account outside this chart with name: `serviceAccount.name`\n  ##\n  create: true\n\n  ## the name of the ServiceAccount\n  ## - by default the name is generated using the `airflow.serviceAccountName` template in `_helpers/common.tpl`\n  ##\n  name: \"\"\n\n  ## annotations for the ServiceAccount\n  ##\n  ## ____ EXAMPLE _______________\n  ##   # EKS - IAM Roles for Service Accounts\n  ##   annotations:\n  ##     eks.amazonaws.com/role-arn: \"arn:aws:iam::XXXXXXXXXX:role/\u003c\u003cMY-ROLE-NAME\u003e\u003e\"\n  ##\n  ## ____ EXAMPLE _______________\n  ##   # GKE - WorkloadIdentity\n  ##   annotations:\n  ##     iam.gke.io/gcp-service-account: \"\u003c\u003cGCP_SERVICE\u003e\u003e@\u003c\u003cGCP_PROJECT\u003e\u003e.iam.gserviceaccount.com\"\n  ##\n  annotations: {}\n\n###################################\n## CONFIG | Kubernetes Extra Manifests\n###################################\n## a list of extra Kubernetes manifests that will be deployed alongside the chart\n## - helm templates within these strings will be rendered\n##\n## ____ EXAMPLE _______________\n##   extraManifests:\n##     - |\n##       apiVersion: v1\n##       kind: Secret\n##       metadata:\n##         name: airflow-postgres\n##       data:\n##         postgresql-password: {{ `password1` | b64enc | quote }}\n##     - |\n##       apiVersion: apps/v1\n##       kind: Deployment\n##       metadata:\n##         name: {{ include \"airflow.fullname\" . }}-busybox\n##         labels:\n##           app: {{ include \"airflow.labels.app\" . }}\n##           component: busybox\n##           chart: {{ include \"airflow.labels.chart\" . }}\n##           release: {{ .Release.Name }}\n##           heritage: {{ .Release.Service }}\n##       spec:\n##         replicas: 1\n##         selector:\n##           matchLabels:\n##             app: {{ include \"airflow.labels.app\" . }}\n##             component: busybox\n##             release: {{ .Release.Name }}\n##         template:\n##           metadata:\n##             labels:\n##               app: {{ include \"airflow.labels.app\" . }}\n##               component: busybox\n##               release: {{ .Release.Name }}\n##           spec:\n##             containers:\n##               - name: busybox\n##                 image: busybox:1.35\n##                 command:\n##                   - \"/bin/sh\"\n##                   - \"-c\"\n##                 args:\n##                   - |\n##                     ## to break the infinite loop when we receive SIGTERM\n##                     trap \"exit 0\" SIGTERM;\n##                     ## keep the container running (so people can `kubectl exec -it` into it)\n##                     while true; do\n##                       echo \"I am alive...\";\n##                       sleep 30;\n##                     done\n##\nextraManifests: []\n\n###################################\n## DATABASE | PgBouncer\n###################################\npgbouncer:\n  ## if the pgbouncer Deployment is created\n  ##\n  enabled: true\n\n  ## configs for the pgbouncer container image\n  ##\n  image:\n    repository: ghcr.io/airflow-helm/pgbouncer\n    tag: 1.18.0-patch.1\n    pullPolicy: IfNotPresent\n    uid: 1001\n    gid: 1001\n\n  ## resource requests/limits for the pgbouncer Pods\n  ## - spec for ResourceRequirements:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n  ##\n  resources: {}\n\n  ## the nodeSelector configs for the pgbouncer Pods\n  ## - docs for nodeSelector:\n  ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n  ##\n  nodeSelector: {}\n\n  ## the affinity configs for the pgbouncer Pods\n  ## - spec for Affinity:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n  ##\n  affinity: {}\n\n  ## the toleration configs for the pgbouncer Pods\n  ## - spec for Toleration:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n  ##\n  tolerations: []\n\n  ## the security context for the pgbouncer Pods\n  ## - spec for PodSecurityContext:\n  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core\n  ##\n  securityContext: {}\n\n  ## Labels for the pgbouncer Deployment\n  ##\n  labels: {}\n\n  ## Pod labels for the pgbouncer Deployment\n  ##\n  podLabels: {}\n\n  ## annotations for the pgbouncer Deployment\n  ##\n  annotations: {}\n\n  ## Pod annotations for the pgbouncer Deployment\n  ##\n  podAnnotations: {}\n\n  ## if we add the annotation: \"cluster-autoscaler.kubernetes.io/safe-to-evict\" = \"true\"\n  ##\n  safeToEvict: true\n\n  ## configs for the PodDisruptionBudget of the pgbouncer Deployment\n  ##\n  podDisruptionBudget:\n    ## if a PodDisruptionBudget resource is created for the pgbouncer Deployment\n    ##\n    enabled: false\n\n    ## the `apiVersion` to use for PodDisruptionBudget resources\n    ## - for Kubernetes 1.21 and later: \"policy/v1\"\n    ## - for Kubernetes 1.20 and before: \"policy/v1beta1\"\n    ##\n    apiVersion: policy/v1\n\n    ## the maximum unavailable pods/percentage for the pgbouncer Deployment\n    ##\n    maxUnavailable:\n\n    ## the minimum available pods/percentage for the pgbouncer Deployment\n    ##\n    minAvailable:\n\n  ## configs for the pgbouncer Pods' liveness probe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 30\n    timeoutSeconds: 60\n    failureThreshold: 3\n\n  ## configs for the pgbouncer Pods' startup probe\n  ##\n  startupProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 15\n    failureThreshold: 30\n\n  ## the maximum number of seconds to wait for queries upon pod termination, before force killing\n  ##\n  terminationGracePeriodSeconds: 120\n\n  ## sets pgbouncer config: `auth_type`\n  ##\n  authType: md5\n\n  ## sets pgbouncer config: `max_client_conn`\n  ##\n  maxClientConnections: 1000\n\n  ## sets pgbouncer config: `default_pool_size`\n  ##\n  poolSize: 20\n\n  ## sets pgbouncer config: `log_disconnections`\n  ##\n  logDisconnections: 0\n\n  ## sets pgbouncer config: `log_connections`\n  ##\n  logConnections: 0\n\n  ## ssl configs for: clients -\u003e pgbouncer\n  ##\n  clientSSL:\n    ## sets pgbouncer config: `client_tls_sslmode`\n    ##\n    mode: prefer\n\n    ## sets pgbouncer config: `client_tls_ciphers`\n    ##\n    ciphers: normal\n\n    ## sets pgbouncer config: `client_tls_ca_file`\n    ##\n    caFile:\n      existingSecret: \"\"\n      existingSecretKey: root.crt\n\n    ## sets pgbouncer config: `client_tls_key_file`\n    ## - [WARNING] a self-signed cert \u0026 key are generated if left empty\n    ##\n    keyFile:\n      existingSecret: \"\"\n      existingSecretKey: client.key\n\n    ## sets pgbouncer config: `client_tls_cert_file`\n    ## - [WARNING] a self-signed cert \u0026 key are generated if left empty\n    ##\n    certFile:\n      existingSecret: \"\"\n      existingSecretKey: client.crt\n\n  ## ssl configs for: pgbouncer -\u003e postgres\n  ##\n  serverSSL:\n    ## sets pgbouncer config: `server_tls_sslmode`\n    ##\n    mode: prefer\n\n    ## sets pgbouncer config: `server_tls_ciphers`\n    ##\n    ciphers: normal\n\n    ## sets pgbouncer config: `server_tls_ca_file`\n    ##\n    caFile:\n      existingSecret: \"\"\n      existingSecretKey: root.crt\n\n    ## sets pgbouncer config: `server_tls_key_file`\n    ##\n    keyFile:\n      existingSecret: \"\"\n      existingSecretKey: server.key\n\n    ## sets pgbouncer config: `server_tls_cert_file`\n    ##\n    certFile:\n      existingSecret: \"\"\n      existingSecretKey: server.crt\n\n###################################\n## DATABASE | Embedded Postgres\n###################################\npostgresql:\n  ## if the `stable/postgresql` chart is used\n  ## - [WARNING] the embedded Postgres is NOT SUITABLE for production deployments of Airflow\n  ## - [WARNING] consider using an external database with `externalDatabase.*`\n  ## - set to `false` if using `externalDatabase.*`\n  ##\n  enabled: true\n  metrics:\n    enabled: true\n  ## configs for the postgres container image\n  ##\n  image:\n    registry: ghcr.io\n    repository: airflow-helm/postgresql-bitnami\n    tag: 11.16-patch.0\n    pullPolicy: IfNotPresent\n\n  ## the postgres database to use\n  ##\n  postgresqlDatabase: airflow\n\n  ## the postgres user to create\n  ##\n  postgresqlUsername: postgres\n\n  ## the postgres user's password\n  ##\n  postgresqlPassword: airflow\n\n  ## the name of a pre-created secret containing the postgres password\n  ##\n  existingSecret: \"\"\n\n  ## the key within `postgresql.existingSecret` containing the password string\n  ##\n  existingSecretKey: \"postgresql-password\"\n\n  ## configs for the PVC of postgresql\n  ##\n  persistence:\n    ## if postgres will use Persistent Volume Claims to store data\n    ## - [WARNING] if false, data will be LOST as postgres Pods restart\n    ##\n    enabled: true\n\n    ## the name of the StorageClass used by the PVC\n    ##\n    storageClass: \"\"\n\n    ## the access modes of the PVC\n    ##\n    accessModes:\n    - ReadWriteOnce\n\n    ## the size of PVC to request\n    ##\n    size: 25Gi\n\n  ## configs for the postgres StatefulSet\n  ##\n  master:\n    ## the nodeSelector configs for the postgres Pods\n    ## - docs for nodeSelector:\n    ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n    ##\n    nodeSelector: {}\n\n    ## the affinity configs for the postgres Pods\n    ## - spec for Affinity:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n    ##\n    affinity: {}\n\n    ## the toleration configs for the postgres Pods\n    ## - spec for Toleration:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n    ##\n    tolerations: []\n\n    ## annotations for the postgres Pods\n    ##\n    podAnnotations:\n      cluster-autoscaler.kubernetes.io/safe-to-evict: \"true\"\n\n###################################\n## DATABASE | External Database\n###################################\nexternalDatabase:\n  ## the type of external database\n  ## - allowed values: \"mysql\", \"postgres\"\n  ##\n  type: postgres\n\n  ## the host of the external database\n  ##\n  host: localhost\n\n  ## the port of the external database\n  ##\n  port: 5432\n\n  ## the database/scheme to use within the external database\n  ##\n  database: airflow\n\n  ## the username for the external database\n  ##\n  user: airflow\n\n  ## the name of a pre-created secret containing the external database user\n  ## - if set, this overrides `externalDatabase.user`\n  ##\n  userSecret: \"\"\n\n  ## the key within `externalDatabase.userSecret` containing the user string\n  ##\n  userSecretKey: \"postgresql-user\"\n\n  ## the password for the external database\n  ## - [WARNING] to avoid storing the password in plain-text within your values,\n  ##   create a Kubernetes secret and use `externalDatabase.passwordSecret`\n  ##\n  password: \"\"\n\n  ## the name of a pre-created secret containing the external database password\n  ## - if set, this overrides `externalDatabase.password`\n  ##\n  passwordSecret: \"\"\n\n  ## the key within `externalDatabase.passwordSecret` containing the password string\n  ##\n  passwordSecretKey: \"postgresql-password\"\n\n  ## extra connection-string properties for the external database\n  ##\n  ## ____ EXAMPLE _______________\n  ##   # require SSL (only for Postgres)\n  ##   properties: \"?sslmode=require\"\n  ##\n  properties: \"\"\n\n###################################\n## DATABASE | Embedded Redis\n###################################\nredis:\n  ## if the `stable/redis` chart is used\n  ## - set to `false` if `airflow.executor` is `KubernetesExecutor`\n  ## - set to `false` if using `externalRedis.*`\n  ##\n  enabled: true\n\n  ## configs for the redis container image\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/redis\n    tag: 5.0.14-debian-10-r173\n    pullPolicy: IfNotPresent\n\n  ## the redis password\n  ##\n  password: airflow\n\n  ## the name of a pre-created secret containing the redis password\n  ##\n  existingSecret: \"\"\n\n  ## the key within `redis.existingSecret` containing the password string\n  ##\n  existingSecretPasswordKey: \"redis-password\"\n\n  ## configs for redis cluster mode\n  ##\n  cluster:\n    ## if redis runs in cluster mode\n    ##\n    enabled: false\n\n    ## the number of redis slaves\n    ##\n    slaveCount: 1\n\n  ## configs for the redis master StatefulSet\n  ##\n  master:\n    ## resource requests/limits for the redis master Pods\n    ## - spec for ResourceRequirements:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n    ##\n    resources: {}\n\n    ## the nodeSelector configs for the redis master Pods\n    ## - docs for nodeSelector:\n    ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n    ##\n    nodeSelector: {}\n\n    ## the affinity configs for the redis master Pods\n    ## - spec for Affinity:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n    ##\n    affinity: {}\n\n    ## the toleration configs for the redis master Pods\n    ## - spec for Toleration:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n    ##\n    tolerations: []\n\n    ## annotations for the redis master Pods\n    ##\n    podAnnotations:\n      cluster-autoscaler.kubernetes.io/safe-to-evict: \"true\"\n\n    ## configs for the PVC of the redis master Pods\n    ##\n    persistence:\n      ## use a PVC to persist data\n      ##\n      enabled: false\n\n      ## the name of the StorageClass used by the PVC\n      ##\n      storageClass: \"\"\n\n      ## the access mode of the PVC\n      ##\n      accessModes:\n      - ReadWriteOnce\n\n      ## the size of PVC to request\n      ##\n      size: 8Gi\n\n  ## configs for the redis slave StatefulSet\n  ## - only used if `redis.cluster.enabled` is `true`\n  ##\n  slave:\n    ## resource requests/limits for the slave Pods\n    ## - spec for ResourceRequirements:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core\n    ##\n    resources: {}\n\n    ## the nodeSelector configs for the redis slave Pods\n    ## - docs for nodeSelector:\n    ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n    ##\n    nodeSelector: {}\n\n    ## the affinity configs for the redis slave Pods\n    ## - spec for Affinity:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core\n    ##\n    affinity: {}\n\n    ## the toleration configs for the redis slave Pods\n    ## - spec for Toleration:\n    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core\n    ##\n    tolerations: []\n\n    ## annotations for the slave Pods\n    ##\n    podAnnotations:\n      cluster-autoscaler.kubernetes.io/safe-to-evict: \"true\"\n\n    ## configs for the PVC of the redis slave Pods\n    ##\n    persistence:\n      ## use a PVC to persist data\n      ##\n      enabled: false\n\n      ## the name of the StorageClass used by the PVC\n      ##\n      storageClass: \"\"\n\n      ## the access mode of the PVC\n      ##\n      accessModes:\n      - ReadWriteOnce\n\n      ## the size of PVC to request\n      ##\n      size: 8Gi\n\n###################################\n## DATABASE | External Redis\n###################################\nexternalRedis:\n  ## the host of the external redis\n  ##\n  host: localhost\n\n  ## the port of the external redis\n  ##\n  port: 6379\n\n  ## the database number to use within the external redis\n  ##\n  databaseNumber: 1\n\n  ## the password for the external redis\n  ## - [WARNING] to avoid storing the password in plain-text within your values,\n  ##   create a Kubernetes secret and use `externalRedis.passwordSecret`\n  ##\n  password: \"\"\n\n  ## the name of a pre-created secret containing the external redis password\n  ## - if set, this overrides `externalRedis.password`\n  ##\n  passwordSecret: \"\"\n\n  ## the key within `externalRedis.passwordSecret` containing the password string\n  ##\n  passwordSecretKey: \"redis-password\"\n\n  ## extra connection-string properties for the external redis\n  ##\n  ## ____ EXAMPLE _______________\n  ##   properties: \"?ssl_cert_reqs=CERT_OPTIONAL\"\n  ##\n  properties: \"\"\n\n###################################\n## CONFIG | ServiceMonitor (Prometheus Operator)\n###################################\nserviceMonitor:\n  ## if ServiceMonitor resources should be deployed for airflow webserver\n  ## - [WARNING] you will need a metrics exporter in your `airflow.image`, for example:\n  ##   https://github.com/epoch8/airflow-exporter\n  ## - ServiceMonitor is a resource from prometheus-operator:\n  ##   https://github.com/prometheus-operator/prometheus-operator\n  ##\n  enabled: false\n\n  ## labels for ServiceMonitor, so that Prometheus can select it\n  ##\n  selector:\n    prometheus: kube-prometheus\n\n  ## the ServiceMonitor web endpoint path\n  ##\n  path: /admin/metrics\n\n  ## the ServiceMonitor web endpoint interval\n  ##\n  interval: \"30s\"\n\n###################################\n## CONFIG | PrometheusRule (Prometheus Operator)\n###################################\nprometheusRule:\n  ## if PrometheusRule resources should be deployed for airflow webserver\n  ## - [WARNING] you will need a metrics exporter in your `airflow.image`, for example:\n  ##   https://github.com/epoch8/airflow-exporter\n  ## - PrometheusRule is a resource from prometheus-operator:\n  ##   https://github.com/prometheus-operator/prometheus-operator\n  ##\n  enabled: false\n\n  ## labels for PrometheusRule, so that Prometheus can select it\n  ##\n  additionalLabels: {}\n\n  ## alerting rules for Prometheus\n  ## - docs for alerting rules: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/\n  ##\n  groups: []\n"
            ],
            "verify": false,
            "version": "8.9.0",
            "wait": false,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_namespace.datalake_ns-namespace",
            "kubernetes_secret_v1.airflow"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "airflow_production",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "airflow",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "airflow-v3",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "2.8.3",
                "chart": "airflow",
                "name": "airflow-v3",
                "namespace": "datalake",
                "revision": 2,
                "values": "{\"affinity\":{},\"airflowConfigAnnotations\":{},\"airflowHome\":\"/opt/airflow\",\"airflowLocalSettings\":\"{{- if semverCompare \\\"\\u003e=2.2.0\\\" .Values.airflowVersion }}\\n{{- if not (or .Values.webserverSecretKey .Values.webserverSecretKeySecretName) }}\\nfrom airflow.www.utils import UIAlert\\n\\nDASHBOARD_UIALERTS = [\\n  UIAlert(\\n    'Usage of a dynamic webserver secret key detected. We recommend a static webserver secret key instead.'\\n    ' See the \\u003ca href='\\n    '\\\"https://airflow.apache.org/docs/helm-chart/stable/production-guide.html#webserver-secret-key\\\"\\u003e'\\n    'Helm Chart Production Guide\\u003c/a\\u003e for more details.',\\n    category=\\\"warning\\\",\\n    roles=[\\\"Admin\\\"],\\n    html=True,\\n  )\\n]\\n{{- end }}\\n{{- end }}\",\"airflowPodAnnotations\":{},\"airflowVersion\":\"2.8.3\",\"allowPodLaunching\":true,\"cleanup\":{\"affinity\":{},\"args\":[\"bash\",\"-c\",\"exec airflow kubernetes cleanup-pods --namespace={{ .Release.Namespace }}\"],\"command\":null,\"containerLifecycleHooks\":{},\"enabled\":true,\"env\":[],\"failedJobsHistoryLimit\":null,\"jobAnnotations\":{},\"labels\":{},\"nodeSelector\":{\"airflow-node\":\"true\"},\"podAnnotations\":{},\"resources\":{},\"schedule\":\"*/15 * * * *\",\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"successfulJobsHistoryLimit\":null,\"tolerations\":[],\"topologySpreadConstraints\":[]},\"config\":{\"celery\":{\"flower_url_prefix\":\"{{ ternary \\\"\\\" .Values.ingress.flower.path (eq .Values.ingress.flower.path \\\"/\\\") }}\",\"worker_concurrency\":16},\"celery_kubernetes_executor\":{\"kubernetes_queue\":\"kubernetes\"},\"core\":{\"colored_console_log\":\"True\",\"dags_folder\":\"{{ include \\\"airflow_dags\\\" . }}\",\"executor\":\"{{ .Values.executor }}\",\"load_examples\":\"False\",\"remote_logging\":\"{{- ternary \\\"True\\\" \\\"False\\\" .Values.elasticsearch.enabled }}\"},\"elasticsearch\":{\"json_format\":\"True\",\"log_id_template\":\"{dag_id}_{task_id}_{execution_date}_{try_number}\"},\"elasticsearch_configs\":{\"max_retries\":3,\"retry_timeout\":\"True\",\"timeout\":30},\"kerberos\":{\"ccache\":\"{{ .Values.kerberos.ccacheMountPath }}/{{ .Values.kerberos.ccacheFileName }}\",\"keytab\":\"{{ .Values.kerberos.keytabPath }}\",\"principal\":\"{{ .Values.kerberos.principal }}\",\"reinit_frequency\":\"{{ .Values.kerberos.reinitFrequency }}\"},\"kubernetes\":{\"airflow_configmap\":\"{{ include \\\"airflow_config\\\" . }}\",\"airflow_local_settings_configmap\":\"{{ include \\\"airflow_config\\\" . }}\",\"multi_namespace_mode\":\"{{ ternary \\\"True\\\" \\\"False\\\" .Values.multiNamespaceMode }}\",\"namespace\":\"{{ .Release.Namespace }}\",\"pod_template_file\":\"{{ include \\\"airflow_pod_template_file\\\" . }}/pod_template_file.yaml\",\"worker_container_repository\":\"{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}\",\"worker_container_tag\":\"{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}\"},\"kubernetes_executor\":{\"multi_namespace_mode\":\"{{ ternary \\\"True\\\" \\\"False\\\" .Values.multiNamespaceMode }}\",\"namespace\":\"{{ .Release.Namespace }}\",\"pod_template_file\":\"{{ include \\\"airflow_pod_template_file\\\" . }}/pod_template_file.yaml\",\"worker_container_repository\":\"{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}\",\"worker_container_tag\":\"{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}\"},\"logging\":{\"colored_console_log\":\"True\",\"remote_logging\":\"{{- ternary \\\"True\\\" \\\"False\\\" .Values.elasticsearch.enabled }}\"},\"metrics\":{\"statsd_host\":\"{{ printf \\\"%s-statsd\\\" (include \\\"airflow.fullname\\\" .) }}\",\"statsd_on\":\"{{ ternary \\\"True\\\" \\\"False\\\" .Values.statsd.enabled }}\",\"statsd_port\":9125,\"statsd_prefix\":\"airflow\"},\"scheduler\":{\"run_duration\":41460,\"standalone_dag_processor\":\"{{ ternary \\\"True\\\" \\\"False\\\" .Values.dagProcessor.enabled }}\",\"statsd_host\":\"{{ printf \\\"%s-statsd\\\" (include \\\"airflow.fullname\\\" .) }}\",\"statsd_on\":\"{{ ternary \\\"True\\\" \\\"False\\\" .Values.statsd.enabled }}\",\"statsd_port\":9125,\"statsd_prefix\":\"airflow\"},\"triggerer\":{\"default_capacity\":1000},\"webserver\":{\"enable_proxy_fix\":\"True\",\"rbac\":\"True\"}},\"containerLifecycleHooks\":{},\"createUserJob\":{\"affinity\":{},\"annotations\":{},\"applyCustomEnv\":true,\"args\":[\"bash\",\"-c\",\"exec \\\\\\nairflow {{ semverCompare \\\"\\u003e=2.0.0\\\" .Values.airflowVersion | ternary \\\"users create\\\" \\\"create_user\\\" }} \\\"$@\\\"\",\"--\",\"-r\",\"{{ .Values.webserver.defaultUser.role }}\",\"-u\",\"{{ .Values.webserver.defaultUser.username }}\",\"-e\",\"{{ .Values.webserver.defaultUser.email }}\",\"-f\",\"{{ .Values.webserver.defaultUser.firstName }}\",\"-l\",\"{{ .Values.webserver.defaultUser.lastName }}\",\"-p\",\"{{ .Values.webserver.defaultUser.password }}\"],\"command\":null,\"containerLifecycleHooks\":{},\"env\":[],\"extraContainers\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"jobAnnotations\":{},\"labels\":{},\"nodeSelector\":{\"airflow-node\":\"true\"},\"resources\":{},\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"tolerations\":[],\"topologySpreadConstraints\":[],\"ttlSecondsAfterFinished\":300,\"useHelmHooks\":true},\"dagProcessor\":{\"affinity\":{},\"annotations\":{},\"args\":[\"bash\",\"-c\",\"exec airflow dag-processor\"],\"command\":null,\"containerLifecycleHooks\":{},\"enabled\":true,\"env\":[],\"extraContainers\":[],\"extraInitContainers\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"livenessProbe\":{\"command\":null,\"failureThreshold\":5,\"initialDelaySeconds\":10,\"periodSeconds\":60,\"timeoutSeconds\":20},\"logGroomerSidecar\":{\"args\":[\"bash\",\"/clean-logs\"],\"command\":null,\"enabled\":true,\"resources\":{},\"retentionDays\":15,\"securityContexts\":{\"container\":{}}},\"nodeSelector\":{\"airflow-node\":\"true\"},\"podAnnotations\":{},\"priorityClassName\":null,\"replicas\":12,\"resources\":{},\"revisionHistoryLimit\":null,\"safeToEvict\":true,\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"strategy\":{\"rollingUpdate\":{\"maxSurge\":\"100%\",\"maxUnavailable\":\"50%\"}},\"terminationGracePeriodSeconds\":60,\"tolerations\":[],\"topologySpreadConstraints\":[],\"waitForMigrations\":{\"enabled\":true,\"env\":[],\"securityContexts\":{\"container\":{}}}},\"dags\":{\"gitSync\":{\"branch\":\"main\",\"containerLifecycleHooks\":{},\"containerName\":\"git-sync\",\"credentialsSecret\":\"git-credentials\",\"depth\":1,\"enabled\":true,\"env\":[],\"extraVolumeMounts\":[],\"maxFailures\":0,\"period\":\"5s\",\"ref\":\"v1.0.0\",\"repo\":\"https://github.com/Bifrost3-0/airflow_bifrost\",\"resources\":{},\"rev\":\"HEAD\",\"securityContext\":{},\"securityContexts\":{\"container\":{}},\"subPath\":\"production/dags\",\"uid\":65533,\"wait\":null},\"mountPath\":null,\"persistence\":{\"accessMode\":\"ReadWriteOnce\",\"annotations\":{},\"enabled\":false,\"existingClaim\":null,\"size\":\"1Gi\",\"storageClassName\":null,\"subPath\":null}},\"data\":{\"brokerUrl\":null,\"brokerUrlSecretName\":null,\"metadataConnection\":{\"db\":\"hdfs\",\"host\":\"postgres-airflow-postgresql.datalake.svc.cluster.local\",\"pass\":\"Maniac321.\",\"port\":5432,\"protocol\":\"postgresql\",\"sslmode\":\"disable\",\"user\":\"hdfs\"},\"metadataSecretName\":null,\"resultBackendConnection\":null,\"resultBackendSecretName\":null},\"defaultAirflowDigest\":null,\"defaultAirflowRepository\":\"apache/airflow\",\"defaultAirflowTag\":\"2.8.3\",\"elasticsearch\":{\"connection\":{},\"enabled\":false,\"secretName\":null},\"enableBuiltInSecretEnvVars\":{\"AIRFLOW_CONN_AIRFLOW_DB\":true,\"AIRFLOW__CELERY__BROKER_URL\":true,\"AIRFLOW__CELERY__CELERY_RESULT_BACKEND\":true,\"AIRFLOW__CELERY__RESULT_BACKEND\":true,\"AIRFLOW__CORE__FERNET_KEY\":true,\"AIRFLOW__CORE__SQL_ALCHEMY_CONN\":true,\"AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\":true,\"AIRFLOW__ELASTICSEARCH__ELASTICSEARCH_HOST\":true,\"AIRFLOW__ELASTICSEARCH__HOST\":true,\"AIRFLOW__WEBSERVER__SECRET_KEY\":true},\"env\":[{\"name\":\"AIRFLOW_CONN_MYSQLPRD\",\"value\":\"mysql+mysqlconnector://root:q%7DIb%5DDg7QVEi08VXN%7E%28@192.168.29.9/bifrost_auth\"}],\"executor\":\"CeleryExecutor\",\"extraConfigMaps\":{},\"extraEnv\":null,\"extraEnvFrom\":null,\"extraSecrets\":{},\"fernetKey\":null,\"fernetKeySecretName\":null,\"flower\":{\"affinity\":{},\"annotations\":{},\"args\":[\"bash\",\"-c\",\"exec \\\\\\nairflow {{ semverCompare \\\"\\u003e=2.0.0\\\" .Values.airflowVersion | ternary \\\"celery flower\\\" \\\"flower\\\" }}\"],\"command\":null,\"containerLifecycleHooks\":{},\"enabled\":false,\"env\":[],\"extraContainers\":[],\"extraNetworkPolicies\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"labels\":{},\"livenessProbe\":{\"failureThreshold\":10,\"initialDelaySeconds\":10,\"periodSeconds\":5,\"timeoutSeconds\":5},\"networkPolicy\":{\"ingress\":{\"from\":[],\"ports\":[{\"port\":\"{{ .Values.ports.flowerUI }}\"}]}},\"nodeSelector\":{\"airflow-node\":\"true\"},\"password\":null,\"podAnnotations\":{},\"priorityClassName\":null,\"readinessProbe\":{\"failureThreshold\":10,\"initialDelaySeconds\":10,\"periodSeconds\":5,\"timeoutSeconds\":5},\"resources\":{},\"revisionHistoryLimit\":null,\"secretName\":null,\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"service\":{\"annotations\":{},\"loadBalancerIP\":null,\"loadBalancerSourceRanges\":[],\"ports\":[{\"name\":\"flower-ui\",\"port\":\"{{ .Values.ports.flowerUI }}\"}],\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"tolerations\":[],\"topologySpreadConstraints\":[],\"username\":null},\"fullnameOverride\":\"\",\"gid\":0,\"images\":{\"airflow\":{\"digest\":null,\"pullPolicy\":\"IfNotPresent\",\"repository\":\"jackt72xp/airflow\",\"tag\":\"v1\"},\"flower\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":null,\"tag\":null},\"gitSync\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"registry.k8s.io/git-sync/git-sync\",\"tag\":\"v4.1.0\"},\"migrationsWaitTimeout\":60,\"pgbouncer\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"apache/airflow\",\"tag\":\"airflow-pgbouncer-2024.01.19-1.21.0\"},\"pgbouncerExporter\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"apache/airflow\",\"tag\":\"airflow-pgbouncer-exporter-2024.01.19-0.16.0\"},\"pod_template\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":null,\"tag\":null},\"redis\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"redis\",\"tag\":\"7-bookworm\"},\"statsd\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"quay.io/prometheus/statsd-exporter\",\"tag\":\"v0.26.0\"},\"useDefaultImageForMigration\":false},\"ingress\":{\"enabled\":null,\"flower\":{\"annotations\":{},\"enabled\":true,\"host\":\"\",\"hosts\":[],\"ingressClassName\":\"\",\"path\":\"/\",\"pathType\":\"ImplementationSpecific\",\"tls\":{\"enabled\":false,\"secretName\":\"\"}},\"web\":{\"annotations\":{},\"enabled\":false,\"host\":\"\",\"hosts\":[],\"ingressClassName\":\"\",\"path\":\"/\",\"pathType\":\"ImplementationSpecific\",\"precedingPaths\":[],\"succeedingPaths\":[],\"tls\":{\"enabled\":false,\"secretName\":\"\"}}},\"kerberos\":{\"ccacheFileName\":\"cache\",\"ccacheMountPath\":\"/var/kerberos-ccache\",\"config\":\"# This is an example config showing how you can use templating and how \\\"example\\\" config\\n# might look like. It works with the test kerberos server that we are using during integration\\n# testing at Apache Airflow (see `scripts/ci/docker-compose/integration-kerberos.yml` but in\\n# order to make it production-ready you must replace it with your own configuration that\\n# Matches your kerberos deployment. Administrators of your Kerberos instance should\\n# provide the right configuration.\\n\\n[logging]\\ndefault = \\\"FILE:{{ template \\\"airflow_logs_no_quote\\\" . }}/kerberos_libs.log\\\"\\nkdc = \\\"FILE:{{ template \\\"airflow_logs_no_quote\\\" . }}/kerberos_kdc.log\\\"\\nadmin_server = \\\"FILE:{{ template \\\"airflow_logs_no_quote\\\" . }}/kadmind.log\\\"\\n\\n[libdefaults]\\ndefault_realm = FOO.COM\\nticket_lifetime = 10h\\nrenew_lifetime = 7d\\nforwardable = true\\n\\n[realms]\\nFOO.COM = {\\n  kdc = kdc-server.foo.com\\n  admin_server = admin_server.foo.com\\n}\\n\",\"configPath\":\"/etc/krb5.conf\",\"enabled\":false,\"keytabBase64Content\":null,\"keytabPath\":\"/etc/airflow.keytab\",\"principal\":\"airflow@FOO.COM\",\"reinitFrequency\":3600},\"labels\":{},\"limits\":[],\"logs\":{\"persistence\":{\"annotations\":{},\"enabled\":false,\"existingClaim\":null,\"size\":\"100Gi\",\"storageClassName\":null}},\"migrateDatabaseJob\":{\"affinity\":{},\"annotations\":{},\"applyCustomEnv\":true,\"args\":[\"bash\",\"-c\",\"exec \\\\\\nairflow {{ semverCompare \\\"\\u003e=2.7.0\\\" .Values.airflowVersion | ternary \\\"db migrate\\\" (semverCompare \\\"\\u003e=2.0.0\\\" .Values.airflowVersion | ternary \\\"db upgrade\\\" \\\"upgradedb\\\") }}\"],\"command\":null,\"containerLifecycleHooks\":{},\"enabled\":true,\"extraContainers\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"jobAnnotations\":{},\"labels\":{},\"nodeSelector\":{\"airflow-node\":\"true\"},\"resources\":{},\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"tolerations\":[],\"topologySpreadConstraints\":[],\"ttlSecondsAfterFinished\":300,\"useHelmHooks\":true},\"multiNamespaceMode\":false,\"nameOverride\":\"\",\"networkPolicies\":{\"enabled\":false},\"nodeSelector\":{\"airflow-node\":\"true\"},\"pgbouncer\":{\"affinity\":{},\"annotations\":{},\"args\":null,\"auth_file\":\"/etc/pgbouncer/users.txt\",\"auth_type\":\"scram-sha-256\",\"ciphers\":\"normal\",\"command\":[\"pgbouncer\",\"-u\",\"nobody\",\"/etc/pgbouncer/pgbouncer.ini\"],\"configSecretName\":null,\"containerLifecycleHooks\":{\"preStop\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"killall -INT pgbouncer \\u0026\\u0026 sleep 120\"]}}},\"enabled\":false,\"env\":[],\"extraContainers\":[],\"extraIni\":null,\"extraIniMetadata\":null,\"extraIniResultBackend\":null,\"extraNetworkPolicies\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"logConnections\":0,\"logDisconnections\":0,\"maxClientConn\":100,\"metadataPoolSize\":10,\"metricsExporterSidecar\":{\"containerLifecycleHooks\":{},\"livenessProbe\":{\"initialDelaySeconds\":10,\"periodSeconds\":10,\"timeoutSeconds\":1},\"readinessProbe\":{\"initialDelaySeconds\":10,\"periodSeconds\":10,\"timeoutSeconds\":1},\"resources\":{},\"securityContexts\":{\"container\":{}},\"sslmode\":\"disable\",\"statsSecretKey\":null,\"statsSecretName\":null},\"nodeSelector\":{\"airflow-node\":\"true\"},\"podAnnotations\":{},\"podDisruptionBudget\":{\"config\":{\"maxUnavailable\":1},\"enabled\":false},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"resultBackendPoolSize\":5,\"revisionHistoryLimit\":null,\"securityContexts\":{\"container\":{},\"pod\":{}},\"service\":{\"extraAnnotations\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"ssl\":{\"ca\":null,\"cert\":null,\"key\":null},\"sslmode\":\"prefer\",\"tolerations\":[],\"topologySpreadConstraints\":[],\"uid\":65534,\"verbose\":0},\"podTemplate\":null,\"ports\":{\"airflowUI\":8080,\"flowerUI\":5555,\"pgbouncer\":6543,\"pgbouncerScrape\":9127,\"redisDB\":6379,\"statsdIngest\":9125,\"statsdScrape\":9102,\"triggererLogs\":8794,\"workerLogs\":8793},\"postgresql\":{\"auth\":{\"enablePostgresUser\":true,\"password\":\"\",\"postgresPassword\":\"postgres\",\"username\":\"\"},\"enabled\":false},\"priorityClasses\":[],\"quotas\":{},\"rbac\":{\"create\":true,\"createSCCRoleBinding\":false},\"redis\":{\"affinity\":{},\"containerLifecycleHooks\":{},\"enabled\":true,\"nodeSelector\":{\"airflow-node\":\"true\"},\"password\":null,\"passwordSecretName\":null,\"persistence\":{\"annotations\":{},\"enabled\":true,\"size\":\"1Gi\",\"storageClassName\":null},\"podAnnotations\":{},\"priorityClassName\":null,\"resources\":{},\"safeToEvict\":true,\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"terminationGracePeriodSeconds\":600,\"tolerations\":[],\"topologySpreadConstraints\":[],\"uid\":0},\"registry\":{\"connection\":{},\"secretName\":null},\"revisionHistoryLimit\":null,\"scheduler\":{\"affinity\":{},\"annotations\":{},\"args\":[\"bash\",\"-c\",\"exec airflow scheduler\"],\"command\":null,\"containerLifecycleHooks\":{},\"enabled\":true,\"env\":[],\"extraContainers\":[],\"extraInitContainers\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"labels\":{},\"livenessProbe\":{\"command\":null,\"failureThreshold\":5,\"initialDelaySeconds\":10,\"periodSeconds\":60,\"timeoutSeconds\":20},\"logGroomerSidecar\":{\"args\":[\"bash\",\"/clean-logs\"],\"command\":null,\"containerLifecycleHooks\":{},\"enabled\":true,\"resources\":{},\"retentionDays\":15,\"securityContexts\":{\"container\":{}}},\"nodeSelector\":{\"airflow-node\":\"true\"},\"podAnnotations\":{},\"podDisruptionBudget\":{\"config\":{\"maxUnavailable\":1},\"enabled\":false},\"priorityClassName\":null,\"replicas\":20,\"resources\":{},\"revisionHistoryLimit\":null,\"safeToEvict\":true,\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"startupProbe\":{\"command\":null,\"failureThreshold\":6,\"periodSeconds\":10,\"timeoutSeconds\":20},\"strategy\":null,\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategy\":null,\"waitForMigrations\":{\"enabled\":true,\"env\":[],\"securityContexts\":{\"container\":{}}}},\"schedulerName\":null,\"secret\":[],\"securityContext\":{},\"securityContexts\":{\"containers\":{},\"pod\":{}},\"statsd\":{\"affinity\":{},\"annotations\":{},\"args\":[\"--statsd.mapping-config=/etc/statsd-exporter/mappings.yml\"],\"configMapAnnotations\":{},\"containerLifecycleHooks\":{},\"enabled\":true,\"env\":[],\"extraMappings\":[],\"extraNetworkPolicies\":[],\"nodeSelector\":{\"airflow-node\":\"true\"},\"overrideMappings\":[],\"podAnnotations\":{},\"priorityClassName\":null,\"resources\":{},\"revisionHistoryLimit\":null,\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"service\":{\"extraAnnotations\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"tolerations\":[],\"topologySpreadConstraints\":[],\"uid\":65534},\"tolerations\":[],\"topologySpreadConstraints\":[],\"triggerer\":{\"affinity\":{},\"annotations\":{},\"args\":[\"bash\",\"-c\",\"exec airflow triggerer\"],\"command\":null,\"containerLifecycleHooks\":{},\"enabled\":true,\"env\":[],\"extraContainers\":[],\"extraInitContainers\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"keda\":{\"advanced\":{},\"cooldownPeriod\":30,\"enabled\":false,\"maxReplicaCount\":10,\"minReplicaCount\":0,\"namespaceLabels\":{},\"pollingInterval\":5,\"query\":\"SELECT ceil(COUNT(*)::decimal / {{ .Values.config.triggerer.default_capacity }}) FROM trigger\"},\"labels\":{},\"livenessProbe\":{\"command\":null,\"failureThreshold\":5,\"initialDelaySeconds\":10,\"periodSeconds\":60,\"timeoutSeconds\":20},\"logGroomerSidecar\":{\"args\":[\"bash\",\"/clean-logs\"],\"command\":null,\"containerLifecycleHooks\":{},\"enabled\":true,\"resources\":{},\"retentionDays\":15,\"securityContexts\":{\"container\":{}}},\"nodeSelector\":{\"airflow-node\":\"true\"},\"persistence\":{\"annotations\":{},\"enabled\":true,\"fixPermissions\":false,\"size\":\"100Gi\",\"storageClassName\":null},\"podAnnotations\":{},\"priorityClassName\":null,\"replicas\":15,\"resources\":{},\"revisionHistoryLimit\":null,\"safeToEvict\":true,\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"strategy\":{\"rollingUpdate\":{\"maxSurge\":\"100%\",\"maxUnavailable\":\"50%\"}},\"terminationGracePeriodSeconds\":60,\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategy\":null,\"waitForMigrations\":{\"enabled\":true,\"env\":[],\"securityContexts\":{\"container\":{}}}},\"uid\":50000,\"useStandardNaming\":true,\"volumeMounts\":[],\"volumes\":[],\"webserver\":{\"affinity\":{},\"allowPodLogReading\":true,\"annotations\":{},\"args\":[\"bash\",\"-c\",\"exec airflow webserver\"],\"command\":null,\"configMapAnnotations\":{},\"containerLifecycleHooks\":{},\"defaultUser\":{\"email\":\"admin@example.com\",\"enabled\":true,\"firstName\":\"admin\",\"lastName\":\"user\",\"password\":\"admin\",\"role\":\"Admin\",\"username\":\"admin\"},\"enabled\":true,\"env\":[],\"extraContainers\":[],\"extraInitContainers\":[],\"extraNetworkPolicies\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"labels\":{},\"livenessProbe\":{\"failureThreshold\":5,\"initialDelaySeconds\":15,\"periodSeconds\":10,\"scheme\":\"HTTP\",\"timeoutSeconds\":5},\"networkPolicy\":{\"ingress\":{\"from\":[],\"ports\":[{\"port\":\"{{ .Values.ports.airflowUI }}\"}]}},\"nodeSelector\":{\"airflow-node\":\"true\"},\"podAnnotations\":{},\"podDisruptionBudget\":{\"config\":{\"maxUnavailable\":1},\"enabled\":false},\"priorityClassName\":null,\"readinessProbe\":{\"failureThreshold\":5,\"initialDelaySeconds\":15,\"periodSeconds\":10,\"scheme\":\"HTTP\",\"timeoutSeconds\":5},\"replicas\":1,\"resources\":{},\"revisionHistoryLimit\":null,\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"service\":{\"annotations\":{},\"loadBalancerIP\":null,\"loadBalancerSourceRanges\":[],\"ports\":[{\"name\":\"airflow-ui\",\"port\":\"{{ .Values.ports.airflowUI }}\"}],\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"startupProbe\":{\"failureThreshold\":6,\"periodSeconds\":10,\"scheme\":\"HTTP\",\"timeoutSeconds\":20},\"strategy\":null,\"tolerations\":[],\"topologySpreadConstraints\":[],\"waitForMigrations\":{\"enabled\":true,\"env\":[],\"securityContexts\":{\"container\":{}}},\"webserverConfig\":null,\"webserverConfigConfigMapName\":null},\"webserverSecretKey\":null,\"webserverSecretKeySecretName\":null,\"workers\":{\"affinity\":{},\"annotations\":{},\"args\":[\"bash\",\"-c\",\"exec \\\\\\nairflow {{ semverCompare \\\"\\u003e=2.0.0\\\" .Values.airflowVersion | ternary \\\"celery worker\\\" \\\"worker\\\" }}\"],\"command\":null,\"containerLifecycleHooks\":{},\"env\":[],\"extraContainers\":[],\"extraInitContainers\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[{\"ip\":\"192.168.36.99\"}],\"hpa\":{\"behavior\":{},\"enabled\":true,\"maxReplicaCount\":40,\"metrics\":[{\"resource\":{\"name\":\"cpu\",\"target\":{\"averageUtilization\":75,\"type\":\"Utilization\"}},\"type\":\"Resource\"}],\"minReplicaCount\":15},\"keda\":{\"advanced\":{},\"cooldownPeriod\":30,\"enabled\":false,\"maxReplicaCount\":10,\"minReplicaCount\":0,\"namespaceLabels\":{},\"pollingInterval\":5,\"query\":\"SELECT ceil(COUNT(*)::decimal / {{ .Values.config.celery.worker_concurrency }}) FROM task_instance WHERE (state='running' OR state='queued') {{- if eq .Values.executor \\\"CeleryKubernetesExecutor\\\" }} AND queue != '{{ .Values.config.celery_kubernetes_executor.kubernetes_queue }}' {{- end }} #magic___^_^___line\",\"usePgbouncer\":true},\"kerberosInitContainer\":{\"enabled\":false,\"resources\":{}},\"kerberosSidecar\":{\"containerLifecycleHooks\":{},\"enabled\":false,\"resources\":{},\"securityContexts\":{\"container\":{}}},\"labels\":{},\"livenessProbe\":{\"command\":null,\"enabled\":true,\"failureThreshold\":5,\"initialDelaySeconds\":10,\"periodSeconds\":60,\"timeoutSeconds\":20},\"logGroomerSidecar\":{\"args\":[\"bash\",\"/clean-logs\"],\"command\":null,\"enabled\":true,\"resources\":{},\"retentionDays\":15,\"securityContexts\":{\"container\":{}}},\"nodeSelector\":{\"airflow-node\":\"true\"},\"persistence\":{\"annotations\":{},\"containerLifecycleHooks\":{},\"enabled\":true,\"fixPermissions\":false,\"securityContexts\":{\"container\":{}},\"size\":\"30Gi\",\"storageClassName\":null},\"podAnnotations\":{},\"priorityClassName\":null,\"replicas\":21,\"resources\":{},\"revisionHistoryLimit\":null,\"runtimeClassName\":null,\"safeToEvict\":true,\"securityContext\":{},\"securityContexts\":{\"container\":{},\"pod\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":null},\"strategy\":{\"rollingUpdate\":{\"maxSurge\":\"100%\",\"maxUnavailable\":\"50%\"}},\"terminationGracePeriodSeconds\":600,\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategy\":null,\"volumeClaimTemplates\":[],\"waitForMigrations\":{\"enabled\":true,\"env\":[],\"securityContexts\":{\"container\":{}}}}}",
                "version": "1.13.1"
              }
            ],
            "name": "airflow-v3",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://airflow.apache.org",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "fullnameOverride: \"\"\n\nnameOverride: \"\"\n\nuseStandardNaming: true\n\n# Max number of old replicasets to retain. Can be overridden by each deployment's revisionHistoryLimit\nrevisionHistoryLimit: ~\n\n# User and group of airflow user\nuid: 50000\ngid: 0\n\n# Default security context for airflow (deprecated, use `securityContexts` instead)\nsecurityContext: {}\n#  runAsUser: 50000\n#  fsGroup: 0\n#  runAsGroup: 0\n\n# Detailed default security context for airflow deployments\nsecurityContexts:\n  pod: {}\n  containers: {}\n\n# Default container lifecycle hooks for every service except for redis, statsd and pgbouncer.\ncontainerLifecycleHooks: {}\n\n# Airflow home directory\n# Used for mount paths\nairflowHome: /opt/airflow\n\n# Default airflow repository -- overridden by all the specific images below\ndefaultAirflowRepository: apache/airflow\n\n# Default airflow tag to deploy\ndefaultAirflowTag: \"2.8.3\"\n\n# Default airflow digest. If specified, it takes precedence over tag\ndefaultAirflowDigest: ~\n\n# Airflow version (Used to make some decisions based on Airflow Version being deployed)\nairflowVersion: \"2.8.3\"\n\n# Images\nimages:\n  airflow:\n    repository: jackt72xp/airflow\n    tag: v1\n    # Specifying digest takes precedence over tag.\n    digest: ~\n    pullPolicy: IfNotPresent\n  useDefaultImageForMigration: false\n  migrationsWaitTimeout: 60\n  pod_template:\n    repository: ~\n    tag: ~\n    pullPolicy: IfNotPresent\n  flower:\n    repository: ~\n    tag: ~\n    pullPolicy: IfNotPresent\n  statsd:\n    repository: quay.io/prometheus/statsd-exporter\n    tag: v0.26.0\n    pullPolicy: IfNotPresent\n  redis:\n    repository: redis\n    tag: 7-bookworm\n    pullPolicy: IfNotPresent\n  pgbouncer:\n    repository: apache/airflow\n    tag: airflow-pgbouncer-2024.01.19-1.21.0\n    pullPolicy: IfNotPresent\n  pgbouncerExporter:\n    repository: apache/airflow\n    tag: airflow-pgbouncer-exporter-2024.01.19-0.16.0\n    pullPolicy: IfNotPresent\n  gitSync:\n    repository: registry.k8s.io/git-sync/git-sync\n    tag: v4.1.0\n    pullPolicy: IfNotPresent\n\n# Select certain nodes for airflow pods.\nnodeSelector:\n  airflow-node: \"true\"\n\n\n\naffinity: {}\n\ntolerations: []\ntopologySpreadConstraints: []\nschedulerName: ~\n\n# Add common labels to all objects and pods defined in this chart.\nlabels: {}\n\n# Ingress configuration\ningress:\n  # Enable all ingress resources (deprecated - use ingress.web.enabled and ingress.flower.enabled)\n  enabled: ~\n\n  # Configs for the Ingress of the web Service\n  web:\n    # Enable web ingress resource\n    enabled: false\n\n    # Annotations for the web Ingress\n    annotations: {}\n\n    # The path for the web Ingress\n    path: \"/\"\n\n    # The pathType for the above path (used only with Kubernetes v1.19 and above)\n    pathType: \"ImplementationSpecific\"\n\n    # The hostname for the web Ingress (Deprecated - renamed to `ingress.web.hosts`)\n    host: \"\"\n\n    # The hostnames or hosts configuration for the web Ingress\n    hosts: []\n    #   # The hostname for the web Ingress (can be templated)\n    # - name: \"\"\n    #   # configs for web Ingress TLS\n    #   tls:\n    #     # Enable TLS termination for the web Ingress\n    #     enabled: false\n    #     # the name of a pre-created Secret containing a TLS private key and certificate\n    #     secretName: \"\"\n\n    # The Ingress Class for the web Ingress (used only with Kubernetes v1.19 and above)\n    ingressClassName: \"\"\n\n    # configs for web Ingress TLS (Deprecated - renamed to `ingress.web.hosts[*].tls`)\n    tls:\n      # Enable TLS termination for the web Ingress\n      enabled: false\n      # the name of a pre-created Secret containing a TLS private key and certificate\n      secretName: \"\"\n\n    # HTTP paths to add to the web Ingress before the default path\n    precedingPaths: []\n\n    # Http paths to add to the web Ingress after the default path\n    succeedingPaths: []\n\n  # Configs for the Ingress of the flower Service\n  flower:\n    # Enable web ingress resource\n    enabled: true\n\n    # Annotations for the flower Ingress\n    annotations: {}\n\n    # The path for the flower Ingress\n    path: \"/\"\n\n    # The pathType for the above path (used only with Kubernetes v1.19 and above)\n    pathType: \"ImplementationSpecific\"\n\n    # The hostname for the flower Ingress (Deprecated - renamed to `ingress.flower.hosts`)\n    host: \"\"\n\n    # The hostnames or hosts configuration for the flower Ingress\n    hosts: []\n    #   # The hostname for the flower Ingress (can be templated)\n    # - name: \"\"\n    #   tls:\n    #     # Enable TLS termination for the flower Ingress\n    #     enabled: false\n    #     # the name of a pre-created Secret containing a TLS private key and certificate\n    #     secretName: \"\"\n\n    # The Ingress Class for the flower Ingress (used only with Kubernetes v1.19 and above)\n    ingressClassName: \"\"\n\n    # configs for flower Ingress TLS (Deprecated - renamed to `ingress.flower.hosts[*].tls`)\n    tls:\n      # Enable TLS termination for the flower Ingress\n      enabled: false\n      # the name of a pre-created Secret containing a TLS private key and certificate\n      secretName: \"\"\n\n# Network policy configuration\nnetworkPolicies:\n  # Enabled network policies\n  enabled: false\n\n# Extra annotations to apply to all\n# Airflow pods\nairflowPodAnnotations: {}\n\n# Extra annotations to apply to\n# main Airflow configmap\nairflowConfigAnnotations: {}\n\n# `airflow_local_settings` file as a string (can be templated).\nairflowLocalSettings: |-\n  {{- if semverCompare \"\u003e=2.2.0\" .Values.airflowVersion }}\n  {{- if not (or .Values.webserverSecretKey .Values.webserverSecretKeySecretName) }}\n  from airflow.www.utils import UIAlert\n\n  DASHBOARD_UIALERTS = [\n    UIAlert(\n      'Usage of a dynamic webserver secret key detected. We recommend a static webserver secret key instead.'\n      ' See the \u003ca href='\n      '\"https://airflow.apache.org/docs/helm-chart/stable/production-guide.html#webserver-secret-key\"\u003e'\n      'Helm Chart Production Guide\u003c/a\u003e for more details.',\n      category=\"warning\",\n      roles=[\"Admin\"],\n      html=True,\n    )\n  ]\n  {{- end }}\n  {{- end }}\n\n# Enable RBAC (default on most clusters these days)\nrbac:\n  # Specifies whether RBAC resources should be created\n  create: true\n  createSCCRoleBinding: false\n\n# Airflow executor\n# One of: LocalExecutor, LocalKubernetesExecutor, CeleryExecutor, KubernetesExecutor, CeleryKubernetesExecutor\nexecutor: \"CeleryExecutor\"\n\n# If this is true and using LocalExecutor/KubernetesExecutor/CeleryKubernetesExecutor, the scheduler's\n# service account will have access to communicate with the api-server and launch pods.\n# If this is true and using CeleryExecutor/KubernetesExecutor/CeleryKubernetesExecutor, the workers\n# will be able to launch pods.\nallowPodLaunching: true\n\n# Environment variables for all airflow containers\nenv:\n- name: AIRFLOW_CONN_MYSQLPRD\n  value: mysql+mysqlconnector://root:q%7DIb%5DDg7QVEi08VXN%7E%28@192.168.29.9/bifrost_auth\n\n# - name: \"\"\n#   value: \"\"\n\n# Volumes for all airflow containers\nvolumes: []\n\n# VolumeMounts for all airflow containers\nvolumeMounts: []\n\n# Secrets for all airflow containers\nsecret: []\n# - envName: \"\"\n#   secretName: \"\"\n#   secretKey: \"\"\n\n# Enables selected built-in secrets that are set via environment variables by default.\n# Those secrets are provided by the Helm Chart secrets by default but in some cases you\n# might want to provide some of those variables with _CMD or _SECRET variable, and you should\n# in this case disable setting of those variables by setting the relevant configuration to false.\nenableBuiltInSecretEnvVars:\n  AIRFLOW__CORE__FERNET_KEY: true\n  # For Airflow \u003c2.3, backward compatibility; moved to [database] in 2.3\n  AIRFLOW__CORE__SQL_ALCHEMY_CONN: true\n  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: true\n  AIRFLOW_CONN_AIRFLOW_DB: true\n  AIRFLOW__WEBSERVER__SECRET_KEY: true\n  AIRFLOW__CELERY__CELERY_RESULT_BACKEND: true\n  AIRFLOW__CELERY__RESULT_BACKEND: true\n  AIRFLOW__CELERY__BROKER_URL: true\n  AIRFLOW__ELASTICSEARCH__HOST: true\n  AIRFLOW__ELASTICSEARCH__ELASTICSEARCH_HOST: true\n\npriorityClasses: []\n#    * key (can be templated) is the name of the secret that will be created\n#    * value: an object with the standard 'data' or 'stringData' key (or both).\n#          The value associated with those keys must be a string (can be templated)\nextraSecrets: {}\nextraConfigMaps: {}\nextraEnv: ~\nextraEnvFrom: ~\ndata:\n  metadataSecretName: ~\n  resultBackendSecretName: ~\n  brokerUrlSecretName: ~\n\n  # Otherwise pass connection values in\n  metadataConnection:\n    user: hdfs\n    pass: Maniac321.\n    protocol: postgresql\n    host: postgres-airflow-postgresql.datalake.svc.cluster.local\n    port: 5432\n    db: hdfs\n    sslmode: disable\n  # resultBackendConnection defaults to the same database as metadataConnection\n  resultBackendConnection: ~\n  # or, you can use a different database\n  # resultBackendConnection:\n  #   user: postgres\n  #   pass: postgres\n  #   protocol: postgresql\n  #   host: ~\n  #   port: 5432\n  #   db: postgres\n  #   sslmode: disable\n  # Note: brokerUrl can only be set during install, not upgrade\n  brokerUrl: ~\n\n# Fernet key settings\n# Note: fernetKey can only be set during install, not upgrade\nfernetKey: ~\nfernetKeySecretName: ~\n\n# Flask secret key for Airflow Webserver: `[webserver] secret_key` in airflow.cfg\nwebserverSecretKey: ~\nwebserverSecretKeySecretName: ~\n\n# In order to use kerberos you need to create secret containing the keytab file\n# The secret name should follow naming convention of the application where resources are\n# name {{ .Release-name }}-\u003cPOSTFIX\u003e. In case of the keytab file, the postfix is \"kerberos-keytab\"\n# So if your release is named \"my-release\" the name of the secret should be \"my-release-kerberos-keytab\"\n#\n# The Keytab content should be available in the \"kerberos.keytab\" key of the secret.\n#\n#  apiVersion: v1\n#  kind: Secret\n#  data:\n#    kerberos.keytab: \u003cbase64_encoded keytab file content\u003e\n#  type: Opaque\n#\n#\n#  If you have such keytab file you can do it with similar\n#\n#  kubectl create secret generic {{ .Release.name }}-kerberos-keytab --from-file=kerberos.keytab\n#\n#\n#  Alternatively, instead of manually creating the secret, it is possible to specify\n#  kerberos.keytabBase64Content parameter. This parameter should contain base64 encoded keytab.\n#\n\nkerberos:\n  enabled: false\n  ccacheMountPath: /var/kerberos-ccache\n  ccacheFileName: cache\n  configPath: /etc/krb5.conf\n  keytabBase64Content: ~\n  keytabPath: /etc/airflow.keytab\n  principal: airflow@FOO.COM\n  reinitFrequency: 3600\n  config: |\n    # This is an example config showing how you can use templating and how \"example\" config\n    # might look like. It works with the test kerberos server that we are using during integration\n    # testing at Apache Airflow (see `scripts/ci/docker-compose/integration-kerberos.yml` but in\n    # order to make it production-ready you must replace it with your own configuration that\n    # Matches your kerberos deployment. Administrators of your Kerberos instance should\n    # provide the right configuration.\n\n    [logging]\n    default = \"FILE:{{ template \"airflow_logs_no_quote\" . }}/kerberos_libs.log\"\n    kdc = \"FILE:{{ template \"airflow_logs_no_quote\" . }}/kerberos_kdc.log\"\n    admin_server = \"FILE:{{ template \"airflow_logs_no_quote\" . }}/kadmind.log\"\n\n    [libdefaults]\n    default_realm = FOO.COM\n    ticket_lifetime = 10h\n    renew_lifetime = 7d\n    forwardable = true\n\n    [realms]\n    FOO.COM = {\n      kdc = kdc-server.foo.com\n      admin_server = admin_server.foo.com\n    }\n\n# Airflow Worker Config\nworkers:\n  # Number of airflow celery workers in StatefulSet\n  replicas: 21\n  # Max number of old replicasets to retain\n  revisionHistoryLimit: ~\n\n  # Command to use when running Airflow workers (templated).\n  command: ~\n  # Args to use when running Airflow workers (templated).\n  args:\n  - \"bash\"\n  - \"-c\"\n  # The format below is necessary to get `helm lint` happy\n  - |-\n    exec \\\n    airflow {{ semverCompare \"\u003e=2.0.0\" .Values.airflowVersion | ternary \"celery worker\" \"worker\" }}\n\n  # If the worker stops responding for 5 minutes (5*60s) kill the\n  # worker and let Kubernetes restart it\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    timeoutSeconds: 20\n    failureThreshold: 5\n    periodSeconds: 60\n    command: ~\n\n  # Update Strategy when worker is deployed as a StatefulSet\n  updateStrategy: ~\n  # Update Strategy when worker is deployed as a Deployment\n  strategy:\n    rollingUpdate:\n      maxSurge: \"100%\"\n      maxUnavailable: \"50%\"\n\n  # When not set, the values defined in the global securityContext will be used\n  securityContext: {}\n  #  runAsUser: 50000\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security context for worker deployments for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to worker kubernetes service account.\n    annotations: {}\n\n  # Allow KEDA autoscaling.\n  keda:\n    enabled: false\n    namespaceLabels: {}\n\n    # How often KEDA polls the airflow DB to report new scale requests to the HPA\n    pollingInterval: 5\n\n    # How many seconds KEDA will wait before scaling to zero.\n    # Note that HPA has a separate cooldown period for scale-downs\n    cooldownPeriod: 30\n\n    # Minimum number of workers created by keda\n    minReplicaCount: 0\n\n    # Maximum number of workers created by keda\n    maxReplicaCount: 10\n\n    # Specify HPA related options\n    advanced: {}\n    # horizontalPodAutoscalerConfig:\n    #   behavior:\n    #     scaleDown:\n    #       stabilizationWindowSeconds: 300\n    #       policies:\n    #         - type: Percent\n    #           value: 100\n    #           periodSeconds: 15\n\n    # Query to use for KEDA autoscaling. Must return a single integer.\n    query: \u003e-\n      SELECT ceil(COUNT(*)::decimal / {{ .Values.config.celery.worker_concurrency }}) FROM task_instance WHERE (state='running' OR state='queued') {{- if eq .Values.executor \"CeleryKubernetesExecutor\" }} AND queue != '{{ .Values.config.celery_kubernetes_executor.kubernetes_queue }}' {{- end }} #magic___^_^___line\n    # Weather to use PGBouncer to connect to the database or not when it is enabled\n    # This configuration will be ignored if PGBouncer is not enabled\n    usePgbouncer: true\n\n  # Allow HPA (KEDA must be disabled).\n  hpa:\n    enabled: true\n\n    # Minimum number of workers created by HPA\n    minReplicaCount: 15\n\n    # Maximum number of workers created by HPA\n    maxReplicaCount: 40\n\n    # Specifications for which to use to calculate the desired replica count\n    metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 75\n\n    # Scaling behavior of the target in both Up and Down directions\n    behavior: {}\n\n  persistence:\n    # Enable persistent volumes\n    enabled: true\n    # Volume size for worker StatefulSet\n    size: 30Gi\n    # If using a custom storageClass, pass name ref to all statefulSets here\n    storageClassName:\n    # Execute init container to chown log directory.\n    # This is currently only needed in kind, due to usage\n    # of local-path provisioner.\n    fixPermissions: false\n    # Annotations to add to worker volumes\n    annotations: {}\n    # Detailed default security context for persistence for container level\n    securityContexts:\n      container: {}\n    # container level lifecycle hooks\n    containerLifecycleHooks: {}\n\n  kerberosSidecar:\n    # Enable kerberos sidecar\n    enabled: false\n    resources: {}\n    #  limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    #  requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # Detailed default security context for kerberosSidecar for container level\n    securityContexts:\n      container: {}\n    # container level lifecycle hooks\n    containerLifecycleHooks: {}\n\n  kerberosInitContainer:\n    # Enable kerberos init container\n    enabled: false\n    resources: {}\n    #  limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    #  requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n\n\n  resources: {}\n  #  limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  #  requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\n  # Grace period for tasks to finish after SIGTERM is sent from kubernetes\n  terminationGracePeriodSeconds: 600\n\n  # This setting tells kubernetes that its ok to evict\n  # when it wants to scale a node down.\n  safeToEvict: true\n\n  # Launch additional containers into worker.\n  # Note: If used with KubernetesExecutor, you are responsible for signaling sidecars to exit when the main\n  # container finishes so Airflow can continue the worker shutdown process!\n  extraContainers: []\n  # Add additional init containers into workers.\n  extraInitContainers: []\n\n  # Mount additional volumes into worker. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  # Select certain nodes for airflow worker pods.\n  nodeSelector:\n    airflow-node: \"true\"\n  runtimeClassName: ~\n  priorityClassName: ~\n  affinity: {}\n  # default worker affinity is:\n  #  podAntiAffinity:\n  #    preferredDuringSchedulingIgnoredDuringExecution:\n  #    - podAffinityTerm:\n  #        labelSelector:\n  #          matchLabels:\n  #            component: worker\n  #        topologyKey: kubernetes.io/hostname\n  #      weight: 100\n  tolerations: []\n  topologySpreadConstraints: []\n  # hostAliases to use in worker pods.\n  # See:\n  # https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  hostAliases:\n  - ip: \"192.168.36.99\"\n  # - ip: \"127.0.0.3\"\n  #   hostnames:\n  #   - \"test.hostname.two\"\n\n  # annotations for the worker resource\n  annotations: {}\n\n  podAnnotations: {}\n\n  # Labels specific to workers objects and pods\n  labels: {}\n\n  logGroomerSidecar:\n    # Whether to deploy the Airflow worker log groomer sidecar.\n    enabled: true\n    # Command to use when running the Airflow worker log groomer sidecar (templated).\n    command: ~\n    # Args to use when running the Airflow worker log groomer sidecar (templated).\n    args: [\"bash\", \"/clean-logs\"]\n    # Number of days to retain logs\n    retentionDays: 15\n    resources: {}\n    #  limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    #  requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # Detailed default security context for logGroomerSidecar for container level\n    securityContexts:\n      container: {}\n\n  waitForMigrations:\n    # Whether to create init container to wait for db migrations\n    enabled: true\n    env: []\n    # Detailed default security context for waitForMigrations for container level\n    securityContexts:\n      container: {}\n\n  env: []\n\n  volumeClaimTemplates: []\n  # Additional volumeClaimTemplates needed.\n  # Comment out the above and uncomment the section below to enable it.\n  # Add more as needed\n  # Make sure to mount it under extraVolumeMounts.\n  # volumeClaimTemplates:\n  #   - metadata:\n  #       name: data-volume-1\n  #     spec:\n  #       storageClassName: \"storage-class-1\"\n  #       accessModes:\n  #         - \"ReadWriteOnce\"\n  #       resources:\n  #         requests:\n  #           storage: \"10Gi\"\n  #   - metadata:\n  #       name: data-volume-2\n  #     spec:\n  #       storageClassName: \"storage-class-2\"\n  #       accessModes:\n  #         - \"ReadWriteOnce\"\n  #       resources:\n  #         requests:\n  #           storage: \"20Gi\"\n\n# Airflow scheduler settings\nscheduler:\n  enabled: true\n  #  hostAliases for the scheduler pod\n  hostAliases: []\n  #  - ip: \"127.0.0.1\"\n  #    hostnames:\n  #      - \"foo.local\"\n  #  - ip: \"10.1.2.3\"\n  #    hostnames:\n  #      - \"foo.remote\"\n\n  # If the scheduler stops heartbeating for 5 minutes (5*60s) kill the\n  # scheduler and let Kubernetes restart it\n  livenessProbe:\n    initialDelaySeconds: 10\n    timeoutSeconds: 20\n    failureThreshold: 5\n    periodSeconds: 60\n    command: ~\n\n  # Wait for at most 10 minutes (6*10s) for the scheduler container to startup.\n  # livenessProbe kicks in after the startup\n  startupProbe:\n    failureThreshold: 6\n    periodSeconds: 10\n    timeoutSeconds: 20\n    command: ~\n  # Airflow 2.0 allows users to run multiple schedulers,\n  # However this feature is only recommended for MySQL 8+ and Postgres\n  replicas: 20\n  # Max number of old replicasets to retain\n  revisionHistoryLimit: ~\n\n  # Command to use when running the Airflow scheduler (templated).\n  command: ~\n  # Args to use when running the Airflow scheduler (templated).\n  args: [\"bash\", \"-c\", \"exec airflow scheduler\"]\n\n  # Update Strategy when scheduler is deployed as a StatefulSet\n  # (when using LocalExecutor and workers.persistence)\n  updateStrategy: ~\n  # Update Strategy when scheduler is deployed as a Deployment\n  # (when not using LocalExecutor and workers.persistence)\n  strategy: ~\n\n  # When not set, the values defined in the global securityContext will be used\n  # (deprecated, use `securityContexts` instead)\n  securityContext: {}\n  #  runAsUser: 50000\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security context for scheduler deployments for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to scheduler kubernetes service account.\n    annotations: {}\n\n  # Scheduler pod disruption budget\n  podDisruptionBudget:\n    enabled: false\n\n    # PDB configuration\n    config:\n      # minAvailable and maxUnavailable are mutually exclusive\n      maxUnavailable: 1\n      # minAvailable: 1\n\n  resources: {}\n  #  limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  #  requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\n  # This setting tells kubernetes that its ok to evict\n  # when it wants to scale a node down.\n  safeToEvict: true\n\n  # Launch additional containers into scheduler.\n  extraContainers: []\n  # Add additional init containers into scheduler.\n  extraInitContainers: []\n\n  # Mount additional volumes into scheduler. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  # Select certain nodes for airflow scheduler pods.\n  nodeSelector:\n    airflow-node: \"true\"\n  affinity: {}\n  # default scheduler affinity is:\n  #  podAntiAffinity:\n  #    preferredDuringSchedulingIgnoredDuringExecution:\n  #    - podAffinityTerm:\n  #        labelSelector:\n  #          matchLabels:\n  #            component: scheduler\n  #        topologyKey: kubernetes.io/hostname\n  #      weight: 100\n  tolerations: []\n  topologySpreadConstraints: []\n\n  priorityClassName: ~\n\n  # annotations for scheduler deployment\n  annotations: {}\n\n  podAnnotations: {}\n\n  # Labels specific to scheduler objects and pods\n  labels: {}\n\n  logGroomerSidecar:\n    # Whether to deploy the Airflow scheduler log groomer sidecar.\n    enabled: true\n    # Command to use when running the Airflow scheduler log groomer sidecar (templated).\n    command: ~\n    # Args to use when running the Airflow scheduler log groomer sidecar (templated).\n    args: [\"bash\", \"/clean-logs\"]\n    # Number of days to retain logs\n    retentionDays: 15\n    resources: {}\n    #  limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    #  requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # Detailed default security context for logGroomerSidecar for container level\n    securityContexts:\n      container: {}\n    # container level lifecycle hooks\n    containerLifecycleHooks: {}\n\n  waitForMigrations:\n    # Whether to create init container to wait for db migrations\n    enabled: true\n    env: []\n    # Detailed default security context for waitForMigrations for container level\n    securityContexts:\n      container: {}\n\n  env: []\n\n# Airflow create user job settings\ncreateUserJob:\n  # Limit the lifetime of the job object after it finished execution.\n  ttlSecondsAfterFinished: 300\n  # Command to use when running the create user job (templated).\n  command: ~\n  # Args to use when running the create user job (templated).\n  args:\n  - \"bash\"\n  - \"-c\"\n  # The format below is necessary to get `helm lint` happy\n  - |-\n    exec \\\n    airflow {{ semverCompare \"\u003e=2.0.0\" .Values.airflowVersion | ternary \"users create\" \"create_user\" }} \"$@\"\n  - --\n  - \"-r\"\n  - \"{{ .Values.webserver.defaultUser.role }}\"\n  - \"-u\"\n  - \"{{ .Values.webserver.defaultUser.username }}\"\n  - \"-e\"\n  - \"{{ .Values.webserver.defaultUser.email }}\"\n  - \"-f\"\n  - \"{{ .Values.webserver.defaultUser.firstName }}\"\n  - \"-l\"\n  - \"{{ .Values.webserver.defaultUser.lastName }}\"\n  - \"-p\"\n  - \"{{ .Values.webserver.defaultUser.password }}\"\n\n  # Annotations on the create user job pod\n  annotations: {}\n  # jobAnnotations are annotations on the create user job\n  jobAnnotations: {}\n\n  # Labels specific to createUserJob objects and pods\n  labels: {}\n\n  # When not set, the values defined in the global securityContext will be used\n  securityContext: {}\n  #  runAsUser: 50000\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security context for createUserJob for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to create user kubernetes service account.\n    annotations: {}\n\n  # Launch additional containers into user creation job\n  extraContainers: []\n\n  # Mount additional volumes into user creation job. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  nodeSelector:\n    airflow-node: \"true\"\n  affinity: {}\n  tolerations: []\n  topologySpreadConstraints: []\n  # In case you need to disable the helm hooks that create the jobs after install.\n  # Disable this if you are using ArgoCD for example\n  useHelmHooks: true\n  applyCustomEnv: true\n\n  env: []\n\n  resources: {}\n  #  limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  #  requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\n# Airflow database migration job settings\nmigrateDatabaseJob:\n  enabled: true\n  # Limit the lifetime of the job object after it finished execution.\n  ttlSecondsAfterFinished: 300\n  # Command to use when running the migrate database job (templated).\n  command: ~\n  # Args to use when running the migrate database job (templated).\n  args:\n  - \"bash\"\n  - \"-c\"\n  - \u003e-\n    exec \\\n\n    airflow {{ semverCompare \"\u003e=2.7.0\" .Values.airflowVersion | ternary \"db migrate\" (semverCompare \"\u003e=2.0.0\" .Values.airflowVersion | ternary \"db upgrade\" \"upgradedb\") }}\n\n  # Annotations on the database migration pod\n  annotations: {}\n  # jobAnnotations are annotations on the database migration job\n  jobAnnotations: {}\n\n  # Labels specific to migrate database job objects and pods\n  labels: {}\n\n  # When not set, the values defined in the global securityContext will be used\n  securityContext: {}\n  #  runAsUser: 50000\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security context for migrateDatabaseJob for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to migrate database job kubernetes service account.\n    annotations: {}\n\n  resources: {}\n  #  limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  #  requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\n  # Launch additional containers into database migration job\n  extraContainers: []\n\n  # Mount additional volumes into database migration job. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  nodeSelector:\n    airflow-node: \"true\"\n  affinity: {}\n  tolerations: []\n  topologySpreadConstraints: []\n  # In case you need to disable the helm hooks that create the jobs after install.\n  # Disable this if you are using ArgoCD for example\n  useHelmHooks: true\n  applyCustomEnv: true\n\n# Airflow webserver settings\nwebserver:\n  enabled: true\n  # Add custom annotations to the webserver configmap\n  configMapAnnotations: {}\n  #  hostAliases for the webserver pod\n  hostAliases: []\n  #  - ip: \"127.0.0.1\"\n  #    hostnames:\n  #      - \"foo.local\"\n  #  - ip: \"10.1.2.3\"\n  #    hostnames:\n  #      - \"foo.remote\"\n  allowPodLogReading: true\n  livenessProbe:\n    initialDelaySeconds: 15\n    timeoutSeconds: 5\n    failureThreshold: 5\n    periodSeconds: 10\n    scheme: HTTP\n\n  readinessProbe:\n    initialDelaySeconds: 15\n    timeoutSeconds: 5\n    failureThreshold: 5\n    periodSeconds: 10\n    scheme: HTTP\n\n  startupProbe:\n    timeoutSeconds: 20\n    failureThreshold: 6\n    periodSeconds: 10\n    scheme: HTTP\n\n  # Number of webservers\n  replicas: 1\n  # Max number of old replicasets to retain\n  revisionHistoryLimit: ~\n\n  # Command to use when running the Airflow webserver (templated).\n  command: ~\n  # Args to use when running the Airflow webserver (templated).\n  args: [\"bash\", \"-c\", \"exec airflow webserver\"]\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to webserver kubernetes service account.\n    annotations: {}\n\n  # Webserver pod disruption budget\n  podDisruptionBudget:\n    enabled: false\n\n    # PDB configuration\n    config:\n      # minAvailable and maxUnavailable are mutually exclusive\n      maxUnavailable: 1\n      # minAvailable: 1\n\n  # Allow overriding Update Strategy for Webserver\n  strategy: ~\n\n  # When not set, the values defined in the global securityContext will be used\n  # (deprecated, use `securityContexts` instead)\n  securityContext: {}\n  #  runAsUser: 50000\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security contexts for webserver deployments for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  # Additional network policies as needed (Deprecated - renamed to `webserver.networkPolicy.ingress.from`)\n  extraNetworkPolicies: []\n  networkPolicy:\n    ingress:\n      # Peers for webserver NetworkPolicy ingress\n      from: []\n      # Ports for webserver NetworkPolicy ingress (if `from` is set)\n      ports:\n      - port: \"{{ .Values.ports.airflowUI }}\"\n\n  resources: {}\n  #   limits:\n  #     cpu: 100m\n  #     memory: 128Mi\n  #   requests:\n  #     cpu: 100m\n  #     memory: 128Mi\n\n  # Create initial user.\n  defaultUser:\n    enabled: true\n    role: Admin\n    username: admin\n    email: admin@example.com\n    firstName: admin\n    lastName: user\n    password: admin\n\n  # Launch additional containers into webserver.\n  extraContainers: []\n  # Add additional init containers into webserver.\n  extraInitContainers: []\n\n  # Mount additional volumes into webserver. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  # This string (can be templated) will be mounted into the Airflow Webserver\n  # as a custom webserver_config.py. You can bake a webserver_config.py in to\n  # your image instead or specify a configmap containing the\n  # webserver_config.py.\n  webserverConfig: ~\n  # webserverConfig: |\n  #   from airflow import configuration as conf\n\n  #   # The SQLAlchemy connection string.\n  #   SQLALCHEMY_DATABASE_URI = conf.get('database', 'SQL_ALCHEMY_CONN')\n\n  #   # Flask-WTF flag for CSRF\n  #   CSRF_ENABLED = True\n  webserverConfigConfigMapName: ~\n\n  service:\n    type: ClusterIP\n    ## service annotations\n    annotations: {}\n    ports:\n    - name: airflow-ui\n      port: \"{{ .Values.ports.airflowUI }}\"\n    # To change the port used to access the webserver:\n    # ports:\n    #   - name: airflow-ui\n    #     port: 80\n    #     targetPort: airflow-ui\n    # To only expose a sidecar, not the webserver directly:\n    # ports:\n    #   - name: only_sidecar\n    #     port: 80\n    #     targetPort: 8888\n    # If you have a public IP, set NodePort to set an external port.\n    # Service type must be 'NodePort':\n    # ports:\n    #   - name: airflow-ui\n    #     port: 8080\n    #     targetPort: 8080\n    #     nodePort: 31151\n    loadBalancerIP: ~\n    ## Limit load balancer source ips to list of CIDRs\n    # loadBalancerSourceRanges:\n    #   - \"10.123.0.0/16\"\n    loadBalancerSourceRanges: []\n\n  # Select certain nodes for airflow webserver pods.\n  nodeSelector:\n    airflow-node: \"true\"\n  priorityClassName: ~\n\n  affinity: {}\n  # default webserver affinity is:\n  #  podAntiAffinity:\n  #    preferredDuringSchedulingIgnoredDuringExecution:\n  #    - podAffinityTerm:\n  #        labelSelector:\n  #          matchLabels:\n  #            component: webserver\n  #        topologyKey: kubernetes.io/hostname\n  #      weight: 100\n  tolerations: []\n  topologySpreadConstraints: []\n\n  # annotations for webserver deployment\n  annotations: {}\n\n  podAnnotations: {}\n\n  # Labels specific webserver app\n  labels: {}\n\n  waitForMigrations:\n    # Whether to create init container to wait for db migrations\n    enabled: true\n    env: []\n    # Detailed default security context for waitForMigrations for container level\n    securityContexts:\n      container: {}\n\n  env: []\n\n# Airflow Triggerer Config\ntriggerer:\n  enabled: true\n  # Number of airflow triggerers in the deployment\n  replicas: 15\n  # Max number of old replicasets to retain\n  revisionHistoryLimit: ~\n\n  # Command to use when running Airflow triggerers (templated).\n  command: ~\n  # Args to use when running Airflow triggerer (templated).\n  args: [\"bash\", \"-c\", \"exec airflow triggerer\"]\n\n  # Update Strategy when triggerer is deployed as a StatefulSet\n  updateStrategy: ~\n  # Update Strategy when triggerer is deployed as a Deployment\n  strategy:\n    rollingUpdate:\n      maxSurge: \"100%\"\n      maxUnavailable: \"50%\"\n\n  # If the triggerer stops heartbeating for 5 minutes (5*60s) kill the\n  # triggerer and let Kubernetes restart it\n  livenessProbe:\n    initialDelaySeconds: 10\n    timeoutSeconds: 20\n    failureThreshold: 5\n    periodSeconds: 60\n    command: ~\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to triggerer kubernetes service account.\n    annotations: {}\n\n  # When not set, the values defined in the global securityContext will be used\n  securityContext: {}\n  #  runAsUser: 50000\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security context for triggerer for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  persistence:\n    # Enable persistent volumes\n    enabled: true\n    # Volume size for triggerer StatefulSet\n    size: 100Gi\n    # If using a custom storageClass, pass name ref to all statefulSets here\n    storageClassName:\n    # Execute init container to chown log directory.\n    # This is currently only needed in kind, due to usage\n    # of local-path provisioner.\n    fixPermissions: false\n    # Annotations to add to triggerer volumes\n    annotations: {}\n\n  resources: {}\n  #  limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  #  requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\n  # Grace period for triggerer to finish after SIGTERM is sent from kubernetes\n  terminationGracePeriodSeconds: 60\n\n  # This setting tells kubernetes that its ok to evict\n  # when it wants to scale a node down.\n  safeToEvict: true\n\n  # Launch additional containers into triggerer.\n  extraContainers: []\n  # Add additional init containers into triggerers.\n  extraInitContainers: []\n\n  # Mount additional volumes into triggerer. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  # Select certain nodes for airflow triggerer pods.\n  nodeSelector:\n    airflow-node: \"true\"\n\n  affinity: {}\n  # default triggerer affinity is:\n  #  podAntiAffinity:\n  #    preferredDuringSchedulingIgnoredDuringExecution:\n  #    - podAffinityTerm:\n  #        labelSelector:\n  #          matchLabels:\n  #            component: triggerer\n  #        topologyKey: kubernetes.io/hostname\n  #      weight: 100\n  tolerations: []\n  topologySpreadConstraints: []\n\n  priorityClassName: ~\n\n  # annotations for the triggerer deployment\n  annotations: {}\n\n  podAnnotations: {}\n\n  # Labels specific to triggerer objects and pods\n  labels: {}\n\n  logGroomerSidecar:\n    # Whether to deploy the Airflow triggerer log groomer sidecar.\n    enabled: true\n    # Command to use when running the Airflow triggerer log groomer sidecar (templated).\n    command: ~\n    # Args to use when running the Airflow triggerer log groomer sidecar (templated).\n    args: [\"bash\", \"/clean-logs\"]\n    # Number of days to retain logs\n    retentionDays: 15\n    resources: {}\n    #  limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    #  requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # Detailed default security context for logGroomerSidecar for container level\n    securityContexts:\n      container: {}\n\n    # container level lifecycle hooks\n    containerLifecycleHooks: {}\n\n  waitForMigrations:\n    # Whether to create init container to wait for db migrations\n    enabled: true\n    env: []\n    # Detailed default security context for waitForMigrations for container level\n    securityContexts:\n      container: {}\n\n  env: []\n\n  # Allow KEDA autoscaling.\n  keda:\n    enabled: false\n    namespaceLabels: {}\n\n    # How often KEDA polls the airflow DB to report new scale requests to the HPA\n    pollingInterval: 5\n\n    # How many seconds KEDA will wait before scaling to zero.\n    # Note that HPA has a separate cooldown period for scale-downs\n    cooldownPeriod: 30\n\n    # Minimum number of triggerers created by keda\n    minReplicaCount: 0\n\n    # Maximum number of triggerers created by keda\n    maxReplicaCount: 10\n\n    # Specify HPA related options\n    advanced: {}\n    # horizontalPodAutoscalerConfig:\n    #   behavior:\n    #     scaleDown:\n    #       stabilizationWindowSeconds: 300\n    #       policies:\n    #         - type: Percent\n    #           value: 100\n    #           periodSeconds: 15\n\n    # Query to use for KEDA autoscaling. Must return a single integer.\n    query: \u003e-\n      SELECT ceil(COUNT(*)::decimal / {{ .Values.config.triggerer.default_capacity }}) FROM trigger\n\n# Airflow Dag Processor Config\ndagProcessor:\n  enabled: true\n  # Number of airflow dag processors in the deployment\n  replicas: 12\n  # Max number of old replicasets to retain\n  revisionHistoryLimit: ~\n\n  # Command to use when running Airflow dag processors (templated).\n  command: ~\n  # Args to use when running Airflow dag processor (templated).\n  args: [\"bash\", \"-c\", \"exec airflow dag-processor\"]\n\n  # Update Strategy for dag processors\n  strategy:\n    rollingUpdate:\n      maxSurge: \"100%\"\n      maxUnavailable: \"50%\"\n\n  # If the dag processor stops heartbeating for 5 minutes (5*60s) kill the\n  # dag processor and let Kubernetes restart it\n  livenessProbe:\n    initialDelaySeconds: 10\n    timeoutSeconds: 20\n    failureThreshold: 5\n    periodSeconds: 60\n    command: ~\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to dag processor kubernetes service account.\n    annotations: {}\n\n  # When not set, the values defined in the global securityContext will be used\n  securityContext: {}\n  #  runAsUser: 50000\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security context for dagProcessor for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  resources: {}\n  #  limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  #  requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\n  # Grace period for dag processor to finish after SIGTERM is sent from kubernetes\n  terminationGracePeriodSeconds: 60\n\n  # This setting tells kubernetes that its ok to evict\n  # when it wants to scale a node down.\n  safeToEvict: true\n\n  # Launch additional containers into dag processor.\n  extraContainers: []\n  # Add additional init containers into dag processors.\n  extraInitContainers: []\n\n  # Mount additional volumes into dag processor. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  # Select certain nodes for airflow dag processor pods.\n  nodeSelector:\n    airflow-node: \"true\"\n\n  affinity: {}\n  # default dag processor affinity is:\n  #  podAntiAffinity:\n  #    preferredDuringSchedulingIgnoredDuringExecution:\n  #    - podAffinityTerm:\n  #        labelSelector:\n  #          matchLabels:\n  #            component: dag-processor\n  #        topologyKey: kubernetes.io/hostname\n  #      weight: 100\n  tolerations: []\n  topologySpreadConstraints: []\n\n  priorityClassName: ~\n\n  # annotations for the dag processor deployment\n  annotations: {}\n\n  podAnnotations: {}\n\n  logGroomerSidecar:\n    # Whether to deploy the Airflow dag processor log groomer sidecar.\n    enabled: true\n    # Command to use when running the Airflow dag processor log groomer sidecar (templated).\n    command: ~\n    # Args to use when running the Airflow dag processor log groomer sidecar (templated).\n    args: [\"bash\", \"/clean-logs\"]\n    # Number of days to retain logs\n    retentionDays: 15\n    resources: {}\n    #  limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    #  requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n    securityContexts:\n      container: {}\n\n  waitForMigrations:\n    # Whether to create init container to wait for db migrations\n    enabled: true\n    env: []\n    # Detailed default security context for waitForMigrations for container level\n    securityContexts:\n      container: {}\n\n  env: []\n\n# Flower settings\nflower:\n  # Enable flower.\n  # If True, and using CeleryExecutor/CeleryKubernetesExecutor, will deploy flower app.\n  enabled: false\n\n  livenessProbe:\n    initialDelaySeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 10\n    periodSeconds: 5\n\n  readinessProbe:\n    initialDelaySeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 10\n    periodSeconds: 5\n\n  # Max number of old replicasets to retain\n  revisionHistoryLimit: ~\n\n  # Command to use when running flower (templated).\n  command: ~\n  # Args to use when running flower (templated).\n  args:\n  - \"bash\"\n  - \"-c\"\n  # The format below is necessary to get `helm lint` happy\n  - |-\n    exec \\\n    airflow {{ semverCompare \"\u003e=2.0.0\" .Values.airflowVersion | ternary \"celery flower\" \"flower\" }}\n\n  # Additional network policies as needed (Deprecated - renamed to `flower.networkPolicy.ingress.from`)\n  extraNetworkPolicies: []\n  networkPolicy:\n    ingress:\n      # Peers for flower NetworkPolicy ingress\n      from: []\n      # Ports for flower NetworkPolicy ingress (if ingressPeers is set)\n      ports:\n      - port: \"{{ .Values.ports.flowerUI }}\"\n\n  resources: {}\n  #   limits:\n  #     cpu: 100m\n  #     memory: 128Mi\n  #   requests:\n  #     cpu: 100m\n  #     memory: 128Mi\n\n  # When not set, the values defined in the global securityContext will be used\n  securityContext: {}\n  #  runAsUser: 50000\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security context for flower for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to worker kubernetes service account.\n    annotations: {}\n\n  # A secret containing the connection\n  secretName: ~\n\n  # Else, if username and password are set, create secret from username and password\n  username: ~\n  password: ~\n\n  service:\n    type: ClusterIP\n    ## service annotations\n    annotations: {}\n    ports:\n    - name: flower-ui\n      port: \"{{ .Values.ports.flowerUI }}\"\n    # To change the port used to access flower:\n    # ports:\n    #   - name: flower-ui\n    #     port: 8080\n    #     targetPort: flower-ui\n    loadBalancerIP: ~\n    ## Limit load balancer source ips to list of CIDRs\n    # loadBalancerSourceRanges:\n    #   - \"10.123.0.0/16\"\n    loadBalancerSourceRanges: []\n\n  # Launch additional containers into the flower pods.\n  extraContainers: []\n  # Mount additional volumes into the flower pods. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  # Select certain nodes for airflow flower pods.\n  nodeSelector:\n    airflow-node: \"true\"\n\n  affinity: {}\n  tolerations: []\n  topologySpreadConstraints: []\n\n  priorityClassName: ~\n\n  # annotations for the flower deployment\n  annotations: {}\n\n  podAnnotations: {}\n\n  # Labels specific to flower objects and pods\n  labels: {}\n  env: []\n\n# StatsD settings\nstatsd:\n  # Add custom annotations to the statsd configmap\n  configMapAnnotations: {}\n\n  enabled: true\n  # Max number of old replicasets to retain\n  revisionHistoryLimit: ~\n\n  # Arguments for StatsD exporter command.\n  args: [\"--statsd.mapping-config=/etc/statsd-exporter/mappings.yml\"]\n\n  # Annotations to add to the StatsD Deployment.\n  annotations: {}\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to worker kubernetes service account.\n    annotations: {}\n\n  uid: 65534\n  # When not set, `statsd.uid` will be used\n\n  # (deprecated, use `securityContexts` instead)\n  securityContext: {}\n  #  runAsUser: 65534\n  #  fsGroup: 0\n  #  runAsGroup: 0\n\n  # Detailed default security context for statsd deployments for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  # Additional network policies as needed\n  extraNetworkPolicies: []\n  resources: {}\n  #   limits:\n  #     cpu: 100m\n  #     memory: 128Mi\n  #   requests:\n  #     cpu: 100m\n  #     memory: 128Mi\n\n  service:\n    extraAnnotations: {}\n\n  # Select certain nodes for StatsD pods.\n  nodeSelector:\n    airflow-node: \"true\"\n\n  affinity: {}\n  tolerations: []\n  topologySpreadConstraints: []\n\n  priorityClassName: ~\n\n  # Additional mappings for StatsD exporter.\n  # If set, will merge default mapping and extra mappings, default mapping has higher priority.\n  # So, if you want to change some default mapping, please use `overrideMappings`\n  extraMappings: []\n\n  # Override mappings for StatsD exporter.\n  # If set, will ignore setting item in default and `extraMappings`.\n  # So, If you use it, ensure all mapping item contains in it.\n  overrideMappings: []\n\n  podAnnotations: {}\n  env: []\n\n# PgBouncer settings\npgbouncer:\n  # Enable PgBouncer\n  enabled: false\n  # Number of PgBouncer replicas to run in Deployment\n  replicas: 1\n  # Max number of old replicasets to retain\n  revisionHistoryLimit: ~\n  # Command to use for PgBouncer(templated).\n  command: [\"pgbouncer\", \"-u\", \"nobody\", \"/etc/pgbouncer/pgbouncer.ini\"]\n  # Args to use for PgBouncer(templated).\n  args: ~\n  auth_type: scram-sha-256\n  auth_file: /etc/pgbouncer/users.txt\n\n  # annotations to be added to the PgBouncer deployment\n  annotations: {}\n\n  podAnnotations: {}\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to worker kubernetes service account.\n    annotations: {}\n\n  # Additional network policies as needed\n  extraNetworkPolicies: []\n\n  # Pool sizes\n  metadataPoolSize: 10\n  resultBackendPoolSize: 5\n\n  # Maximum clients that can connect to PgBouncer (higher = more file descriptors)\n  maxClientConn: 100\n\n  # supply the name of existing secret with pgbouncer.ini and users.txt defined\n  # you can load them to a k8s secret like the one below\n  #  apiVersion: v1\n  #  kind: Secret\n  #  metadata:\n  #    name: pgbouncer-config-secret\n  #  data:\n  #     pgbouncer.ini: \u003cbase64_encoded pgbouncer.ini file content\u003e\n  #     users.txt: \u003cbase64_encoded users.txt file content\u003e\n  #  type: Opaque\n  #\n  #  configSecretName: pgbouncer-config-secret\n  #\n  configSecretName: ~\n\n  # PgBouncer pod disruption budget\n  podDisruptionBudget:\n    enabled: false\n\n    # PDB configuration\n    config:\n      # minAvailable and maxUnavailable are mutually exclusive\n      maxUnavailable: 1\n      # minAvailable: 1\n\n  # Limit the resources to PgBouncer.\n  # When you specify the resource request the k8s scheduler uses this information to decide which node to\n  # place the Pod on. When you specify a resource limit for a Container, the kubelet enforces those limits so\n  # that the running container is not allowed to use more of that resource than the limit you set.\n  # See: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n  # Example:\n  #\n  # resource:\n  #   limits:\n  #     cpu: 100m\n  #     memory: 128Mi\n  #   requests:\n  #     cpu: 100m\n  #     memory: 128Mi\n  resources: {}\n\n  service:\n    extraAnnotations: {}\n\n  # https://www.pgbouncer.org/config.html\n  verbose: 0\n  logDisconnections: 0\n  logConnections: 0\n\n  sslmode: \"prefer\"\n  ciphers: \"normal\"\n\n  ssl:\n    ca: ~\n    cert: ~\n    key: ~\n\n  # Add extra PgBouncer ini configuration in the databases section:\n  # https://www.pgbouncer.org/config.html#section-databases\n  extraIniMetadata: ~\n  extraIniResultBackend: ~\n  # Add extra general PgBouncer ini configuration: https://www.pgbouncer.org/config.html\n  extraIni: ~\n\n  # Mount additional volumes into pgbouncer. It can be templated like in the following example:\n  #   extraVolumes:\n  #     - name: my-templated-extra-volume\n  #       secret:\n  #          secretName: '{{ include \"my_secret_template\" . }}'\n  #          defaultMode: 0640\n  #          optional: true\n  #\n  #   extraVolumeMounts:\n  #     - name: my-templated-extra-volume\n  #       mountPath: \"{{ .Values.my_custom_path }}\"\n  #       readOnly: true\n  extraVolumes: []\n  extraVolumeMounts: []\n\n  # Launch additional containers into pgbouncer.\n  extraContainers: []\n\n  # Select certain nodes for PgBouncer pods.\n  nodeSelector:\n    airflow-node: \"true\"\n\n  affinity: {}\n  tolerations: []\n  topologySpreadConstraints: []\n\n  priorityClassName: ~\n\n  uid: 65534\n\n  # Detailed default security context for pgbouncer for container level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks:\n    preStop:\n      exec:\n        # Allow existing queries clients to complete within 120 seconds\n        command: [\"/bin/sh\", \"-c\", \"killall -INT pgbouncer \u0026\u0026 sleep 120\"]\n\n  metricsExporterSidecar:\n    resources: {}\n    #  limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    #  requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n    sslmode: \"disable\"\n\n    # supply the name of existing secret with PGBouncer connection URI containing\n    # stats user and password.\n    # you can load them to a k8s secret like the one below\n    #  apiVersion: v1\n    #  kind: Secret\n    #  metadata:\n    #    name: pgbouncer-stats-secret\n    #  data:\n    #     connection: postgresql://\u003cstats user\u003e:\u003cpassword\u003e@127.0.0.1:6543/pgbouncer?\u003cconnection params\u003e\n    #  type: Opaque\n    #\n    #  statsSecretName: pgbouncer-stats-secret\n    #\n    statsSecretName: ~\n\n    # Key containing the PGBouncer connection URI, defaults to `connection` if not defined\n    statsSecretKey: ~\n\n    # Detailed default security context for metricsExporterSidecar for container level\n    securityContexts:\n      container: {}\n\n    # container level lifecycle hooks\n    containerLifecycleHooks: {}\n\n    livenessProbe:\n      initialDelaySeconds: 10\n      periodSeconds: 10\n      timeoutSeconds: 1\n\n    readinessProbe:\n      initialDelaySeconds: 10\n      periodSeconds: 10\n      timeoutSeconds: 1\n\n  # Environment variables to add to pgbouncer container\n  env: []\n\n# Configuration for the redis provisioned by the chart\nredis:\n  enabled: true\n  terminationGracePeriodSeconds: 600\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to worker kubernetes service account.\n    annotations: {}\n\n  persistence:\n    # Enable persistent volumes\n    enabled: true\n    # Volume size for worker StatefulSet\n    size: 1Gi\n    # If using a custom storageClass, pass name ref to all statefulSets here\n    storageClassName:\n    # Annotations to add to redis volumes\n    annotations: {}\n\n  # Configuration for empty dir volume (if redis.persistence.enabled == false)\n  # emptyDirConfig:\n  #   sizeLimit: 1Gi\n  #   medium: Memory\n\n  resources: {}\n  #  limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  #  requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\n  # If set use as redis secret. Make sure to also set data.brokerUrlSecretName value.\n  passwordSecretName: ~\n\n  # Else, if password is set, create secret with it,\n  # Otherwise a new password will be generated on install\n  # Note: password can only be set during install, not upgrade.\n  password: ~\n\n  # This setting tells kubernetes that its ok to evict\n  # when it wants to scale a node down.\n  safeToEvict: true\n\n  # Select certain nodes for redis pods.\n  nodeSelector:\n    airflow-node: \"true\"\n\n  affinity: {}\n  tolerations: []\n  topologySpreadConstraints: []\n  priorityClassName: ~\n\n  # Set to 0 for backwards-compatiblity\n  uid: 0\n  # If not set, `redis.uid` will be used\n  securityContext: {}\n  #  runAsUser: 999\n  #  runAsGroup: 0\n\n  # Detailed default security context for redis for container and pod level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  podAnnotations: {}\n# Auth secret for a private registry\n# This is used if pulling airflow images from a private registry\nregistry:\n  secretName: ~\n\n  # Example:\n  # connection:\n  #   user: ~\n  #   pass: ~\n  #   host: ~\n  #   email: ~\n  connection: {}\n\n# Elasticsearch logging configuration\nelasticsearch:\n  # Enable elasticsearch task logging\n  enabled: false\n  # A secret containing the connection\n  secretName: ~\n  # Or an object representing the connection\n  # Example:\n  # connection:\n  #   scheme: ~\n  #   user: ~\n  #   pass: ~\n  #   host: ~\n  #   port: ~\n  connection: {}\n\n# All ports used by chart\nports:\n  flowerUI: 5555\n  airflowUI: 8080\n  workerLogs: 8793\n  triggererLogs: 8794\n  redisDB: 6379\n  statsdIngest: 9125\n  statsdScrape: 9102\n  pgbouncer: 6543\n  pgbouncerScrape: 9127\n\n# Define any ResourceQuotas for namespace\nquotas: {}\n\n# Define default/max/min values for pods and containers in namespace\nlimits: []\n\n# This runs as a CronJob to cleanup old pods.\ncleanup:\n  enabled: true\n  # Run every 15 minutes (templated).\n  schedule: \"*/15 * * * *\"\n  # To select a random-ish, deterministic starting minute between 3 and 12 inclusive for each release:\n  #     '{{- add 3 (regexFind \".$\" (adler32sum .Release.Name)) -}}-59/15 * * * *'\n  # To select the last digit of unix epoch time as the starting minute on each deploy:\n  #     '{{- now | unixEpoch | trunc -1 -}}-59/* * * * *'\n\n  # Command to use when running the cleanup cronjob (templated).\n  command: ~\n  # Args to use when running the cleanup cronjob (templated).\n  args: [\"bash\", \"-c\", \"exec airflow kubernetes cleanup-pods --namespace={{ .Release.Namespace }}\"]\n\n  # jobAnnotations are annotations on the cleanup CronJob\n  jobAnnotations: {}\n\n  # Select certain nodes for airflow cleanup pods.\n  nodeSelector:\n    airflow-node: \"true\"\n  affinity: {}\n  tolerations: []\n  topologySpreadConstraints: []\n\n  podAnnotations: {}\n\n  # Labels specific to cleanup objects and pods\n  labels: {}\n\n  resources: {}\n  #  limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  #  requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\n  # Create ServiceAccount\n  serviceAccount:\n    # default value is true\n    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    automountServiceAccountToken: true\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use.\n    # If not set and create is true, a name is generated using the release name\n    name: ~\n\n    # Annotations to add to cleanup cronjob kubernetes service account.\n    annotations: {}\n\n  # When not set, the values defined in the global securityContext will be used\n  securityContext: {}\n  #  runAsUser: 50000\n  #  runAsGroup: 0\n  env: []\n\n  # Detailed default security context for cleanup for container level\n  securityContexts:\n    pod: {}\n    container: {}\n\n  # container level lifecycle hooks\n  containerLifecycleHooks: {}\n\n  # Specify history limit\n  # When set, overwrite the default k8s number of successful and failed CronJob executions that are saved.\n  failedJobsHistoryLimit: ~\n  successfulJobsHistoryLimit: ~\n\n# Configuration for postgresql subchart\n# Not recommended for production\npostgresql:\n  enabled: false\n  auth:\n    enablePostgresUser: true\n    postgresPassword: postgres\n    username: \"\"\n    password: \"\"\n\n# Config settings to go into the mounted airflow.cfg\n#\n# Please note that these values are passed through the `tpl` function, so are\n# all subject to being rendered as go templates. If you need to include a\n# literal `{{` in a value, it must be expressed like this:\n#\n#    a: '{{ \"{{ not a template }}\" }}'\n#\n# Do not set config containing secrets via plain text values, use Env Var or k8s secret object\n# yamllint disable rule:line-length\nconfig:\n  core:\n    dags_folder: '{{ include \"airflow_dags\" . }}'\n    # This is ignored when used with the official Docker image\n    load_examples: 'False'\n    executor: '{{ .Values.executor }}'\n    # For Airflow 1.10, backward compatibility; moved to [logging] in 2.0\n    colored_console_log: 'True'\n    remote_logging: '{{- ternary \"True\" \"False\" .Values.elasticsearch.enabled }}'\n  logging:\n    remote_logging: '{{- ternary \"True\" \"False\" .Values.elasticsearch.enabled }}'\n    colored_console_log: 'True'\n  metrics:\n    statsd_on: '{{ ternary \"True\" \"False\" .Values.statsd.enabled }}'\n    statsd_port: 9125\n    statsd_prefix: airflow\n    statsd_host: '{{ printf \"%s-statsd\" (include \"airflow.fullname\" .) }}'\n  webserver:\n    enable_proxy_fix: 'True'\n    # For Airflow 1.10\n    rbac: 'True'\n  celery:\n    flower_url_prefix: '{{ ternary \"\" .Values.ingress.flower.path (eq .Values.ingress.flower.path \"/\") }}'\n    worker_concurrency: 16\n  scheduler:\n    standalone_dag_processor: '{{ ternary \"True\" \"False\" .Values.dagProcessor.enabled }}'\n    # statsd params included for Airflow 1.10 backward compatibility; moved to [metrics] in 2.0\n    statsd_on: '{{ ternary \"True\" \"False\" .Values.statsd.enabled }}'\n    statsd_port: 9125\n    statsd_prefix: airflow\n    statsd_host: '{{ printf \"%s-statsd\" (include \"airflow.fullname\" .) }}'\n    # `run_duration` included for Airflow 1.10 backward compatibility; removed in 2.0.\n    run_duration: 41460\n  elasticsearch:\n    json_format: 'True'\n    log_id_template: \"{dag_id}_{task_id}_{execution_date}_{try_number}\"\n  elasticsearch_configs:\n    max_retries: 3\n    timeout: 30\n    retry_timeout: 'True'\n  kerberos:\n    keytab: '{{ .Values.kerberos.keytabPath }}'\n    reinit_frequency: '{{ .Values.kerberos.reinitFrequency }}'\n    principal: '{{ .Values.kerberos.principal }}'\n    ccache: '{{ .Values.kerberos.ccacheMountPath }}/{{ .Values.kerberos.ccacheFileName }}'\n  celery_kubernetes_executor:\n    kubernetes_queue: 'kubernetes'\n  # The `kubernetes` section is deprecated in Airflow \u003e= 2.5.0 due to an airflow.cfg schema change.\n  # The `kubernetes` section can be removed once the helm chart no longer supports Airflow \u003c 2.5.0.\n  kubernetes:\n    namespace: '{{ .Release.Namespace }}'\n    # The following `airflow_` entries are for Airflow 1, and can be removed when it is no longer supported.\n    airflow_configmap: '{{ include \"airflow_config\" . }}'\n    airflow_local_settings_configmap: '{{ include \"airflow_config\" . }}'\n    pod_template_file: '{{ include \"airflow_pod_template_file\" . }}/pod_template_file.yaml'\n    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}'\n    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}'\n    multi_namespace_mode: '{{ ternary \"True\" \"False\" .Values.multiNamespaceMode }}'\n  # The `kubernetes_executor` section duplicates the `kubernetes` section in Airflow \u003e= 2.5.0 due to an airflow.cfg schema change.\n  kubernetes_executor:\n    namespace: '{{ .Release.Namespace }}'\n    pod_template_file: '{{ include \"airflow_pod_template_file\" . }}/pod_template_file.yaml'\n    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}'\n    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}'\n    multi_namespace_mode: '{{ ternary \"True\" \"False\" .Values.multiNamespaceMode }}'\n  triggerer:\n    default_capacity: 1000\n# yamllint enable rule:line-length\n\n# Whether Airflow can launch workers and/or pods in multiple namespaces\n# If true, it creates ClusterRole/ClusterRolebinding (with access to entire cluster)\nmultiNamespaceMode: false\n\n# `podTemplate` is a templated string containing the contents of `pod_template_file.yaml` used for\n# KubernetesExecutor workers. The default `podTemplate` will use normal `workers` configuration parameters\n# (e.g. `workers.resources`). As such, you normally won't need to override this directly, however,\n# you can still provide a completely custom `pod_template_file.yaml` if desired.\n# If not set, a default one is created using `files/pod-template-file.kubernetes-helm-yaml`.\npodTemplate: ~\n# The following example is NOT functional, but meant to be illustrative of how you can provide a custom\n# `pod_template_file`. You're better off starting with the default in\n# `files/pod-template-file.kubernetes-helm-yaml` and modifying from there.\n# We will set `priorityClassName` in this example:\n# podTemplate: |\n#   apiVersion: v1\n#   kind: Pod\n#   metadata:\n#     name: placeholder-name\n#     labels:\n#       tier: airflow\n#       component: worker\n#       release: {{ .Release.Name }}\n#   spec:\n#     priorityClassName: high-priority\n#     containers:\n#       - name: base\n#         ...\n\n# Git sync\ndags:\n  # Where dags volume will be mounted. Works for both persistence and gitSync.\n  # If not specified, dags mount path will be set to $AIRFLOW_HOME/dags\n  mountPath: ~\n  persistence:\n    # Annotations for dags PVC\n    annotations: {}\n    # Enable persistent volume for storing dags\n    enabled: false\n    # Volume size for dags\n    size: 1Gi\n    # If using a custom storageClass, pass name here\n    storageClassName:\n    # access mode of the persistent volume\n    accessMode: ReadWriteOnce\n    ## the name of an existing PVC to use\n    existingClaim:\n    ## optional subpath for dag volume mount\n    subPath: ~\n  gitSync:\n    enabled: true\n\n    # git repo clone url\n    # ssh example: git@github.com:apache/airflow.git\n    # https example: https://github.com/apache/airflow.git\n    repo: https://github.com/Bifrost3-0/airflow_bifrost\n    branch: main\n    rev: HEAD\n    # The git revision (branch, tag, or hash) to check out, v4 only\n    ref: v1.0.0\n    depth: 1\n    # the number of consecutive failures allowed before aborting\n    maxFailures: 0\n    # subpath within the repo where dags are located\n    # should be \"\" if dags are at repo root\n    subPath: \"production/dags\"\n    # if your repo needs a user name password\n    # you can load them to a k8s secret like the one below\n    #   ---\n    #   apiVersion: v1\n    #   kind: Secret\n    #   metadata:\n    #     name: git-credentials\n    #   data:\n    #     # For git-sync v3\n    #     GIT_SYNC_USERNAME: \u003cbase64_encoded_git_username\u003e\n    #     GIT_SYNC_PASSWORD: \u003cbase64_encoded_git_password\u003e\n    #     # For git-sync v4\n    #     GITSYNC_USERNAME: \u003cbase64_encoded_git_username\u003e\n    #     GITSYNC_PASSWORD: \u003cbase64_encoded_git_password\u003e\n    # and specify the name of the secret below\n    #\n    credentialsSecret: git-credentials\n    #\n    #\n    # If you are using an ssh clone url, you can load\n    # the ssh private key to a k8s secret like the one below\n    #   ---\n    #   apiVersion: v1\n    #   kind: Secret\n    #   metadata:\n    #     name: airflow-ssh-secret\n    #   data:\n    #     # key needs to be gitSshKey\n    #     gitSshKey: \u003cbase64_encoded_data\u003e\n    # and specify the name of the secret below\n    # sshKeySecret: airflow-ssh-secret\n    #\n    # If you are using an ssh private key, you can additionally\n    # specify the content of your known_hosts file, example:\n    #\n    # knownHosts: |\n    #    \u003chost1\u003e,\u003cip1\u003e \u003ckey1\u003e\n    #    \u003chost2\u003e,\u003cip2\u003e \u003ckey2\u003e\n\n    # interval between git sync attempts in seconds\n    # high values are more likely to cause DAGs to become out of sync between different components\n    # low values cause more traffic to the remote git repository\n    # Go-style duration string (e.g. \"100ms\" or \"0.1s\" = 100ms).\n    # For backwards compatibility, wait will be used if it is specified.\n    period: 5s\n    wait: ~\n\n    containerName: git-sync\n    uid: 65533\n\n    # When not set, the values defined in the global securityContext will be used\n    securityContext: {}\n    #  runAsUser: 65533\n    #  runAsGroup: 0\n\n    securityContexts:\n      container: {}\n\n    # container level lifecycle hooks\n    containerLifecycleHooks: {}\n\n    # Mount additional volumes into git-sync. It can be templated like in the following example:\n    #   extraVolumeMounts:\n    #     - name: my-templated-extra-volume\n    #       mountPath: \"{{ .Values.my_custom_path }}\"\n    #       readOnly: true\n    extraVolumeMounts: []\n    env: []\n    # Supported env vars for gitsync can be found at https://github.com/kubernetes/git-sync\n    # - name: \"\"\n    #   value: \"\"\n\n    # Configuration for empty dir volume\n    # emptyDirConfig:\n    #   sizeLimit: 1Gi\n    #   medium: Memory\n\n    resources: {}\n    #  limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    #  requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n\nlogs:\n  # Configuration for empty dir volume (if logs.persistence.enabled == false)\n  # emptyDirConfig:\n  #   sizeLimit: 1Gi\n  #   medium: Memory\n\n  persistence:\n    # Enable persistent volume for storing logs\n    enabled: false\n    # Volume size for logs\n    size: 100Gi\n    # Annotations for the logs PVC\n    annotations: {}\n    # If using a custom storageClass, pass name here\n    storageClassName:\n    ## the name of an existing PVC to use\n    existingClaim:\n"
            ],
            "verify": false,
            "version": "1.13.1",
            "wait": false,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_namespace.datalake_ns-namespace",
            "kubernetes_secret_v1.airflow"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "authv3_redis",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "redis",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "authv3-redis",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "7.2.5",
                "chart": "redis",
                "name": "authv3-redis",
                "namespace": "datalake",
                "revision": 1,
                "values": "{\"auth\":{\"enabled\":false},\"master\":{\"resourcesPreset\":\"small\"},\"replica\":{\"resourcesPreset\":\"small\"}}",
                "version": "19.6.2"
              }
            ],
            "name": "authv3-redis",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://charts.bitnami.com/bitnami",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [
              {
                "name": "auth.enabled",
                "type": "",
                "value": "false"
              },
              {
                "name": "master.resourcesPreset",
                "type": "",
                "value": "small"
              },
              {
                "name": "replica.resourcesPreset",
                "type": "",
                "value": "small"
              }
            ],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "19.6.2",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "influxdb_operator",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "influxdb2",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "influxdb",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "2.7.4",
                "chart": "influxdb2",
                "name": "influxdb",
                "namespace": "datalake",
                "revision": 1,
                "values": "{\"adminUser\":{\"bucket\":\"default\",\"organization\":\"influxdata\",\"password\":\"Maniac321.\",\"retention_policy\":\"0s\",\"token\":\"\",\"user\":\"admin\"},\"affinity\":{},\"env\":{},\"fullnameOverride\":\"\",\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"influxdb\",\"tag\":\"2.7.4-alpine\"},\"ingress\":{\"annotations\":{},\"enabled\":false,\"hostname\":\"influxdb.foobar.com\",\"path\":\"/\",\"tls\":false},\"initScripts\":{\"enabled\":false,\"scripts\":{\"init.sh\":\"#!/bin/bash\\ninflux apply --force yes -u https://raw.githubusercontent.com/influxdata/community-templates/master/influxdb2_operational_monitoring/influxdb2_operational_monitoring.yml\\n\"}},\"livenessProbe\":{},\"nameOverride\":\"\",\"nodeSelector\":{},\"pdb\":{\"create\":true,\"minAvailable\":1},\"persistence\":{\"accessMode\":\"ReadWriteOnce\",\"enabled\":true,\"mountPath\":\"/var/lib/influxdb2\",\"size\":\"25Gi\",\"subPath\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"readinessProbe\":{},\"resources\":{},\"securityContext\":{},\"service\":{\"annotations\":{},\"labels\":{},\"port\":80,\"portName\":\"http\",\"targetPort\":8086,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":null},\"startupProbe\":{\"enabled\":false},\"tolerations\":[]}",
                "version": "2.1.2"
              }
            ],
            "name": "influxdb",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://helm.influxdata.com",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "image:\n  repository: influxdb\n  tag: 2.7.4-alpine\n  pullPolicy: IfNotPresent\n  ## If specified, use these secrets to access the images\n  # pullSecrets:\n  #   - registry-secret\n\n## Annotations to be added to InfluxDB pods\n##\npodAnnotations: {}\n\n## Labels to be added to InfluxDB pods\n##\npodLabels: {}\n\nnameOverride: \"\"\nfullnameOverride: \"\"\n\n## Configure resource requests and limits\n## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n##\nresources: {}\n# We usually recommend not to specify default resources and to leave this as a conscious\n# choice for the user. This also increases chances charts run on environments with little\n# resources, such as Minikube. If you do want to specify resources, uncomment the following\n# lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n# limits:\n#  cpu: 100m\n#  memory: 128Mi\n# requests:\n#  cpu: 100m\n#  memory: 128Mi\n\n## Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n\n## Tolerations for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n\n## Affinity for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n\nsecurityContext: {}\n\n## Customize liveness, readiness and startup probes\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n##\nlivenessProbe: {}\n# path: \"/health\"\n# scheme: \"HTTP\"\n# initialDelaySeconds: 0\n# periodSeconds: 10\n# timeoutSeconds: 1\n# failureThreshold: 3\n\nreadinessProbe: {}\n# path: \"/health\"\n# scheme: \"HTTP\"\n# initialDelaySeconds: 0\n# periodSeconds: 10\n# timeoutSeconds: 1\n# successThreshold: 1\n# failureThreshold: 3\n\nstartupProbe:\n  enabled: false\n  # path: \"/health\"\n  # scheme: \"HTTP\"\n  # initialDelaySeconds: 30\n  # periodSeconds: 5\n  # timeoutSeconds: 1\n  # failureThreshold: 6\n\n## Extra environment variables to configure influxdb\n## e.g.\n# env:\n#   - name: FOO\n#     value: BAR\n#   - name: BAZ\n#     valueFrom:\n#       secretKeyRef:\n#         name: my-secret\n#         key: my-key\nenv: {}\n\n## Create default user through docker entrypoint\n## Defaults indicated below\n##\nadminUser:\n  organization: \"influxdata\"\n  bucket: \"default\"\n  user: \"admin\"\n  retention_policy: \"0s\"\n  ## Leave empty to generate a random password and token.\n  ## Or fill any of these values to use fixed values.\n  password: \"Maniac321.\"\n  token: \"\"\n\n  ## The password and token are obtained from an existing secret. The expected\n  ## keys are `admin-password` and `admin-token`.\n  ## If set, the password and token values above are ignored.\n  # existingSecret: influxdb-auth\n\n## Persist data to a persistent volume\n##\npersistence:\n  enabled: true\n  ## If true will use an existing PVC instead of creating one\n  # useExisting: false\n  ## Name of existing PVC to be used in the influx deployment\n  # name:\n  ## influxdb data Persistent Volume Storage Class\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS \u0026 OpenStack)\n  ##\n  # storageClass: \"-\"\n  accessMode: ReadWriteOnce\n  size: 25Gi\n  mountPath: /var/lib/influxdb2\n  subPath: \"\"\n\n## Add custom volume and volumeMounts\n##\n# volumes:\n#   - name: influxdb2-templates\n#     hostPath:\n#       path: /data/influxdb2-templates\n#       type: Directory\n# mountPoints:\n#   - name: influxdb2-templates\n#     mountPath: /influxdb2-templates\n#     readOnly: true\n\n## Allow executing custom init scripts\n## If the container finds any files with the .sh extension inside of the\n## /docker-entrypoint-initdb.d folder, it will execute them.\n## When multiple scripts are present, they will be executed in lexical sort order by name.\n## For more details see Custom Initialization Scripts in https://hub.docker.com/_/influxdb\ninitScripts:\n  enabled: false\n  scripts:\n    init.sh: |\n      #!/bin/bash\n      influx apply --force yes -u https://raw.githubusercontent.com/influxdata/community-templates/master/influxdb2_operational_monitoring/influxdb2_operational_monitoring.yml\n\n## Specify a service type\n## ref: http://kubernetes.io/docs/user-guide/services/\n##\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 8086\n  annotations: {}\n  labels: {}\n  portName: http\n\nserviceAccount:\n  # Specifies whether a ServiceAccount should be created\n  create: true\n  # The name of the ServiceAccount to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name:\n  # Annotations for the ServiceAccount\n  annotations: {}\n\ningress:\n  enabled: false\n  # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\n  # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\n  # className: nginx\n  tls: false\n  # secretName: my-tls-cert # only needed if tls above is true or default certificate is not configured for Nginx\n  hostname: influxdb.foobar.com\n  annotations: {}\n  # kubernetes.io/ingress.class: \"nginx\"\n  # kubernetes.io/tls-acme: \"true\"\n  path: /\n\n## Pod disruption budget configuration\n##\npdb:\n  ## Specifies whether a Pod disruption budget should be created\n  ##\n  create: true\n  minAvailable: 1\n  # maxUnavailable: 1\n"
            ],
            "verify": false,
            "version": "2.1.2",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "loki_name",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "loki-distributed",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "loki",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "2.9.6",
                "chart": "loki-distributed",
                "name": "loki",
                "namespace": "monitoring",
                "revision": 3,
                "values": "{\"compactor\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.compactorSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.compactorSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"appProtocol\":{\"grpc\":\"\"},\"command\":null,\"enabled\":false,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"initContainers\":[],\"kind\":\"StatefulSet\",\"livenessProbe\":{},\"nodeSelector\":{},\"persistence\":{\"annotations\":{},\"claims\":[{\"name\":\"data\",\"size\":\"10Gi\",\"storageClass\":null}],\"enableStatefulSetAutoDeletePVC\":false,\"enabled\":false,\"size\":\"10Gi\",\"storageClass\":null,\"whenDeleted\":\"Retain\",\"whenScaled\":\"Retain\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"readinessProbe\":{},\"replicas\":1,\"resources\":{},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":false,\"imagePullSecrets\":[],\"name\":null},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[]},\"distributor\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.distributorSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.distributorSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"appProtocol\":{\"grpc\":\"\"},\"autoscaling\":{\"behavior\":{\"enabled\":false,\"scaleDown\":{},\"scaleUp\":{}},\"customMetrics\":[],\"enabled\":false,\"maxReplicas\":3,\"minReplicas\":1,\"targetCPUUtilizationPercentage\":60,\"targetMemoryUtilizationPercentage\":null},\"command\":null,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"maxSurge\":0,\"maxUnavailable\":null,\"nodeSelector\":{\"airflow\":\"nodeok\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[]},\"fullnameOverride\":null,\"gateway\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.gatewaySelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.gatewaySelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"autoscaling\":{\"behavior\":{\"enabled\":false,\"scaleDown\":{},\"scaleUp\":{}},\"customMetrics\":[],\"enabled\":false,\"maxReplicas\":3,\"minReplicas\":1,\"targetCPUUtilizationPercentage\":60,\"targetMemoryUtilizationPercentage\":null},\"basicAuth\":{\"enabled\":false,\"existingSecret\":null,\"htpasswd\":\"{{ htpasswd (required \\\"'gateway.basicAuth.username' is required\\\" .Values.gateway.basicAuth.username) (required \\\"'gateway.basicAuth.password' is required\\\" .Values.gateway.basicAuth.password) }}\",\"password\":null,\"username\":null},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true},\"deploymentStrategy\":{\"type\":\"RollingUpdate\"},\"dnsConfig\":{},\"enabled\":true,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"docker.io\",\"repository\":\"nginxinc/nginx-unprivileged\",\"tag\":\"1.20.2-alpine\"},\"ingress\":{\"annotations\":{},\"enabled\":false,\"hosts\":[{\"host\":\"gateway.loki.example.com\",\"paths\":[{\"path\":\"/\"}]}],\"ingressClassName\":\"\",\"tls\":[]},\"livenessProbe\":{\"httpGet\":{\"path\":\"/\",\"port\":\"http\"},\"initialDelaySeconds\":30},\"maxUnavailable\":null,\"nginxConfig\":{\"file\":\"worker_processes  5;  ## Default: 1\\nerror_log  /dev/stderr;\\npid        /tmp/nginx.pid;\\nworker_rlimit_nofile 8192;\\n\\nevents {\\n  worker_connections  4096;  ## Default: 1024\\n}\\n\\nhttp {\\n  client_body_temp_path /tmp/client_temp;\\n  proxy_temp_path       /tmp/proxy_temp_path;\\n  fastcgi_temp_path     /tmp/fastcgi_temp;\\n  uwsgi_temp_path       /tmp/uwsgi_temp;\\n  scgi_temp_path        /tmp/scgi_temp;\\n\\n  proxy_http_version    1.1;\\n\\n  default_type application/octet-stream;\\n  log_format   {{ .Values.gateway.nginxConfig.logFormat }}\\n\\n  {{- if .Values.gateway.verboseLogging }}\\n  access_log   /dev/stderr  main;\\n  {{- else }}\\n\\n  map $status $loggable {\\n    ~^[23]  0;\\n    default 1;\\n  }\\n  access_log   /dev/stderr  main  if=$loggable;\\n  {{- end }}\\n\\n  sendfile     on;\\n  tcp_nopush   on;\\n  {{- if .Values.gateway.nginxConfig.resolver }}\\n  resolver {{ .Values.gateway.nginxConfig.resolver }};\\n  {{- else }}\\n  resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};\\n  {{- end }}\\n\\n  {{- with .Values.gateway.nginxConfig.httpSnippet }}\\n  {{ . | nindent 2 }}\\n  {{- end }}\\n\\n  server {\\n    listen             8080;\\n\\n    {{- if .Values.gateway.basicAuth.enabled }}\\n    auth_basic           \\\"Loki\\\";\\n    auth_basic_user_file /etc/nginx/secrets/.htpasswd;\\n    {{- end }}\\n\\n    location = / {\\n      return 200 'OK';\\n      auth_basic off;\\n      access_log off;\\n    }\\n\\n    location = /api/prom/push {\\n      set $api_prom_push_backend http://{{ include \\\"loki.distributorFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\\n      proxy_pass       $api_prom_push_backend:3100$request_uri;\\n      proxy_http_version 1.1;\\n    }\\n\\n    location = /api/prom/tail {\\n      set $api_prom_tail_backend http://{{ include \\\"loki.querierFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\\n      proxy_pass       $api_prom_tail_backend:3100$request_uri;\\n      proxy_set_header Upgrade $http_upgrade;\\n      proxy_set_header Connection \\\"upgrade\\\";\\n      proxy_http_version 1.1;\\n    }\\n\\n    # Ruler\\n    location ~ /prometheus/api/v1/alerts.* {\\n      proxy_pass       http://{{ include \\\"loki.rulerFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;\\n    }\\n    location ~ /prometheus/api/v1/rules.* {\\n      proxy_pass       http://{{ include \\\"loki.rulerFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;\\n    }\\n    location ~ /api/prom/rules.* {\\n      proxy_pass       http://{{ include \\\"loki.rulerFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;\\n    }\\n    location ~ /api/prom/alerts.* {\\n      proxy_pass       http://{{ include \\\"loki.rulerFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;\\n    }\\n\\n    location ~ /api/prom/.* {\\n      set $api_prom_backend http://{{ include \\\"loki.queryFrontendFullname\\\" . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\\n      proxy_pass       $api_prom_backend:3100$request_uri;\\n      proxy_http_version 1.1;\\n    }\\n\\n    location = /loki/api/v1/push {\\n      set $loki_api_v1_push_backend http://{{ include \\\"loki.distributorFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\\n      proxy_pass       $loki_api_v1_push_backend:3100$request_uri;\\n      proxy_http_version 1.1;\\n    }\\n\\n    location = /loki/api/v1/tail {\\n      set $loki_api_v1_tail_backend http://{{ include \\\"loki.querierFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\\n      proxy_pass       $loki_api_v1_tail_backend:3100$request_uri;\\n      proxy_set_header Upgrade $http_upgrade;\\n      proxy_set_header Connection \\\"upgrade\\\";\\n      proxy_http_version 1.1;\\n    }\\n\\n    location ~ /loki/api/.* {\\n      set $loki_api_backend http://{{ include \\\"loki.queryFrontendFullname\\\" . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\\n      proxy_pass       $loki_api_backend:3100$request_uri;\\n      proxy_http_version 1.1;\\n    }\\n\\n    {{- with .Values.gateway.nginxConfig.serverSnippet }}\\n    {{ . | nindent 4 }}\\n    {{- end }}\\n  }\\n}\\n\",\"httpSnippet\":\"\",\"logFormat\":\"main '$remote_addr - $remote_user [$time_local]  $status '\\n        '\\\"$request\\\" $body_bytes_sent \\\"$http_referer\\\" '\\n        '\\\"$http_user_agent\\\" \\\"$http_x_forwarded_for\\\"';\",\"resolver\":\"\",\"serverSnippet\":\"\"},\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"podSecurityContext\":{\"fsGroup\":101,\"runAsGroup\":101,\"runAsNonRoot\":true,\"runAsUser\":101},\"priorityClassName\":null,\"readinessProbe\":{\"httpGet\":{\"path\":\"/\",\"port\":\"http\"},\"initialDelaySeconds\":15,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"service\":{\"annotations\":{},\"appProtocol\":null,\"clusterIP\":null,\"labels\":{},\"loadBalancerIP\":null,\"loadBalancerSourceRanges\":[],\"nodePort\":null,\"port\":80,\"type\":\"ClusterIP\"},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"verboseLogging\":true},\"global\":{\"clusterDomain\":\"cluster.local\",\"dnsNamespace\":\"kube-system\",\"dnsService\":\"kube-dns\",\"image\":{\"registry\":null},\"priorityClassName\":null},\"hostAliases\":[],\"imagePullSecrets\":[],\"indexGateway\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.indexGatewaySelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.indexGatewaySelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"appProtocol\":{\"grpc\":\"\"},\"enabled\":false,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"initContainers\":[],\"joinMemberlist\":true,\"maxUnavailable\":null,\"nodeSelector\":{},\"persistence\":{\"annotations\":{},\"enableStatefulSetAutoDeletePVC\":false,\"enabled\":false,\"inMemory\":false,\"size\":\"10Gi\",\"storageClass\":null,\"whenDeleted\":\"Retain\",\"whenScaled\":\"Retain\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":300,\"tolerations\":[]},\"ingester\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.ingesterSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.ingesterSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"appProtocol\":{\"grpc\":\"\"},\"autoscaling\":{\"behavior\":{\"enabled\":false,\"scaleDown\":{},\"scaleUp\":{}},\"customMetrics\":[],\"enabled\":false,\"maxReplicas\":3,\"minReplicas\":1,\"targetCPUUtilizationPercentage\":60,\"targetMemoryUtilizationPercentage\":null},\"command\":null,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"initContainers\":[],\"kind\":\"StatefulSet\",\"lifecycle\":{},\"livenessProbe\":{},\"maxSurge\":0,\"maxUnavailable\":null,\"nodeSelector\":{},\"persistence\":{\"claims\":[{\"name\":\"data\",\"size\":\"50Gi\",\"storageClass\":null}],\"enableStatefulSetAutoDeletePVC\":false,\"enabled\":true,\"inMemory\":false,\"whenDeleted\":\"Retain\",\"whenScaled\":\"Retain\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"readinessProbe\":{},\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":300,\"tolerations\":[],\"topologySpreadConstraints\":\"- maxSkew: 1\\n  topologyKey: kubernetes.io/hostname\\n  whenUnsatisfiable: ScheduleAnyway\\n  labelSelector:\\n    matchLabels:\\n      {{- include \\\"loki.ingesterSelectorLabels\\\" . | nindent 6 }}\\n\"},\"ingress\":{\"annotations\":{},\"enabled\":false,\"hosts\":[\"loki.example.com\"],\"paths\":{\"distributor\":[\"/api/prom/push\",\"/loki/api/v1/push\"],\"querier\":[\"/api/prom/tail\",\"/loki/api/v1/tail\"],\"query-frontend\":[\"/loki/api\"],\"ruler\":[\"/api/prom/rules\",\"/loki/api/v1/rules\",\"/prometheus/api/v1/rules\",\"/prometheus/api/v1/alerts\"]}},\"loki\":{\"annotations\":{},\"appProtocol\":\"\",\"command\":null,\"config\":\"auth_enabled: false\\n\\nserver:\\n  {{- toYaml .Values.loki.server | nindent 6 }}\\n\\ncommon:\\n  compactor_address: http://{{ include \\\"loki.compactorFullname\\\" . }}:3100\\n\\ndistributor:\\n  ring:\\n    kvstore:\\n      store: memberlist\\n\\nmemberlist:\\n  join_members:\\n    - {{ include \\\"loki.fullname\\\" . }}-memberlist\\n\\ningester_client:\\n  grpc_client_config:\\n    grpc_compression: gzip\\n\\ningester:\\n  lifecycler:\\n    ring:\\n      kvstore:\\n        store: memberlist\\n      replication_factor: 1\\n  chunk_idle_period: 30m\\n  chunk_block_size: 262144\\n  chunk_encoding: snappy\\n  chunk_retain_period: 1m\\n  max_transfer_retries: 0\\n  wal:\\n    dir: /var/loki/wal\\n\\nlimits_config:\\n  enforce_metric_name: false\\n  reject_old_samples: true\\n  reject_old_samples_max_age: 168h\\n  max_cache_freshness_per_query: 10m\\n  split_queries_by_interval: 15m\\n  ingestion_burst_size_mb: 128\\n  ingestion_rate_mb: 64\\n\\n{{- if .Values.loki.schemaConfig}}\\nschema_config:\\n{{- toYaml .Values.loki.schemaConfig | nindent 2}}\\n{{- end}}\\n{{- if .Values.loki.storageConfig}}\\nstorage_config:\\n{{- if .Values.indexGateway.enabled}}\\n{{- $indexGatewayClient := dict \\\"server_address\\\" (printf \\\"dns:///%s:9095\\\" (include \\\"loki.indexGatewayFullname\\\" .)) }}\\n{{- $_ := set .Values.loki.storageConfig.boltdb_shipper \\\"index_gateway_client\\\" $indexGatewayClient }}\\n{{- end}}\\n{{- toYaml .Values.loki.storageConfig | nindent 2}}\\n{{- if .Values.memcachedIndexQueries.enabled }}\\n  index_queries_cache_config:\\n    memcached_client:\\n      addresses: dnssrv+_memcached-client._tcp.{{ include \\\"loki.memcachedIndexQueriesFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}\\n      consistent_hash: true\\n{{- end}}\\n{{- end}}\\n\\nruntime_config:\\n  file: /var/{{ include \\\"loki.name\\\" . }}-runtime/runtime.yaml\\n\\nchunk_store_config:\\n  max_look_back_period: 0s\\n  {{- if .Values.memcachedChunks.enabled }}\\n  chunk_cache_config:\\n    embedded_cache:\\n      enabled: false\\n    memcached_client:\\n      consistent_hash: true\\n      addresses: dnssrv+_memcached-client._tcp.{{ include \\\"loki.memcachedChunksFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}\\n  {{- end }}\\n  {{- if .Values.memcachedIndexWrites.enabled }}\\n  write_dedupe_cache_config:\\n    memcached_client:\\n      consistent_hash: true\\n      addresses: dnssrv+_memcached-client._tcp.{{ include \\\"loki.memcachedIndexWritesFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}\\n  {{- end }}\\n\\ntable_manager:\\n  retention_deletes_enabled: false\\n  retention_period: 0s\\n\\nquery_range:\\n  align_queries_with_step: true\\n  max_retries: 5\\n  cache_results: true\\n  results_cache:\\n    cache:\\n      {{- if .Values.memcachedFrontend.enabled }}\\n      memcached_client:\\n        addresses: dnssrv+_memcached-client._tcp.{{ include \\\"loki.memcachedFrontendFullname\\\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}\\n        consistent_hash: true\\n      {{- else }}\\n      embedded_cache:\\n        enabled: true\\n        ttl: 24h\\n      {{- end }}\\n\\nfrontend_worker:\\n  {{- if .Values.queryScheduler.enabled }}\\n  scheduler_address: {{ include \\\"loki.querySchedulerFullname\\\" . }}:9095\\n  {{- else }}\\n  frontend_address: {{ include \\\"loki.queryFrontendFullname\\\" . }}-headless:9095\\n  {{- end }}\\n\\nfrontend:\\n  log_queries_longer_than: 5s\\n  compress_responses: true\\n  {{- if .Values.queryScheduler.enabled }}\\n  scheduler_address: {{ include \\\"loki.querySchedulerFullname\\\" . }}:9095\\n  {{- end }}\\n  tail_proxy_url: http://{{ include \\\"loki.querierFullname\\\" . }}:3100\\n\\ncompactor:\\n  shared_store: filesystem\\n  working_directory: /var/loki/compactor\\n\\nruler:\\n  storage:\\n    type: local\\n    local:\\n      directory: /etc/loki/rules\\n  ring:\\n    kvstore:\\n      store: memberlist\\n  rule_path: /tmp/loki/scratch\\n  alertmanager_url: https://alertmanager.xx\\n  external_url: https://alertmanager.xx\\n\",\"configAsSecret\":false,\"configSecretAnnotations\":{},\"configSecretLabels\":{},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true},\"existingSecretForConfig\":\"\",\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"docker.io\",\"repository\":\"grafana/loki\",\"tag\":null},\"livenessProbe\":{\"httpGet\":{\"path\":\"/ready\",\"port\":\"http\"},\"initialDelaySeconds\":300},\"podAnnotations\":{},\"podLabels\":{},\"podSecurityContext\":{\"fsGroup\":10001,\"runAsGroup\":10001,\"runAsNonRoot\":true,\"runAsUser\":10001},\"readinessProbe\":{\"httpGet\":{\"path\":\"/ready\",\"port\":\"http\"},\"initialDelaySeconds\":30,\"timeoutSeconds\":1},\"revisionHistoryLimit\":10,\"schemaConfig\":{\"configs\":[{\"from\":\"2020-09-07\",\"index\":{\"period\":\"24h\",\"prefix\":\"loki_index_\"},\"object_store\":\"filesystem\",\"schema\":\"v11\",\"store\":\"boltdb-shipper\"}]},\"server\":{\"http_listen_port\":3100},\"serviceAnnotations\":{},\"storageConfig\":{\"boltdb_shipper\":{\"active_index_directory\":\"/var/loki/index\",\"cache_location\":\"/var/loki/cache\",\"cache_ttl\":\"168h\",\"shared_store\":\"filesystem\"},\"filesystem\":{\"directory\":\"/var/loki/chunks\"}},\"structuredConfig\":{}},\"memcached\":{\"appProtocol\":\"\",\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true},\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"docker.io\",\"repository\":\"memcached\",\"tag\":\"1.6.21-alpine\"},\"livenessProbe\":{\"initialDelaySeconds\":10,\"tcpSocket\":{\"port\":\"http\"}},\"podLabels\":{},\"podSecurityContext\":{\"fsGroup\":11211,\"runAsGroup\":11211,\"runAsNonRoot\":true,\"runAsUser\":11211},\"readinessProbe\":{\"initialDelaySeconds\":5,\"tcpSocket\":{\"port\":\"http\"},\"timeoutSeconds\":1},\"serviceAnnotations\":{}},\"memcachedChunks\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.memcachedChunksSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.memcachedChunksSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"enabled\":false,\"extraArgs\":[\"-I 32m\"],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"hostAliases\":[],\"maxUnavailable\":null,\"nodeSelector\":{},\"persistence\":{\"enabled\":false,\"size\":\"10Gi\",\"storageClass\":null},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"volumeClaimTemplates\":[]},\"memcachedExporter\":{\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true},\"enabled\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"docker.io\",\"repository\":\"prom/memcached-exporter\",\"tag\":\"v0.13.0\"},\"podLabels\":{},\"resources\":{}},\"memcachedFrontend\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.memcachedFrontendSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.memcachedFrontendSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"enabled\":false,\"extraArgs\":[\"-I 32m\"],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"hostAliases\":[],\"maxUnavailable\":1,\"nodeSelector\":{},\"persistence\":{\"enabled\":false,\"size\":\"10Gi\",\"storageClass\":null},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[]},\"memcachedIndexQueries\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.memcachedIndexQueriesSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.memcachedIndexQueriesSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"enabled\":false,\"extraArgs\":[\"-I 32m\"],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"hostAliases\":[],\"maxUnavailable\":null,\"nodeSelector\":{},\"persistence\":{\"enabled\":false,\"size\":\"10Gi\",\"storageClass\":null},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[]},\"memcachedIndexWrites\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.memcachedIndexWritesSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.memcachedIndexWritesSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"enabled\":false,\"extraArgs\":[\"-I 32m\"],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"hostAliases\":[],\"maxUnavailable\":null,\"nodeSelector\":{},\"persistence\":{\"enabled\":false,\"size\":\"10Gi\",\"storageClass\":null},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[]},\"nameOverride\":null,\"networkPolicy\":{\"alertmanager\":{\"namespaceSelector\":{},\"podSelector\":{},\"port\":9093},\"discovery\":{\"namespaceSelector\":{},\"podSelector\":{},\"port\":null},\"enabled\":false,\"externalStorage\":{\"cidrs\":[],\"ports\":[]},\"ingress\":{\"namespaceSelector\":{},\"podSelector\":{}},\"metrics\":{\"cidrs\":[],\"namespaceSelector\":{},\"podSelector\":{}}},\"prometheusRule\":{\"annotations\":{},\"enabled\":false,\"groups\":[],\"labels\":{},\"namespace\":null},\"querier\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.querierSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.querierSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"appProtocol\":{\"grpc\":\"\"},\"autoscaling\":{\"behavior\":{\"enabled\":false,\"scaleDown\":{},\"scaleUp\":{}},\"customMetrics\":[],\"enabled\":false,\"maxReplicas\":3,\"minReplicas\":1,\"targetCPUUtilizationPercentage\":60,\"targetMemoryUtilizationPercentage\":null},\"command\":null,\"dnsConfig\":{},\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"initContainers\":[],\"maxSurge\":0,\"maxUnavailable\":null,\"nodeSelector\":{},\"persistence\":{\"annotations\":{},\"enabled\":false,\"size\":\"10Gi\",\"storageClass\":null},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":\"- maxSkew: 1\\n  topologyKey: kubernetes.io/hostname\\n  whenUnsatisfiable: ScheduleAnyway\\n  labelSelector:\\n    matchLabels:\\n      {{- include \\\"loki.querierSelectorLabels\\\" . | nindent 6 }}\\n\"},\"queryFrontend\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.queryFrontendSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.queryFrontendSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"appProtocol\":{\"grpc\":\"\"},\"autoscaling\":{\"behavior\":{\"enabled\":false,\"scaleDown\":{},\"scaleUp\":{}},\"customMetrics\":[],\"enabled\":false,\"maxReplicas\":3,\"minReplicas\":1,\"targetCPUUtilizationPercentage\":60,\"targetMemoryUtilizationPercentage\":null},\"command\":null,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"maxUnavailable\":null,\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[]},\"queryScheduler\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.querySchedulerSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.querySchedulerSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"appProtocol\":{\"grpc\":\"\"},\"enabled\":false,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"maxUnavailable\":1,\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":2,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[]},\"rbac\":{\"pspEnabled\":false,\"sccEnabled\":false},\"ruler\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.rulerSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.rulerSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"appProtocol\":{\"grpc\":\"\"},\"command\":null,\"directories\":{},\"dnsConfig\":{},\"enabled\":false,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"initContainers\":[],\"kind\":\"Deployment\",\"maxUnavailable\":null,\"nodeSelector\":{},\"persistence\":{\"annotations\":{},\"enabled\":false,\"size\":\"10Gi\",\"storageClass\":null},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"replicas\":1,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":300,\"tolerations\":[]},\"runtimeConfig\":{},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"imagePullSecrets\":[],\"labels\":{},\"name\":null},\"serviceMonitor\":{\"annotations\":{},\"enabled\":false,\"interval\":null,\"labels\":{},\"matchExpressions\":[],\"metricRelabelings\":[],\"namespace\":null,\"namespaceSelector\":{},\"relabelings\":[],\"scheme\":\"http\",\"scrapeTimeout\":null,\"targetLabels\":[],\"tlsConfig\":null},\"tableManager\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          {{- include \\\"loki.tableManagerSelectorLabels\\\" . | nindent 10 }}\\n      topologyKey: kubernetes.io/hostname\\n  preferredDuringSchedulingIgnoredDuringExecution:\\n    - weight: 100\\n      podAffinityTerm:\\n        labelSelector:\\n          matchLabels:\\n            {{- include \\\"loki.tableManagerSelectorLabels\\\" . | nindent 12 }}\\n        topologyKey: failure-domain.beta.kubernetes.io/zone\\n\",\"command\":null,\"enabled\":false,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"registry\":null,\"repository\":null,\"tag\":null},\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":null,\"resources\":{},\"serviceLabels\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[]}}",
                "version": "0.79.0"
              }
            ],
            "name": "loki",
            "namespace": "monitoring",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://grafana.github.io/helm-charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "global:\n  image:\n    # -- Overrides the Docker registry globally for all images\n    registry: null\n  # -- Overrides the priorityClassName for all pods\n  priorityClassName: null\n  # -- configures cluster domain (\"cluster.local\" by default)\n  clusterDomain: \"cluster.local\"\n  # -- configures DNS service name\n  dnsService: \"kube-dns\"\n  # -- configures DNS service namespace\n  dnsNamespace: \"kube-system\"\n\n# -- Overrides the chart's name\nnameOverride: null\n\n# -- Overrides the chart's computed fullname\nfullnameOverride: null\n\n# -- Image pull secrets for Docker images\nimagePullSecrets: []\n\n# -- hostAliases to add\nhostAliases: []\n#  - ip: 1.2.3.4\n#    hostnames:\n#      - domain.tld\n\nloki:\n  # -- If set, these annotations are added to all of the Kubernetes controllers\n  # (Deployments, StatefulSets, etc) that this chart launches. Use this to\n  # implement something like the \"Wave\" controller or another controller that\n  # is monitoring top level deployment resources.\n  annotations: {}\n  # Configures the readiness probe for all of the Loki pods\n  readinessProbe:\n    httpGet:\n      path: /ready\n      port: http\n    initialDelaySeconds: 30\n    timeoutSeconds: 1\n  livenessProbe:\n    httpGet:\n      path: /ready\n      port: http\n    initialDelaySeconds: 300\n  image:\n    # -- The Docker registry\n    registry: docker.io\n    # -- Docker image repository\n    repository: grafana/loki\n    # -- Overrides the image tag whose default is the chart's appVersion\n    tag: null\n    # -- Docker image pull policy\n    pullPolicy: IfNotPresent\n  # -- Common labels for all pods\n  podLabels: {}\n  # -- Common annotations for all pods\n  podAnnotations: {}\n  # -- Common command override for all pods (except gateway)\n  command: null\n  # -- The number of old ReplicaSets to retain to allow rollback\n  revisionHistoryLimit: 10\n  # -- The SecurityContext for Loki pods\n  podSecurityContext:\n    fsGroup: 10001\n    runAsGroup: 10001\n    runAsNonRoot: true\n    runAsUser: 10001\n  # -- The SecurityContext for Loki containers\n  containerSecurityContext:\n    readOnlyRootFilesystem: true\n    capabilities:\n      drop:\n        - ALL\n    allowPrivilegeEscalation: false\n  # -- Specify an existing secret containing loki configuration. If non-empty, overrides `loki.config`\n  existingSecretForConfig: \"\"\n  # -- Store the loki configuration as a secret.\n  configAsSecret: false\n  # -- Annotations for the secret with loki configuration.\n  configSecretAnnotations: {}\n  # -- Additional labels for the secret with loki configuration.\n  configSecretLabels: {}\n  # -- Adds the appProtocol field to the memberlist service. This allows memberlist to work with istio protocol selection. Ex: \"http\" or \"tcp\"\n  appProtocol: \"\"\n  # -- Common annotations for all loki services\n  serviceAnnotations: {}\n  # Loki server configuration\n  # Refers to https://grafana.com/docs/loki/latest/configuration/#server\n  server:\n    # -- HTTP server listen port\n    http_listen_port: 3100\n  # -- Config file contents for Loki\n  # @default -- See values.yaml\n  config: |\n    auth_enabled: false\n\n    server:\n      {{- toYaml .Values.loki.server | nindent 6 }}\n\n    common:\n      compactor_address: http://{{ include \"loki.compactorFullname\" . }}:3100\n\n    distributor:\n      ring:\n        kvstore:\n          store: memberlist\n\n    memberlist:\n      join_members:\n        - {{ include \"loki.fullname\" . }}-memberlist\n\n    ingester_client:\n      grpc_client_config:\n        grpc_compression: gzip\n\n    ingester:\n      lifecycler:\n        ring:\n          kvstore:\n            store: memberlist\n          replication_factor: 1\n      chunk_idle_period: 30m\n      chunk_block_size: 262144\n      chunk_encoding: snappy\n      chunk_retain_period: 1m\n      max_transfer_retries: 0\n      wal:\n        dir: /var/loki/wal\n\n    limits_config:\n      enforce_metric_name: false\n      reject_old_samples: true\n      reject_old_samples_max_age: 168h\n      max_cache_freshness_per_query: 10m\n      split_queries_by_interval: 15m\n      ingestion_burst_size_mb: 128\n      ingestion_rate_mb: 64\n\n    {{- if .Values.loki.schemaConfig}}\n    schema_config:\n    {{- toYaml .Values.loki.schemaConfig | nindent 2}}\n    {{- end}}\n    {{- if .Values.loki.storageConfig}}\n    storage_config:\n    {{- if .Values.indexGateway.enabled}}\n    {{- $indexGatewayClient := dict \"server_address\" (printf \"dns:///%s:9095\" (include \"loki.indexGatewayFullname\" .)) }}\n    {{- $_ := set .Values.loki.storageConfig.boltdb_shipper \"index_gateway_client\" $indexGatewayClient }}\n    {{- end}}\n    {{- toYaml .Values.loki.storageConfig | nindent 2}}\n    {{- if .Values.memcachedIndexQueries.enabled }}\n      index_queries_cache_config:\n        memcached_client:\n          addresses: dnssrv+_memcached-client._tcp.{{ include \"loki.memcachedIndexQueriesFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}\n          consistent_hash: true\n    {{- end}}\n    {{- end}}\n\n    runtime_config:\n      file: /var/{{ include \"loki.name\" . }}-runtime/runtime.yaml\n\n    chunk_store_config:\n      max_look_back_period: 0s\n      {{- if .Values.memcachedChunks.enabled }}\n      chunk_cache_config:\n        embedded_cache:\n          enabled: false\n        memcached_client:\n          consistent_hash: true\n          addresses: dnssrv+_memcached-client._tcp.{{ include \"loki.memcachedChunksFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}\n      {{- end }}\n      {{- if .Values.memcachedIndexWrites.enabled }}\n      write_dedupe_cache_config:\n        memcached_client:\n          consistent_hash: true\n          addresses: dnssrv+_memcached-client._tcp.{{ include \"loki.memcachedIndexWritesFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}\n      {{- end }}\n\n    table_manager:\n      retention_deletes_enabled: false\n      retention_period: 0s\n\n    query_range:\n      align_queries_with_step: true\n      max_retries: 5\n      cache_results: true\n      results_cache:\n        cache:\n          {{- if .Values.memcachedFrontend.enabled }}\n          memcached_client:\n            addresses: dnssrv+_memcached-client._tcp.{{ include \"loki.memcachedFrontendFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}\n            consistent_hash: true\n          {{- else }}\n          embedded_cache:\n            enabled: true\n            ttl: 24h\n          {{- end }}\n\n    frontend_worker:\n      {{- if .Values.queryScheduler.enabled }}\n      scheduler_address: {{ include \"loki.querySchedulerFullname\" . }}:9095\n      {{- else }}\n      frontend_address: {{ include \"loki.queryFrontendFullname\" . }}-headless:9095\n      {{- end }}\n\n    frontend:\n      log_queries_longer_than: 5s\n      compress_responses: true\n      {{- if .Values.queryScheduler.enabled }}\n      scheduler_address: {{ include \"loki.querySchedulerFullname\" . }}:9095\n      {{- end }}\n      tail_proxy_url: http://{{ include \"loki.querierFullname\" . }}:3100\n\n    compactor:\n      shared_store: filesystem\n      working_directory: /var/loki/compactor\n\n    ruler:\n      storage:\n        type: local\n        local:\n          directory: /etc/loki/rules\n      ring:\n        kvstore:\n          store: memberlist\n      rule_path: /tmp/loki/scratch\n      alertmanager_url: https://alertmanager.xx\n      external_url: https://alertmanager.xx\n\n  # -- Check https://grafana.com/docs/loki/latest/configuration/#schema_config for more info on how to configure schemas\n  schemaConfig:\n    configs:\n    - from: \"2020-09-07\"\n      store: boltdb-shipper\n      object_store: filesystem\n      schema: v11\n      index:\n        prefix: loki_index_\n        period: 24h\n\n  # -- Check https://grafana.com/docs/loki/latest/configuration/#storage_config for more info on how to configure storages\n  storageConfig:\n    boltdb_shipper:\n      shared_store: filesystem\n      active_index_directory: /var/loki/index\n      cache_location: /var/loki/cache\n      cache_ttl: 168h\n    filesystem:\n      directory: /var/loki/chunks\n# -- Uncomment to configure each storage individually\n#   azure: {}\n#   gcs: {}\n#   s3: {}\n#   boltdb: {}\n\n  # -- Structured loki configuration, takes precedence over `loki.config`, `loki.schemaConfig`, `loki.storageConfig`\n  structuredConfig: {}\n\n# -- Provides a reloadable runtime configuration file for some specific configuration\nruntimeConfig: {}\n\nserviceAccount:\n  # -- Specifies whether a ServiceAccount should be created\n  create: true\n  # -- The name of the ServiceAccount to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: null\n  # -- Image pull secrets for the service account\n  imagePullSecrets: []\n  # -- Labels for the service account\n  labels: {}\n  # -- Annotations for the service account\n  annotations: {}\n  # -- Set this toggle to false to opt out of automounting API credentials for the service account\n  automountServiceAccountToken: true\n\n# RBAC configuration\nrbac:\n  # -- If pspEnabled true, a PodSecurityPolicy is created for K8s that use psp.\n  pspEnabled: false\n  # -- For OpenShift set pspEnabled to 'false' and sccEnabled to 'true' to use the SecurityContextConstraints.\n  sccEnabled: false\n\n# ServiceMonitor configuration\nserviceMonitor:\n  # -- If enabled, ServiceMonitor resources for Prometheus Operator are created\n  enabled: false\n  # -- Alternative namespace for ServiceMonitor resources\n  namespace: null\n  # -- Namespace selector for ServiceMonitor resources\n  namespaceSelector: {}\n  # -- Optional expressions to match on\n  matchExpressions: []\n    # - key: prometheus.io/service-monitor\n    #   operator: NotIn\n    #   values:\n    #     - \"false\"\n  # -- ServiceMonitor annotations\n  annotations: {}\n  # -- Additional ServiceMonitor labels\n  labels: {}\n  # -- ServiceMonitor scrape interval\n  interval: null\n  # -- ServiceMonitor scrape timeout in Go duration format (e.g. 15s)\n  scrapeTimeout: null\n  # -- ServiceMonitor relabel configs to apply to samples before scraping\n  # https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#relabelconfig\n  relabelings: []\n  # -- ServiceMonitor metric relabel configs to apply to samples before ingestion\n  # https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#endpoint\n  metricRelabelings: []\n  # --ServiceMonitor will add labels from the service to the Prometheus metric\n  # https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#servicemonitorspec\n  targetLabels: []\n  # -- ServiceMonitor will use http by default, but you can pick https as well\n  scheme: http\n  # -- ServiceMonitor will use these tlsConfig settings to make the health check requests\n  tlsConfig: null\n\n# Rules for the Prometheus Operator\nprometheusRule:\n  # -- If enabled, a PrometheusRule resource for Prometheus Operator is created\n  enabled: false\n  # -- Alternative namespace for the PrometheusRule resource\n  namespace: null\n  # -- PrometheusRule annotations\n  annotations: {}\n  # -- Additional PrometheusRule labels\n  labels: {}\n  # -- Contents of Prometheus rules file\n  groups: []\n  #  - name: loki_rules\n  #    rules:\n  #      - expr: histogram_quantile(0.99, sum(rate(loki_request_duration_seconds_bucket[1m]))\n  #          by (le, cluster, job))\n  #        record: cluster_job:loki_request_duration_seconds:99quantile\n  #      - expr: histogram_quantile(0.50, sum(rate(loki_request_duration_seconds_bucket[1m]))\n  #          by (le, cluster, job))\n  #        record: cluster_job:loki_request_duration_seconds:50quantile\n  #      - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, job) / sum(rate(loki_request_duration_seconds_count[1m]))\n  #          by (cluster, job)\n  #        record: cluster_job:loki_request_duration_seconds:avg\n  #      - expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, cluster, job)\n  #        record: cluster_job:loki_request_duration_seconds_bucket:sum_rate\n  #      - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, job)\n  #        record: cluster_job:loki_request_duration_seconds_sum:sum_rate\n  #      - expr: sum(rate(loki_request_duration_seconds_count[1m])) by (cluster, job)\n  #        record: cluster_job:loki_request_duration_seconds_count:sum_rate\n  #      - expr: histogram_quantile(0.99, sum(rate(loki_request_duration_seconds_bucket[1m]))\n  #          by (le, cluster, job, route))\n  #        record: cluster_job_route:loki_request_duration_seconds:99quantile\n  #      - expr: histogram_quantile(0.50, sum(rate(loki_request_duration_seconds_bucket[1m]))\n  #          by (le, cluster, job, route))\n  #        record: cluster_job_route:loki_request_duration_seconds:50quantile\n  #      - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, job, route)\n  #          / sum(rate(loki_request_duration_seconds_count[1m])) by (cluster, job, route)\n  #        record: cluster_job_route:loki_request_duration_seconds:avg\n  #      - expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, cluster, job,\n  #          route)\n  #        record: cluster_job_route:loki_request_duration_seconds_bucket:sum_rate\n  #      - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, job, route)\n  #        record: cluster_job_route:loki_request_duration_seconds_sum:sum_rate\n  #      - expr: sum(rate(loki_request_duration_seconds_count[1m])) by (cluster, job, route)\n  #        record: cluster_job_route:loki_request_duration_seconds_count:sum_rate\n  #      - expr: histogram_quantile(0.99, sum(rate(loki_request_duration_seconds_bucket[1m]))\n  #          by (le, cluster, namespace, job, route))\n  #        record: cluster_namespace_job_route:loki_request_duration_seconds:99quantile\n  #      - expr: histogram_quantile(0.50, sum(rate(loki_request_duration_seconds_bucket[1m]))\n  #          by (le, cluster, namespace, job, route))\n  #        record: cluster_namespace_job_route:loki_request_duration_seconds:50quantile\n  #      - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, namespace,\n  #          job, route) / sum(rate(loki_request_duration_seconds_count[1m])) by (cluster,\n  #          namespace, job, route)\n  #        record: cluster_namespace_job_route:loki_request_duration_seconds:avg\n  #      - expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, cluster, namespace,\n  #          job, route)\n  #        record: cluster_namespace_job_route:loki_request_duration_seconds_bucket:sum_rate\n  #      - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, namespace,\n  #          job, route)\n  #        record: cluster_namespace_job_route:loki_request_duration_seconds_sum:sum_rate\n  #      - expr: sum(rate(loki_request_duration_seconds_count[1m])) by (cluster, namespace,\n  #          job, route)\n  #        record: cluster_namespace_job_route:loki_request_duration_seconds_count:sum_rate\n\n# Configuration for the ingester\ningester:\n  # -- Kind of deployment [StatefulSet/Deployment]\n  kind: StatefulSet\n  # -- Number of replicas for the ingester\n  replicas: 1\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  autoscaling:\n    # -- Enable autoscaling for the ingester\n    enabled: false\n    # -- Minimum autoscaling replicas for the ingester\n    minReplicas: 1\n    # -- Maximum autoscaling replicas for the ingester\n    maxReplicas: 3\n    # -- Target CPU utilisation percentage for the ingester\n    targetCPUUtilizationPercentage: 60\n    # -- Target memory utilisation percentage for the ingester\n    targetMemoryUtilizationPercentage: null\n    # -- Allows one to define custom metrics using the HPA/v2 schema (for example, Pods, Object or External metrics)\n    customMetrics: []\n    # - type: Pods\n    #   pods:\n    #     metric:\n    #       name: loki_lines_total\n    #     target:\n    #       type: AverageValue\n    #       averageValue: 10k\n    behavior:\n      # -- Enable autoscaling behaviours\n      enabled: false\n      # -- define scale down policies, must conform to HPAScalingRules\n      scaleDown: {}\n      # -- define scale up policies, must conform to HPAScalingRules\n      scaleUp: {}\n  image:\n    # -- The Docker registry for the ingester image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the ingester image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the ingester image. Overrides `loki.image.tag`\n    tag: null\n  # -- Command to execute instead of defined in Docker image\n  command: null\n  # -- The name of the PriorityClass for ingester pods\n  priorityClassName: null\n  # -- Labels for ingester pods\n  podLabels: {}\n  # -- Annotations for ingester pods\n  podAnnotations: {}\n  # -- Labels for ingestor service\n  serviceLabels: {}\n  # -- Additional CLI args for the ingester\n  extraArgs: []\n  # -- Environment variables to add to the ingester pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the ingester pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the ingester pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the ingester pods\n  extraVolumes: []\n  # -- Resource requests and limits for the ingester\n  resources: {}\n  # -- Containers to add to the ingester pods\n  extraContainers: []\n  # -- Init containers to add to the ingester pods\n  initContainers: []\n  # -- Grace period to allow the ingester to shutdown before it is killed. Especially for the ingestor,\n  # this must be increased. It must be long enough so ingesters can be gracefully shutdown flushing/transferring\n  # all data and to successfully leave the member ring on shutdown.\n  terminationGracePeriodSeconds: 300\n  # -- Lifecycle for the ingester container\n  lifecycle: {}\n  # -- topologySpread for ingester pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Defaults to allow skew no more then 1 node per AZ\n  topologySpreadConstraints: |\n    - maxSkew: 1\n      topologyKey: kubernetes.io/hostname\n      whenUnsatisfiable: ScheduleAnyway\n      labelSelector:\n        matchLabels:\n          {{- include \"loki.ingesterSelectorLabels\" . | nindent 6 }}\n  # -- Affinity for ingester pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.ingesterSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.ingesterSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Max Surge for ingester pods\n  maxSurge: 0\n  # -- Node selector for ingester pods\n  nodeSelector: {}\n  # -- Tolerations for ingester pods\n  tolerations: []\n  # -- readiness probe settings for ingester pods. If empty, use `loki.readinessProbe`\n  readinessProbe: {}\n  # -- liveness probe settings for ingester pods. If empty use `loki.livenessProbe`\n  livenessProbe: {}\n  persistence:\n    # -- Enable creating PVCs which is required when using boltdb-shipper\n    enabled: true\n    # -- Use emptyDir with ramdisk for storage. **Please note that all data in ingester will be lost on pod restart**\n    inMemory: false\n    # -- List of the ingester PVCs\n    # @notationType -- list\n    claims:\n      - name: data\n        size: 50Gi\n        #   -- Storage class to be used.\n        #   If defined, storageClassName: \u003cstorageClass\u003e.\n        #   If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n        #   If empty or set to null, no storageClassName spec is\n        #   set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n        storageClass: null\n      # - name: wal\n      #   size: 150Gi\n    # -- Enable StatefulSetAutoDeletePVC feature\n    enableStatefulSetAutoDeletePVC: false\n    whenDeleted: Retain\n    whenScaled: Retain\n  # -- Adds the appProtocol field to the ingester service. This allows ingester to work with istio protocol selection.\n  appProtocol:\n    # -- Set the optional grpc service protocol. Ex: \"grpc\", \"http2\" or \"https\"\n    grpc: \"\"\n\n# Configuration for the distributor\ndistributor:\n  # -- Number of replicas for the distributor\n  replicas: 1\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  autoscaling:\n    # -- Enable autoscaling for the distributor\n    enabled: false\n    # -- Minimum autoscaling replicas for the distributor\n    minReplicas: 1\n    # -- Maximum autoscaling replicas for the distributor\n    maxReplicas: 3\n    # -- Target CPU utilisation percentage for the distributor\n    targetCPUUtilizationPercentage: 60\n    # -- Target memory utilisation percentage for the distributor\n    targetMemoryUtilizationPercentage: null\n    # -- Allows one to define custom metrics using the HPA/v2 schema (for example, Pods, Object or External metrics)\n    customMetrics: []\n    # - type: Pods\n    #   pods:\n    #     metric:\n    #       name: loki_lines_total\n    #     target:\n    #       type: AverageValue\n    #       averageValue: 10k\n    behavior:\n      # -- Enable autoscaling behaviours\n      enabled: false\n      # -- define scale down policies, must conform to HPAScalingRules\n      scaleDown: {}\n      # -- define scale up policies, must conform to HPAScalingRules\n      scaleUp: {}\n  image:\n    # -- The Docker registry for the distributor image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the distributor image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the distributor image. Overrides `loki.image.tag`\n    tag: null\n  # -- Command to execute instead of defined in Docker image\n  command: null\n  # -- The name of the PriorityClass for distributor pods\n  priorityClassName: null\n  # -- Labels for distributor pods\n  podLabels: {}\n  # -- Annotations for distributor pods\n  podAnnotations: {}\n  # -- Labels for distributor service\n  serviceLabels: {}\n  # -- Additional CLI args for the distributor\n  extraArgs: []\n  # -- Environment variables to add to the distributor pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the distributor pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the distributor pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the distributor pods\n  extraVolumes: []\n  # -- Resource requests and limits for the distributor\n  resources: {}\n  # -- Containers to add to the distributor pods\n  extraContainers: []\n  # -- Grace period to allow the distributor to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for distributor pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.distributorSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.distributorSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Max Surge for distributor pods\n  maxSurge: 0\n  # -- Node selector for distributor pods\n  nodeSelector:\n    airflow: \"nodeok\"\n      # -- Tolerations for distributor pods\n  tolerations: []\n    # -- Adds the appProtocol field to the distributor service. This allows distributor to work with istio protocol selection.\n  appProtocol:\n    # -- Set the optional grpc service protocol. Ex: \"grpc\", \"http2\" or \"https\"\n    grpc: \"\"\n\n# Configuration for the querier\nquerier:\n  # -- Number of replicas for the querier\n  replicas: 1\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  autoscaling:\n    # -- Enable autoscaling for the querier, this is only used if `indexGateway.enabled: true`\n    enabled: false\n    # -- Minimum autoscaling replicas for the querier\n    minReplicas: 1\n    # -- Maximum autoscaling replicas for the querier\n    maxReplicas: 3\n    # -- Target CPU utilisation percentage for the querier\n    targetCPUUtilizationPercentage: 60\n    # -- Target memory utilisation percentage for the querier\n    targetMemoryUtilizationPercentage: null\n    # -- Allows one to define custom metrics using the HPA/v2 schema (for example, Pods, Object or External metrics)\n    customMetrics: []\n    # - type: External\n    #   external:\n    #     metric:\n    #       name: loki_inflight_queries\n    #     target:\n    #       type: AverageValue\n    #       averageValue: 12\n    behavior:\n      # -- Enable autoscaling behaviours\n      enabled: false\n      # -- define scale down policies, must conform to HPAScalingRules\n      scaleDown: {}\n      # -- define scale up policies, must conform to HPAScalingRules\n      scaleUp: {}\n  image:\n    # -- The Docker registry for the querier image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the querier image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the querier image. Overrides `loki.image.tag`\n    tag: null\n  # -- Command to execute instead of defined in Docker image\n  command: null\n  # -- The name of the PriorityClass for querier pods\n  priorityClassName: null\n  # -- Labels for querier pods\n  podLabels: {}\n  # -- Annotations for querier pods\n  podAnnotations: {}\n  # -- Labels for querier service\n  serviceLabels: {}\n  # -- Additional CLI args for the querier\n  extraArgs: []\n  # -- Environment variables to add to the querier pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the querier pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the querier pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the querier pods\n  extraVolumes: []\n  # -- Resource requests and limits for the querier\n  resources: {}\n  # -- Containers to add to the querier pods\n  extraContainers: []\n  # -- Init containers to add to the querier pods\n  initContainers: []\n  # -- Grace period to allow the querier to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- topologySpread for querier pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Defaults to allow skew no more then 1 node per AZ\n  topologySpreadConstraints: |\n    - maxSkew: 1\n      topologyKey: kubernetes.io/hostname\n      whenUnsatisfiable: ScheduleAnyway\n      labelSelector:\n        matchLabels:\n          {{- include \"loki.querierSelectorLabels\" . | nindent 6 }}\n  # -- Affinity for querier pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.querierSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.querierSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Max Surge for querier pods\n  maxSurge: 0\n  # -- Node selector for querier pods\n  nodeSelector: {}\n  # -- Tolerations for querier pods\n  tolerations: []\n  # -- DNSConfig for querier pods\n  dnsConfig: {}\n  persistence:\n    # -- Enable creating PVCs for the querier cache\n    enabled: false\n    # -- Size of persistent disk\n    size: 10Gi\n    # -- Storage class to be used.\n    # If defined, storageClassName: \u003cstorageClass\u003e.\n    # If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n    # If empty or set to null, no storageClassName spec is\n    # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n    storageClass: null\n    # -- Annotations for querier PVCs\n    annotations: {}\n  # -- Adds the appProtocol field to the querier service. This allows querier to work with istio protocol selection.\n  appProtocol:\n    # -- Set the optional grpc service protocol. Ex: \"grpc\", \"http2\" or \"https\"\n    grpc: \"\"\n\n# Configuration for the query-frontend\nqueryFrontend:\n  # -- Number of replicas for the query-frontend\n  replicas: 1\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  autoscaling:\n    # -- Enable autoscaling for the query-frontend\n    enabled: false\n    # -- Minimum autoscaling replicas for the query-frontend\n    minReplicas: 1\n    # -- Maximum autoscaling replicas for the query-frontend\n    maxReplicas: 3\n    # -- Target CPU utilisation percentage for the query-frontend\n    targetCPUUtilizationPercentage: 60\n    # -- Target memory utilisation percentage for the query-frontend\n    targetMemoryUtilizationPercentage: null\n    # -- Allows one to define custom metrics using the HPA/v2 schema (for example, Pods, Object or External metrics)\n    customMetrics: []\n    # - type: Pods\n    #   pods:\n    #     metric:\n    #       name: loki_query_rate\n    #     target:\n    #       type: AverageValue\n    #       averageValue: 100\n    behavior:\n      # -- Enable autoscaling behaviours\n      enabled: false\n      # -- define scale down policies, must conform to HPAScalingRules\n      scaleDown: {}\n      # -- define scale up policies, must conform to HPAScalingRules\n      scaleUp: {}\n  image:\n    # -- The Docker registry for the query-frontend image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the query-frontend image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the query-frontend image. Overrides `loki.image.tag`\n    tag: null\n  # -- Command to execute instead of defined in Docker image\n  command: null\n  # -- The name of the PriorityClass for query-frontend pods\n  priorityClassName: null\n  # -- Labels for query-frontend pods\n  podLabels: {}\n  # -- Annotations for query-frontend pods\n  podAnnotations: {}\n  # -- Labels for query-frontend service\n  serviceLabels: {}\n  # -- Additional CLI args for the query-frontend\n  extraArgs: []\n  # -- Environment variables to add to the query-frontend pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the query-frontend pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the query-frontend pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the query-frontend pods\n  extraVolumes: []\n  # -- Resource requests and limits for the query-frontend\n  resources: {}\n  # -- Containers to add to the query-frontend pods\n  extraContainers: []\n  # -- Grace period to allow the query-frontend to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for query-frontend pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.queryFrontendSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.queryFrontendSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Node selector for query-frontend pods\n  nodeSelector: {}\n  # -- Tolerations for query-frontend pods\n  tolerations: []\n  # -- Adds the appProtocol field to the queryFrontend service. This allows queryFrontend to work with istio protocol selection.\n  appProtocol:\n    # -- Set the optional grpc service protocol. Ex: \"grpc\", \"http2\" or \"https\"\n    grpc: \"\"\n\n# Configuration for the query-scheduler\nqueryScheduler:\n  # -- Specifies whether the query-scheduler should be decoupled from the query-frontend\n  enabled: false\n  # -- Number of replicas for the query-scheduler.\n  # It should be lower than `-querier.max-concurrent` to avoid generating back-pressure in queriers;\n  # it's also recommended that this value evenly divides the latter\n  replicas: 2\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  image:\n    # -- The Docker registry for the query-scheduler image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the query-scheduler image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the query-scheduler image. Overrides `loki.image.tag`\n    tag: null\n  # -- The name of the PriorityClass for query-scheduler pods\n  priorityClassName: null\n  # -- Labels for query-scheduler pods\n  podLabels: {}\n  # -- Annotations for query-scheduler pods\n  podAnnotations: {}\n  # -- Labels for query-scheduler service\n  serviceLabels: {}\n  # -- Additional CLI args for the query-scheduler\n  extraArgs: []\n  # -- Environment variables to add to the query-scheduler pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the query-scheduler pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the query-scheduler pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the query-scheduler pods\n  extraVolumes: []\n  # -- Resource requests and limits for the query-scheduler\n  resources: {}\n  # -- Containers to add to the query-scheduler pods\n  extraContainers: []\n  # -- Grace period to allow the query-scheduler to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for query-scheduler pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.querySchedulerSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.querySchedulerSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: 1\n  # -- Node selector for query-scheduler pods\n  nodeSelector: {}\n  # -- Tolerations for query-scheduler pods\n  tolerations: []\n  # -- Set the optional grpc service protocol. Ex: \"grpc\", \"http2\" or \"https\"\n  appProtocol:\n    grpc: \"\"\n\n# Configuration for the table-manager\ntableManager:\n  # -- Specifies whether the table-manager should be enabled\n  enabled: false\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  image:\n    # -- The Docker registry for the table-manager image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the table-manager image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the table-manager image. Overrides `loki.image.tag`\n    tag: null\n  # -- Command to execute instead of defined in Docker image\n  command: null\n  # -- The name of the PriorityClass for table-manager pods\n  priorityClassName: null\n  # -- Labels for table-manager pods\n  podLabels: {}\n  # -- Annotations for table-manager pods\n  podAnnotations: {}\n  # -- Labels for table-manager service\n  serviceLabels: {}\n  # -- Additional CLI args for the table-manager\n  extraArgs: []\n  # -- Environment variables to add to the table-manager pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the table-manager pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the table-manager pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the table-manager pods\n  extraVolumes: []\n  # -- Resource requests and limits for the table-manager\n  resources: {}\n  # -- Containers to add to the table-manager pods\n  extraContainers: []\n  # -- Grace period to allow the table-manager to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for table-manager pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.tableManagerSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.tableManagerSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Node selector for table-manager pods\n  nodeSelector: {}\n  # -- Tolerations for table-manager pods\n  tolerations: []\n\n# Use either this ingress or the gateway, but not both at once.\n# If you enable this, make sure to disable the gateway.\n# You'll need to supply authn configuration for your ingress controller.\ningress:\n  enabled: false\n#  ingressClassName: nginx\n  annotations: {}\n#    nginx.ingress.kubernetes.io/auth-type: basic\n#    nginx.ingress.kubernetes.io/auth-secret: loki-distributed-basic-auth\n#    nginx.ingress.kubernetes.io/auth-secret-type: auth-map\n#    nginx.ingress.kubernetes.io/configuration-snippet: |\n#      proxy_set_header X-Scope-OrgID $remote_user;\n  paths:\n    distributor:\n      - /api/prom/push\n      - /loki/api/v1/push\n    querier:\n      - /api/prom/tail\n      - /loki/api/v1/tail\n    query-frontend:\n      - /loki/api\n    ruler:\n      - /api/prom/rules\n      - /loki/api/v1/rules\n      - /prometheus/api/v1/rules\n      - /prometheus/api/v1/alerts\n  hosts:\n    - loki.example.com\n  # tls:\n  #   - secretName: loki-distributed-tls\n  #     hosts:\n  #       - loki.example.com\n\n# Configuration for the gateway\ngateway:\n  # -- Specifies whether the gateway should be enabled\n  enabled: true\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  # -- Number of replicas for the gateway\n  replicas: 1\n  # -- Enable logging of 2xx and 3xx HTTP requests\n  verboseLogging: true\n  autoscaling:\n    # -- Enable autoscaling for the gateway\n    enabled: false\n    # -- Minimum autoscaling replicas for the gateway\n    minReplicas: 1\n    # -- Maximum autoscaling replicas for the gateway\n    maxReplicas: 3\n    # -- Target CPU utilisation percentage for the gateway\n    targetCPUUtilizationPercentage: 60\n    # -- Target memory utilisation percentage for the gateway\n    targetMemoryUtilizationPercentage: null\n    # -- Allows one to define custom metrics using the HPA/v2 schema (for example, Resource, Object or External metrics)\n    customMetrics: []\n    # - type: Object\n    #   object:\n    #     metric:\n    #       name: requests-per-second\n    #     describedObject:\n    #       apiVersion: networking.k8s.io/v1\n    #       kind: Ingress\n    #       name: main-route\n    #     target:\n    #       type: Values\n    #       averageValue: 10k\n    behavior:\n      # -- Enable autoscaling behaviours\n      enabled: false\n      # -- define scale down policies, must conform to HPAScalingRules\n      scaleDown: {}\n      # -- define scale up policies, must conform to HPAScalingRules\n      scaleUp: {}\n  # -- See `kubectl explain deployment.spec.strategy` for more,\n  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy\n  deploymentStrategy:\n    type: RollingUpdate\n  image:\n    # -- The Docker registry for the gateway image\n    registry: docker.io\n    # -- The gateway image repository\n    repository: nginxinc/nginx-unprivileged\n    # -- The gateway image tag\n    tag: 1.20.2-alpine\n    # -- The gateway image pull policy\n    pullPolicy: IfNotPresent\n  # -- The name of the PriorityClass for gateway pods\n  priorityClassName: null\n  # -- Labels for gateway pods\n  podLabels: {}\n  # -- Annotations for gateway pods\n  podAnnotations: {}\n  # -- Additional CLI args for the gateway\n  extraArgs: []\n  # -- Environment variables to add to the gateway pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the gateway pods\n  extraEnvFrom: []\n  # -- Volumes to add to the gateway pods\n  extraVolumes: []\n  # -- Volume mounts to add to the gateway pods\n  extraVolumeMounts: []\n  # -- The SecurityContext for gateway containers\n  podSecurityContext:\n    fsGroup: 101\n    runAsGroup: 101\n    runAsNonRoot: true\n    runAsUser: 101\n  # -- The SecurityContext for gateway containers\n  containerSecurityContext:\n    readOnlyRootFilesystem: true\n    capabilities:\n      drop:\n        - ALL\n    allowPrivilegeEscalation: false\n  # -- Resource requests and limits for the gateway\n  resources: {}\n  # -- Containers to add to the gateway pods\n  extraContainers: []\n  # -- Grace period to allow the gateway to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for gateway pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.gatewaySelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.gatewaySelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Node selector for gateway pods\n  nodeSelector: {}\n  # -- Tolerations for gateway pods\n  tolerations: []\n  # -- DNSConfig for gateway pods\n  dnsConfig: {}\n  # Gateway service configuration\n  service:\n    # -- Port of the gateway service\n    port: 80\n    # -- Type of the gateway service\n    type: ClusterIP\n    # -- ClusterIP of the gateway service\n    clusterIP: null\n    # -- Node port if service type is NodePort\n    nodePort: null\n    # -- Load balancer IPO address if service type is LoadBalancer\n    loadBalancerIP: null\n    # -- Load balancer allow traffic from CIDR list if service type is LoadBalancer\n    loadBalancerSourceRanges: []\n    # -- Set appProtocol for the service\n    appProtocol: null\n    # -- Annotations for the gateway service\n    annotations: {}\n    # -- Labels for gateway service\n    labels: {}\n  # Gateway ingress configuration\n  ingress:\n    # -- Specifies whether an ingress for the gateway should be created\n    enabled: false\n    # -- Ingress Class Name. MAY be required for Kubernetes versions \u003e= 1.18\n    # For example: `ingressClassName: nginx`\n    ingressClassName: ''\n\n    # -- Annotations for the gateway ingress\n    annotations: {}\n    # -- Hosts configuration for the gateway ingress\n    hosts:\n      - host: gateway.loki.example.com\n        paths:\n          - path: /\n            # -- pathType (e.g. ImplementationSpecific, Prefix, .. etc.) might also be required by some Ingress Controllers\n            # pathType: Prefix\n    # -- TLS configuration for the gateway ingress\n    tls: []\n    # tls:\n    #   - secretName: loki-gateway-tls\n    #     hosts:\n    #       - gateway.loki.example.com\n\n  # Basic auth configuration\n  basicAuth:\n    # -- Enables basic authentication for the gateway\n    enabled: false\n    # -- The basic auth username for the gateway\n    username: null\n    # -- The basic auth password for the gateway\n    password: null\n    # -- Uses the specified username and password to compute a htpasswd using Sprig's `htpasswd` function.\n    # The value is templated using `tpl`. Override this to use a custom htpasswd, e.g. in case the default causes\n    # high CPU load.\n    # @default -- See values.yaml\n    htpasswd: \u003e-\n      {{ htpasswd (required \"'gateway.basicAuth.username' is required\" .Values.gateway.basicAuth.username) (required \"'gateway.basicAuth.password' is required\" .Values.gateway.basicAuth.password) }}\n    # -- Existing basic auth secret to use. Must contain '.htpasswd'\n    existingSecret: null\n  # Configures the readiness probe for the gateway\n  readinessProbe:\n    httpGet:\n      path: /\n      port: http\n    initialDelaySeconds: 15\n    timeoutSeconds: 1\n  livenessProbe:\n    httpGet:\n      path: /\n      port: http\n    initialDelaySeconds: 30\n  nginxConfig:\n    # -- NGINX log format\n    # @default -- See values.yaml\n    logFormat: |-\n      main '$remote_addr - $remote_user [$time_local]  $status '\n              '\"$request\" $body_bytes_sent \"$http_referer\" '\n              '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n    # -- Allows appending custom configuration to the server block\n    serverSnippet: \"\"\n    # -- Allows appending custom configuration to the http block\n    httpSnippet: \"\"\n    # -- Allows overriding the DNS resolver address nginx will use.\n    resolver: \"\"\n    # -- Config file contents for Nginx. Passed through the `tpl` function to allow templating\n    # @default -- See values.yaml\n    file: |\n      worker_processes  5;  ## Default: 1\n      error_log  /dev/stderr;\n      pid        /tmp/nginx.pid;\n      worker_rlimit_nofile 8192;\n\n      events {\n        worker_connections  4096;  ## Default: 1024\n      }\n\n      http {\n        client_body_temp_path /tmp/client_temp;\n        proxy_temp_path       /tmp/proxy_temp_path;\n        fastcgi_temp_path     /tmp/fastcgi_temp;\n        uwsgi_temp_path       /tmp/uwsgi_temp;\n        scgi_temp_path        /tmp/scgi_temp;\n\n        proxy_http_version    1.1;\n\n        default_type application/octet-stream;\n        log_format   {{ .Values.gateway.nginxConfig.logFormat }}\n\n        {{- if .Values.gateway.verboseLogging }}\n        access_log   /dev/stderr  main;\n        {{- else }}\n\n        map $status $loggable {\n          ~^[23]  0;\n          default 1;\n        }\n        access_log   /dev/stderr  main  if=$loggable;\n        {{- end }}\n\n        sendfile     on;\n        tcp_nopush   on;\n        {{- if .Values.gateway.nginxConfig.resolver }}\n        resolver {{ .Values.gateway.nginxConfig.resolver }};\n        {{- else }}\n        resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};\n        {{- end }}\n\n        {{- with .Values.gateway.nginxConfig.httpSnippet }}\n        {{ . | nindent 2 }}\n        {{- end }}\n\n        server {\n          listen             8080;\n\n          {{- if .Values.gateway.basicAuth.enabled }}\n          auth_basic           \"Loki\";\n          auth_basic_user_file /etc/nginx/secrets/.htpasswd;\n          {{- end }}\n\n          location = / {\n            return 200 'OK';\n            auth_basic off;\n            access_log off;\n          }\n\n          location = /api/prom/push {\n            set $api_prom_push_backend http://{{ include \"loki.distributorFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\n            proxy_pass       $api_prom_push_backend:3100$request_uri;\n            proxy_http_version 1.1;\n          }\n\n          location = /api/prom/tail {\n            set $api_prom_tail_backend http://{{ include \"loki.querierFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\n            proxy_pass       $api_prom_tail_backend:3100$request_uri;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection \"upgrade\";\n            proxy_http_version 1.1;\n          }\n\n          # Ruler\n          location ~ /prometheus/api/v1/alerts.* {\n            proxy_pass       http://{{ include \"loki.rulerFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;\n          }\n          location ~ /prometheus/api/v1/rules.* {\n            proxy_pass       http://{{ include \"loki.rulerFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;\n          }\n          location ~ /api/prom/rules.* {\n            proxy_pass       http://{{ include \"loki.rulerFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;\n          }\n          location ~ /api/prom/alerts.* {\n            proxy_pass       http://{{ include \"loki.rulerFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;\n          }\n\n          location ~ /api/prom/.* {\n            set $api_prom_backend http://{{ include \"loki.queryFrontendFullname\" . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\n            proxy_pass       $api_prom_backend:3100$request_uri;\n            proxy_http_version 1.1;\n          }\n\n          location = /loki/api/v1/push {\n            set $loki_api_v1_push_backend http://{{ include \"loki.distributorFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\n            proxy_pass       $loki_api_v1_push_backend:3100$request_uri;\n            proxy_http_version 1.1;\n          }\n\n          location = /loki/api/v1/tail {\n            set $loki_api_v1_tail_backend http://{{ include \"loki.querierFullname\" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\n            proxy_pass       $loki_api_v1_tail_backend:3100$request_uri;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection \"upgrade\";\n            proxy_http_version 1.1;\n          }\n\n          location ~ /loki/api/.* {\n            set $loki_api_backend http://{{ include \"loki.queryFrontendFullname\" . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};\n            proxy_pass       $loki_api_backend:3100$request_uri;\n            proxy_http_version 1.1;\n          }\n\n          {{- with .Values.gateway.nginxConfig.serverSnippet }}\n          {{ . | nindent 4 }}\n          {{- end }}\n        }\n      }\n\n# Configuration for the compactor\ncompactor:\n  # -- Kind of deployment [StatefulSet/Deployment]\n  kind: StatefulSet\n  # -- Number of replicas for the compactor\n  replicas: 1\n  # -- Specifies whether compactor should be enabled\n  enabled: false\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  image:\n    # -- The Docker registry for the compactor image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the compactor image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the compactor image. Overrides `loki.image.tag`\n    tag: null\n  # -- Command to execute instead of defined in Docker image\n  command: null\n  # -- The name of the PriorityClass for compactor pods\n  priorityClassName: null\n  # -- Labels for compactor pods\n  podLabels: {}\n  # -- Annotations for compactor pods\n  podAnnotations: {}\n  # -- Affinity for compactor pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.compactorSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.compactorSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Labels for compactor service\n  serviceLabels: {}\n  # -- Additional CLI args for the compactor\n  extraArgs: []\n  # -- Environment variables to add to the compactor pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the compactor pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the compactor pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the compactor pods\n  extraVolumes: []\n  # -- readiness probe settings for ingester pods. If empty, use `loki.readinessProbe`\n  readinessProbe: {}\n  # -- liveness probe settings for ingester pods. If empty use `loki.livenessProbe`\n  livenessProbe: {}\n  # -- Resource requests and limits for the compactor\n  resources: {}\n  # -- Containers to add to the compactor pods\n  extraContainers: []\n  # -- Init containers to add to the compactor pods\n  initContainers: []\n  # -- Grace period to allow the compactor to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Node selector for compactor pods\n  nodeSelector: {}\n  # -- Tolerations for compactor pods\n  tolerations: []\n  # -- Set the optional grpc service protocol. Ex: \"grpc\", \"http2\" or \"https\"\n  appProtocol:\n    grpc: \"\"\n  persistence:\n    # -- Enable creating PVCs for the compactor\n    enabled: false\n    # -- Size of persistent disk\n    size: 10Gi\n    # -- Storage class to be used.\n    # If defined, storageClassName: \u003cstorageClass\u003e.\n    # If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n    # If empty or set to null, no storageClassName spec is\n    # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n    storageClass: null\n    # -- Annotations for compactor PVCs\n    annotations: {}\n    # -- List of the compactor PVCs\n    # @notationType -- list\n    claims:\n      - name: data\n        size: 10Gi\n        #   -- Storage class to be used.\n        #   If defined, storageClassName: \u003cstorageClass\u003e.\n        #   If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n        #   If empty or set to null, no storageClassName spec is\n        #   set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n        storageClass: null\n      # - name: wal\n      #   size: 150Gi\n    # -- Enable StatefulSetAutoDeletePVC feature\n    enableStatefulSetAutoDeletePVC: false\n    whenDeleted: Retain\n    whenScaled: Retain\n\n  serviceAccount:\n    create: false\n    # -- The name of the ServiceAccount to use for the compactor.\n    # If not set and create is true, a name is generated by appending\n    # \"-compactor\" to the common ServiceAccount.\n    name: null\n    # -- Image pull secrets for the compactor service account\n    imagePullSecrets: []\n    # -- Annotations for the compactor service account\n    annotations: {}\n    # -- Set this toggle to false to opt out of automounting API credentials for the service account\n    automountServiceAccountToken: true\n\n# Configuration for the ruler\nruler:\n  # -- Specifies whether the ruler should be enabled\n  enabled: false\n  # -- Kind of deployment [StatefulSet/Deployment]\n  kind: Deployment\n  # -- Number of replicas for the ruler\n  replicas: 1\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  image:\n    # -- The Docker registry for the ruler image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the ruler image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the ruler image. Overrides `loki.image.tag`\n    tag: null\n  # -- Command to execute instead of defined in Docker image\n  command: null\n  # -- The name of the PriorityClass for ruler pods\n  priorityClassName: null\n  # -- Labels for compactor pods\n  podLabels: {}\n  # -- Annotations for ruler pods\n  podAnnotations: {}\n  # -- Labels for ruler service\n  serviceLabels: {}\n  # -- Additional CLI args for the ruler\n  extraArgs: []\n  # -- Environment variables to add to the ruler pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the ruler pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the ruler pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the ruler pods\n  extraVolumes: []\n  # -- Resource requests and limits for the ruler\n  resources: {}\n  # -- Containers to add to the ruler pods\n  extraContainers: []\n  # -- Init containers to add to the ruler pods\n  initContainers: []\n  # -- Grace period to allow the ruler to shutdown before it is killed\n  terminationGracePeriodSeconds: 300\n  # -- Affinity for ruler pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.rulerSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.rulerSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Node selector for ruler pods\n  nodeSelector: {}\n  # -- Tolerations for ruler pods\n  tolerations: []\n  # -- DNSConfig for ruler pods\n  dnsConfig: {}\n  persistence:\n    # -- Enable creating PVCs which is required when using recording rules\n    enabled: false\n    # -- Size of persistent disk\n    size: 10Gi\n    # -- Storage class to be used.\n    # If defined, storageClassName: \u003cstorageClass\u003e.\n    # If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n    # If empty or set to null, no storageClassName spec is\n    # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n    storageClass: null\n    # -- Annotations for ruler PVCs\n    annotations: {}\n  # -- Set the optional grpc service protocol. Ex: \"grpc\", \"http2\" or \"https\"\n  appProtocol:\n    grpc: \"\"\n  # -- Directories containing rules files\n  directories: {}\n    # tenant_foo:\n    #   rules1.txt: |\n    #     groups:\n    #       - name: should_fire\n    #         rules:\n    #           - alert: HighPercentageError\n    #             expr: |\n    #               sum(rate({app=\"foo\", env=\"production\"} |= \"error\" [5m])) by (job)\n    #                 /\n    #               sum(rate({app=\"foo\", env=\"production\"}[5m])) by (job)\n    #                 \u003e 0.05\n    #             for: 10m\n    #             labels:\n    #               severity: warning\n    #             annotations:\n    #               summary: High error rate\n    #       - name: credentials_leak\n    #         rules:\n    #           - alert: http-credentials-leaked\n    #             annotations:\n    #               message: \"{{ $labels.job }} is leaking http basic auth credentials.\"\n    #             expr: 'sum by (cluster, job, pod) (count_over_time({namespace=\"prod\"} |~ \"http(s?)://(\\\\w+):(\\\\w+)@\" [5m]) \u003e 0)'\n    #             for: 10m\n    #             labels:\n    #               severity: critical\n    #   rules2.txt: |\n    #     groups:\n    #       - name: example\n    #         rules:\n    #         - alert: HighThroughputLogStreams\n    #           expr: sum by(container) (rate({job=~\"loki-dev/.*\"}[1m])) \u003e 1000\n    #           for: 2m\n    # tenant_bar:\n    #   rules1.txt: |\n    #     groups:\n    #       - name: should_fire\n    #         rules:\n    #           - alert: HighPercentageError\n    #             expr: |\n    #               sum(rate({app=\"foo\", env=\"production\"} |= \"error\" [5m])) by (job)\n    #                 /\n    #               sum(rate({app=\"foo\", env=\"production\"}[5m])) by (job)\n    #                 \u003e 0.05\n    #             for: 10m\n    #             labels:\n    #               severity: warning\n    #             annotations:\n    #               summary: High error rate\n    #       - name: credentials_leak\n    #         rules:\n    #           - alert: http-credentials-leaked\n    #             annotations:\n    #               message: \"{{ $labels.job }} is leaking http basic auth credentials.\"\n    #             expr: 'sum by (cluster, job, pod) (count_over_time({namespace=\"prod\"} |~ \"http(s?)://(\\\\w+):(\\\\w+)@\" [5m]) \u003e 0)'\n    #             for: 10m\n    #             labels:\n    #               severity: critical\n    #   rules2.txt: |\n    #     groups:\n    #       - name: example\n    #         rules:\n    #         - alert: HighThroughputLogStreams\n    #           expr: sum by(container) (rate({job=~\"loki-dev/.*\"}[1m])) \u003e 1000\n    #           for: 2m\n\n# Configuration for the index-gateway\nindexGateway:\n  # -- Specifies whether the index-gateway should be enabled\n  enabled: false\n  # -- Number of replicas for the index-gateway\n  replicas: 1\n  # -- Whether the index gateway should join the memberlist hashring\n  joinMemberlist: true\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  image:\n    # -- The Docker registry for the index-gateway image. Overrides `loki.image.registry`\n    registry: null\n    # -- Docker image repository for the index-gateway image. Overrides `loki.image.repository`\n    repository: null\n    # -- Docker image tag for the index-gateway image. Overrides `loki.image.tag`\n    tag: null\n  # -- The name of the PriorityClass for index-gateway pods\n  priorityClassName: null\n  # -- Labels for index-gateway pods\n  podLabels: {}\n  # -- Annotations for index-gateway pods\n  podAnnotations: {}\n  # -- Labels for index-gateway service\n  serviceLabels: {}\n  # -- Additional CLI args for the index-gateway\n  extraArgs: []\n  # -- Environment variables to add to the index-gateway pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to the index-gateway pods\n  extraEnvFrom: []\n  # -- Volume mounts to add to the index-gateway pods\n  extraVolumeMounts: []\n  # -- Volumes to add to the index-gateway pods\n  extraVolumes: []\n  # -- Resource requests and limits for the index-gateway\n  resources: {}\n  # -- Containers to add to the index-gateway pods\n  extraContainers: []\n  # -- Init containers to add to the index-gateway pods\n  initContainers: []\n  # -- Grace period to allow the index-gateway to shutdown before it is killed.\n  terminationGracePeriodSeconds: 300\n  # -- Affinity for index-gateway pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.indexGatewaySelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.indexGatewaySelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Node selector for index-gateway pods\n  nodeSelector: {}\n  # -- Tolerations for index-gateway pods\n  tolerations: []\n  persistence:\n    # -- Enable creating PVCs which is required when using boltdb-shipper\n    enabled: false\n    # -- Use emptyDir with ramdisk for storage. **Please note that all data in indexGateway will be lost on pod restart**\n    inMemory: false\n    # -- Size of persistent or memory disk\n    size: 10Gi\n    # -- Storage class to be used.\n    # If defined, storageClassName: \u003cstorageClass\u003e.\n    # If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n    # If empty or set to null, no storageClassName spec is\n    # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n    storageClass: null\n    # -- Annotations for index gateway PVCs\n    annotations: {}\n    # -- Enable StatefulSetAutoDeletePVC feature\n    enableStatefulSetAutoDeletePVC: false\n    whenDeleted: Retain\n    whenScaled: Retain\n  # -- Set the optional grpc service protocol. Ex: \"grpc\", \"http2\" or \"https\"\n  appProtocol:\n    grpc: \"\"\n\nmemcached:\n  readinessProbe:\n    tcpSocket:\n      port: http\n    initialDelaySeconds: 5\n    timeoutSeconds: 1\n  livenessProbe:\n    tcpSocket:\n      port: http\n    initialDelaySeconds: 10\n  image:\n    # -- The Docker registry for the memcached\n    registry: docker.io\n    # -- Memcached Docker image repository\n    repository: memcached\n    # -- Memcached Docker image tag\n    tag: 1.6.21-alpine\n    # -- Memcached Docker image pull policy\n    pullPolicy: IfNotPresent\n  # -- Labels for memcached pods\n  podLabels: {}\n  # -- The SecurityContext for memcached pods\n  podSecurityContext:\n    fsGroup: 11211\n    runAsGroup: 11211\n    runAsNonRoot: true\n    runAsUser: 11211\n  # -- The SecurityContext for memcached containers\n  containerSecurityContext:\n    readOnlyRootFilesystem: true\n    capabilities:\n      drop:\n        - ALL\n    allowPrivilegeEscalation: false\n  # -- Common annotations for all memcached services\n  serviceAnnotations: {}\n  # -- Adds the appProtocol field to the memcached services. This allows memcached to work with istio protocol selection. Ex: \"http\" or \"tcp\"\n  appProtocol: \"\"\n\nmemcachedExporter:\n  # -- Specifies whether the Memcached Exporter should be enabled\n  enabled: false\n  image:\n    # -- The Docker registry for the Memcached Exporter\n    registry: docker.io\n    # -- Memcached Exporter Docker image repository\n    repository: prom/memcached-exporter\n    # -- Memcached Exporter Docker image tag\n    tag: v0.13.0\n    # -- Memcached Exporter Docker image pull policy\n    pullPolicy: IfNotPresent\n  # -- Labels for memcached-exporter pods\n  podLabels: {}\n  # -- Memcached Exporter resource requests and limits\n  resources: {}\n  # -- The SecurityContext for memcachedExporter containers\n  containerSecurityContext:\n    readOnlyRootFilesystem: true\n    capabilities:\n      drop:\n        - ALL\n    allowPrivilegeEscalation: false\n\nmemcachedChunks:\n  # -- Specifies whether the Memcached chunks cache should be enabled\n  enabled: false\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  # -- Number of replicas for memcached-chunks\n  replicas: 1\n  # -- The name of the PriorityClass for memcached-chunks pods\n  priorityClassName: null\n  # -- Labels for memcached-chunks pods\n  podLabels: {}\n  # -- Annotations for memcached-chunks pods\n  podAnnotations: {}\n  # -- Labels for memcached-chunks service\n  serviceLabels: {}\n  # -- Additional CLI args for memcached-chunks\n  extraArgs:\n    - -I 32m\n  # -- Environment variables to add to memcached-chunks pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to memcached-chunks pods\n  extraEnvFrom: []\n  # -- Resource requests and limits for memcached-chunks\n  resources: {}\n  # -- Containers to add to the memcached-chunks pods\n  extraContainers: []\n  # -- Grace period to allow memcached-chunks to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for memcached-chunks pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.memcachedChunksSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.memcachedChunksSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Node selector for memcached-chunks pods\n  nodeSelector: {}\n  # -- Tolerations for memcached-chunks pods\n  tolerations: []\n  persistence:\n    # -- Enable creating PVCs which will persist cached data through restarts\n    enabled: false\n    # -- Size of persistent or memory disk\n    size: 10Gi\n    # -- Storage class to be used.\n    # If defined, storageClassName: \u003cstorageClass\u003e.\n    # If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n    # If empty or set to null, no storageClassName spec is\n    # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n    storageClass: null\n  # -- List of additional PVCs to be created for the memcached-chunks statefulset\n  volumeClaimTemplates: []\n  # -- List of additional volumes to be mounted for the memcached-chunks statefulset\n  extraVolumeMounts: []\n\nmemcachedFrontend:\n  # -- Specifies whether the Memcached frontend cache should be enabled\n  enabled: false\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  # -- Number of replicas for memcached-frontend\n  replicas: 1\n  # -- The name of the PriorityClass for memcached-frontend pods\n  priorityClassName: null\n  # -- Labels for memcached-frontend pods\n  podLabels: {}\n  # -- Annotations for memcached-frontend pods\n  podAnnotations: {}\n  # -- Labels for memcached-frontend service\n  serviceLabels: {}\n  # -- Additional CLI args for memcached-frontend\n  extraArgs:\n    - -I 32m\n  # -- Environment variables to add to memcached-frontend pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to memcached-frontend pods\n  extraEnvFrom: []\n  # -- Resource requests and limits for memcached-frontend\n  resources: {}\n  # -- Containers to add to the memcached-frontend pods\n  extraContainers: []\n  # -- Grace period to allow memcached-frontend to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for memcached-frontend pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.memcachedFrontendSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.memcachedFrontendSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: 1\n  # -- Node selector for memcached-frontend pods\n  nodeSelector: {}\n  # -- Tolerations for memcached-frontend pods\n  tolerations: []\n  persistence:\n    # -- Enable creating PVCs which will persist cached data through restarts\n    enabled: false\n    # -- Size of persistent or memory disk\n    size: 10Gi\n    # -- Storage class to be used.\n    # If defined, storageClassName: \u003cstorageClass\u003e.\n    # If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n    # If empty or set to null, no storageClassName spec is\n    # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n    storageClass: null\n\nmemcachedIndexQueries:\n  # -- Specifies whether the Memcached index queries cache should be enabled\n  enabled: false\n  # -- Number of replicas for memcached-index-queries\n  replicas: 1\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  # -- The name of the PriorityClass for memcached-index-queries pods\n  priorityClassName: null\n  # -- Labels for memcached-index-queries pods\n  podLabels: {}\n  # -- Annotations for memcached-index-queries pods\n  podAnnotations: {}\n  # -- Labels for memcached-index-queries service\n  serviceLabels: {}\n  # -- Additional CLI args for memcached-index-queries\n  extraArgs:\n    - -I 32m\n  # -- Environment variables to add to memcached-index-queries pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to memcached-index-queries pods\n  extraEnvFrom: []\n  # -- Resource requests and limits for memcached-index-queries\n  resources: {}\n  # -- Containers to add to the memcached-index-queries pods\n  extraContainers: []\n  # -- Grace period to allow memcached-index-queries to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for memcached-index-queries pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.memcachedIndexQueriesSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.memcachedIndexQueriesSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Node selector for memcached-index-queries pods\n  nodeSelector: {}\n  # -- Tolerations for memcached-index-queries pods\n  tolerations: []\n  persistence:\n    # -- Enable creating PVCs which will persist cached data through restarts\n    enabled: false\n    # -- Size of persistent or memory disk\n    size: 10Gi\n    # -- Storage class to be used.\n    # If defined, storageClassName: \u003cstorageClass\u003e.\n    # If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n    # If empty or set to null, no storageClassName spec is\n    # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n    storageClass: null\n\nmemcachedIndexWrites:\n  # -- Specifies whether the Memcached index writes cache should be enabled\n  enabled: false\n  # -- Number of replicas for memcached-index-writes\n  replicas: 1\n  # -- hostAliases to add\n  hostAliases: []\n  #  - ip: 1.2.3.4\n  #    hostnames:\n  #      - domain.tld\n  # -- The name of the PriorityClass for memcached-index-writes pods\n  priorityClassName: null\n  # -- Labels for memcached-index-writes pods\n  podLabels: {}\n  # -- Annotations for memcached-index-writes pods\n  podAnnotations: {}\n  # -- Labels for memcached-index-writes service\n  serviceLabels: {}\n  # -- Additional CLI args for memcached-index-writes\n  extraArgs:\n    - -I 32m\n  # -- Environment variables to add to memcached-index-writes pods\n  extraEnv: []\n  # -- Environment variables from secrets or configmaps to add to memcached-index-writes pods\n  extraEnvFrom: []\n  # -- Resource requests and limits for memcached-index-writes\n  resources: {}\n  # -- Containers to add to the memcached-index-writes pods\n  extraContainers: []\n  # -- Grace period to allow memcached-index-writes to shutdown before it is killed\n  terminationGracePeriodSeconds: 30\n  # -- Affinity for memcached-index-writes pods. Passed through `tpl` and, thus, to be configured as string\n  # @default -- Hard node and soft zone anti-affinity\n  affinity: |\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchLabels:\n              {{- include \"loki.memcachedIndexWritesSelectorLabels\" . | nindent 10 }}\n          topologyKey: kubernetes.io/hostname\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 100\n          podAffinityTerm:\n            labelSelector:\n              matchLabels:\n                {{- include \"loki.memcachedIndexWritesSelectorLabels\" . | nindent 12 }}\n            topologyKey: failure-domain.beta.kubernetes.io/zone\n  # -- Pod Disruption Budget maxUnavailable\n  maxUnavailable: null\n  # -- Node selector for memcached-index-writes pods\n  nodeSelector: {}\n  # -- Tolerations for memcached-index-writes pods\n  tolerations: []\n  persistence:\n    # -- Enable creating PVCs which will persist cached data through restarts\n    enabled: false\n    # -- Size of persistent or memory disk\n    size: 10Gi\n    # -- Storage class to be used.\n    # If defined, storageClassName: \u003cstorageClass\u003e.\n    # If set to \"-\", storageClassName: \"\", which disables dynamic provisioning.\n    # If empty or set to null, no storageClassName spec is\n    # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).\n    storageClass: null\n\nnetworkPolicy:\n  # -- Specifies whether Network Policies should be created\n  enabled: false\n  metrics:\n    # -- Specifies the Pods which are allowed to access the metrics port.\n    # As this is cross-namespace communication, you also need the namespaceSelector.\n    podSelector: {}\n    # -- Specifies the namespaces which are allowed to access the metrics port\n    namespaceSelector: {}\n    # -- Specifies specific network CIDRs which are allowed to access the metrics port.\n    # In case you use namespaceSelector, you also have to specify your kubelet networks here.\n    # The metrics ports are also used for probes.\n    cidrs: []\n  ingress:\n    # -- Specifies the Pods which are allowed to access the http port.\n    # As this is cross-namespace communication, you also need the namespaceSelector.\n    podSelector: {}\n    # -- Specifies the namespaces which are allowed to access the http port\n    namespaceSelector: {}\n  alertmanager:\n    # -- Specify the alertmanager port used for alerting\n    port: 9093\n    # -- Specifies the alertmanager Pods.\n    # As this is cross-namespace communication, you also need the namespaceSelector.\n    podSelector: {}\n    # -- Specifies the namespace the alertmanager is running in\n    namespaceSelector: {}\n  externalStorage:\n    # -- Specify the port used for external storage, e.g. AWS S3\n    ports: []\n    # -- Specifies specific network CIDRs you want to limit access to\n    cidrs: []\n  discovery:\n    # -- Specify the port used for discovery\n    port: null\n    # -- Specifies the Pods labels used for discovery.\n    # As this is cross-namespace communication, you also need the namespaceSelector.\n    podSelector: {}\n    # -- Specifies the namespace the discovery Pods are running in\n    namespaceSelector: {}"
            ],
            "verify": false,
            "version": "0.79.0",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "metalb",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "metallb",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "metalb",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "v0.14.5",
                "chart": "metallb",
                "name": "metalb",
                "namespace": "metalb",
                "revision": 1,
                "values": "{\"controller\":{\"affinity\":{},\"enabled\":true,\"image\":{\"pullPolicy\":null,\"repository\":\"quay.io/metallb/controller\",\"tag\":null},\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"logLevel\":\"info\",\"nodeSelector\":{},\"podAnnotations\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{},\"runtimeClassName\":\"\",\"securityContext\":{\"fsGroup\":65534,\"runAsNonRoot\":true,\"runAsUser\":65534},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":\"\"},\"strategy\":{\"type\":\"RollingUpdate\"},\"tolerations\":[]},\"crds\":{\"enabled\":true,\"validationFailurePolicy\":\"Fail\"},\"fullnameOverride\":\"\",\"imagePullSecrets\":[],\"loadBalancerClass\":\"\",\"nameOverride\":\"\",\"prometheus\":{\"controllerMetricsTLSSecret\":\"\",\"metricsPort\":7472,\"namespace\":\"\",\"podMonitor\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"interval\":null,\"jobLabel\":\"app.kubernetes.io/name\",\"metricRelabelings\":[],\"relabelings\":[]},\"prometheusRule\":{\"additionalLabels\":{},\"addressPoolExhausted\":{\"enabled\":true,\"labels\":{\"severity\":\"alert\"}},\"addressPoolUsage\":{\"enabled\":true,\"thresholds\":[{\"labels\":{\"severity\":\"warning\"},\"percent\":75},{\"labels\":{\"severity\":\"warning\"},\"percent\":85},{\"labels\":{\"severity\":\"alert\"},\"percent\":95}]},\"annotations\":{},\"bgpSessionDown\":{\"enabled\":true,\"labels\":{\"severity\":\"alert\"}},\"configNotLoaded\":{\"enabled\":true,\"labels\":{\"severity\":\"warning\"}},\"enabled\":false,\"extraAlerts\":[],\"staleConfig\":{\"enabled\":true,\"labels\":{\"severity\":\"warning\"}}},\"rbacPrometheus\":true,\"rbacProxy\":{\"pullPolicy\":null,\"repository\":\"gcr.io/kubebuilder/kube-rbac-proxy\",\"tag\":\"v0.12.0\"},\"scrapeAnnotations\":false,\"serviceAccount\":\"\",\"serviceMonitor\":{\"controller\":{\"additionalLabels\":{},\"annotations\":{},\"tlsConfig\":{\"insecureSkipVerify\":true}},\"enabled\":false,\"interval\":null,\"jobLabel\":\"app.kubernetes.io/name\",\"metricRelabelings\":[],\"relabelings\":[],\"speaker\":{\"additionalLabels\":{},\"annotations\":{},\"tlsConfig\":{\"insecureSkipVerify\":true}}},\"speakerMetricsTLSSecret\":\"\"},\"rbac\":{\"create\":true},\"speaker\":{\"affinity\":{},\"enabled\":true,\"excludeInterfaces\":{\"enabled\":true},\"frr\":{\"enabled\":true,\"image\":{\"pullPolicy\":null,\"repository\":\"quay.io/frrouting/frr\",\"tag\":\"8.4.2\"},\"metricsPort\":7473,\"resources\":{}},\"frrMetrics\":{\"resources\":{}},\"image\":{\"pullPolicy\":null,\"repository\":\"quay.io/metallb/speaker\",\"tag\":null},\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"logLevel\":\"info\",\"memberlist\":{\"enabled\":true,\"mlBindPort\":7946,\"mlSecretKeyPath\":\"/etc/ml_secret_key\"},\"nodeSelector\":{},\"podAnnotations\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"reloader\":{\"resources\":{}},\"resources\":{},\"runtimeClassName\":\"\",\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":\"\"},\"startupProbe\":{\"enabled\":true,\"failureThreshold\":30,\"periodSeconds\":5},\"tolerateMaster\":true,\"tolerations\":[],\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}",
                "version": "0.14.5"
              }
            ],
            "name": "metalb",
            "namespace": "metalb",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://metallb.github.io/metallb",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "# Default values for metallb.\n# This is a YAML-formatted file.\n# Declare variables to be passed into your templates.\n\nimagePullSecrets: []\nnameOverride: \"\"\nfullnameOverride: \"\"\nloadBalancerClass: \"\"\n\n# To configure MetalLB, you must specify ONE of the following two\n# options.\n\nrbac:\n  # create specifies whether to install and use RBAC rules.\n  create: true\n\nprometheus:\n  # scrape annotations specifies whether to add Prometheus metric\n  # auto-collection annotations to pods. See\n  # https://github.com/prometheus/prometheus/blob/release-2.1/documentation/examples/prometheus-kubernetes.yml\n  # for a corresponding Prometheus configuration. Alternatively, you\n  # may want to use the Prometheus Operator\n  # (https://github.com/coreos/prometheus-operator) for more powerful\n  # monitoring configuration. If you use the Prometheus operator, this\n  # can be left at false.\n  scrapeAnnotations: false\n\n  # port both controller and speaker will listen on for metrics\n  metricsPort: 7472\n\n  # if set, enables rbac proxy on the controller and speaker to expose\n  # the metrics via tls.\n  # secureMetricsPort: 9120\n\n  # the name of the secret to be mounted in the speaker pod\n  # to expose the metrics securely. If not present, a self signed\n  # certificate to be used.\n  speakerMetricsTLSSecret: \"\"\n\n  # the name of the secret to be mounted in the controller pod\n  # to expose the metrics securely. If not present, a self signed\n  # certificate to be used.\n  controllerMetricsTLSSecret: \"\"\n\n  # prometheus doens't have the permission to scrape all namespaces so we give it permission to scrape metallb's one\n  rbacPrometheus: true\n\n  # the service account used by prometheus\n  # required when \" .Values.prometheus.rbacPrometheus == true \" and \" .Values.prometheus.podMonitor.enabled=true or prometheus.serviceMonitor.enabled=true \"\n  serviceAccount: \"\"\n\n  # the namespace where prometheus is deployed\n  # required when \" .Values.prometheus.rbacPrometheus == true \" and \" .Values.prometheus.podMonitor.enabled=true or prometheus.serviceMonitor.enabled=true \"\n  namespace: \"\"\n\n  # the image to be used for the kuberbacproxy container\n  rbacProxy:\n    repository: gcr.io/kubebuilder/kube-rbac-proxy\n    tag: v0.12.0\n    pullPolicy:\n\n  # Prometheus Operator PodMonitors\n  podMonitor:\n    # enable support for Prometheus Operator\n    enabled: false\n\n    # optional additionnal labels for podMonitors\n    additionalLabels: {}\n\n    # optional annotations for podMonitors\n    annotations: {}\n\n    # Job label for scrape target\n    jobLabel: \"app.kubernetes.io/name\"\n\n    # Scrape interval. If not set, the Prometheus default scrape interval is used.\n    interval:\n\n    # \tmetric relabel configs to apply to samples before ingestion.\n    metricRelabelings: []\n    # - action: keep\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\n    #   sourceLabels: [__name__]\n\n    # \trelabel configs to apply to samples before ingestion.\n    relabelings: []\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\n    #   separator: ;\n    #   regex: ^(.*)$\n    #   target_label: nodename\n    #   replacement: $1\n    #   action: replace\n\n  # Prometheus Operator ServiceMonitors. To be used as an alternative\n  # to podMonitor, supports secure metrics.\n  serviceMonitor:\n    # enable support for Prometheus Operator\n    enabled: false\n\n    speaker:\n      # optional additional labels for the speaker serviceMonitor\n      additionalLabels: {}\n      # optional additional annotations for the speaker serviceMonitor\n      annotations: {}\n      # optional tls configuration for the speaker serviceMonitor, in case\n      # secure metrics are enabled.\n      tlsConfig:\n        insecureSkipVerify: true\n\n    controller:\n      # optional additional labels for the controller serviceMonitor\n      additionalLabels: {}\n      # optional additional annotations for the controller serviceMonitor\n      annotations: {}\n      # optional tls configuration for the controller serviceMonitor, in case\n      # secure metrics are enabled.\n      tlsConfig:\n        insecureSkipVerify: true\n\n    # Job label for scrape target\n    jobLabel: \"app.kubernetes.io/name\"\n\n    # Scrape interval. If not set, the Prometheus default scrape interval is used.\n    interval:\n\n    # \tmetric relabel configs to apply to samples before ingestion.\n    metricRelabelings: []\n    # - action: keep\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\n    #   sourceLabels: [__name__]\n\n    # \trelabel configs to apply to samples before ingestion.\n    relabelings: []\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\n    #   separator: ;\n    #   regex: ^(.*)$\n    #   target_label: nodename\n    #   replacement: $1\n    #   action: replace\n\n  # Prometheus Operator alertmanager alerts\n  prometheusRule:\n    # enable alertmanager alerts\n    enabled: false\n\n    # optional additionnal labels for prometheusRules\n    additionalLabels: {}\n\n    # optional annotations for prometheusRules\n    annotations: {}\n\n    # MetalLBStaleConfig\n    staleConfig:\n      enabled: true\n      labels:\n        severity: warning\n\n    # MetalLBConfigNotLoaded\n    configNotLoaded:\n      enabled: true\n      labels:\n        severity: warning\n\n    # MetalLBAddressPoolExhausted\n    addressPoolExhausted:\n      enabled: true\n      labels:\n        severity: alert\n\n    addressPoolUsage:\n      enabled: true\n      thresholds:\n        - percent: 75\n          labels:\n            severity: warning\n        - percent: 85\n          labels:\n            severity: warning\n        - percent: 95\n          labels:\n            severity: alert\n\n    # MetalLBBGPSessionDown\n    bgpSessionDown:\n      enabled: true\n      labels:\n        severity: alert\n\n    extraAlerts: []\n\n# controller contains configuration specific to the MetalLB cluster\n# controller.\ncontroller:\n  enabled: true\n  # -- Controller log level. Must be one of: `all`, `debug`, `info`, `warn`, `error` or `none`\n  logLevel: info\n  # command: /controller\n  # webhookMode: enabled\n  image:\n    repository: quay.io/metallb/controller\n    tag:\n    pullPolicy:\n  ## @param controller.updateStrategy.type Metallb controller deployment strategy type.\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy\n  ## e.g:\n  ## strategy:\n  ##  type: RollingUpdate\n  ##  rollingUpdate:\n  ##    maxSurge: 25%\n  ##    maxUnavailable: 25%\n  ##\n  strategy:\n    type: RollingUpdate\n  serviceAccount:\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use. If not set and create is\n    # true, a name is generated using the fullname template\n    name: \"\"\n    annotations: {}\n  securityContext:\n    runAsNonRoot: true\n    # nobody\n    runAsUser: 65534\n    fsGroup: 65534\n  resources: {}\n    # limits:\n      # cpu: 100m\n      # memory: 100Mi\n  nodeSelector: {}\n  tolerations: []\n  priorityClassName: \"\"\n  runtimeClassName: \"\"\n  affinity: {}\n  podAnnotations: {}\n  labels: {}\n  livenessProbe:\n    enabled: true\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n  readinessProbe:\n    enabled: true\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n\n# speaker contains configuration specific to the MetalLB speaker\n# daemonset.\nspeaker:\n  enabled: true\n  # command: /speaker\n  # -- Speaker log level. Must be one of: `all`, `debug`, `info`, `warn`, `error` or `none`\n  logLevel: info\n  tolerateMaster: true\n  memberlist:\n    enabled: true\n    mlBindPort: 7946\n    mlSecretKeyPath: \"/etc/ml_secret_key\"\n  excludeInterfaces:\n    enabled: true\n  image:\n    repository: quay.io/metallb/speaker\n    tag:\n    pullPolicy:\n  ## @param speaker.updateStrategy.type Speaker daemonset strategy type\n  ## ref: https://kubernetes.io/docs/tasks/manage-daemon/update-daemon-set/\n  ##\n  updateStrategy:\n    ## StrategyType\n    ## Can be set to RollingUpdate or OnDelete\n    ##\n    type: RollingUpdate\n  serviceAccount:\n    # Specifies whether a ServiceAccount should be created\n    create: true\n    # The name of the ServiceAccount to use. If not set and create is\n    # true, a name is generated using the fullname template\n    name: \"\"\n    annotations: {}\n  ## Defines a secret name for the controller to generate a memberlist encryption secret\n  ## By default secretName: {{ \"metallb.fullname\" }}-memberlist\n  ##\n  # secretName:\n  resources: {}\n    # limits:\n      # cpu: 100m\n      # memory: 100Mi\n  nodeSelector: {}\n  tolerations: []\n  priorityClassName: \"\"\n  affinity: {}\n  ## Selects which runtime class will be used by the pod.\n  runtimeClassName: \"\"\n  podAnnotations: {}\n  labels: {}\n  livenessProbe:\n    enabled: true\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n  readinessProbe:\n    enabled: true\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n  startupProbe:\n    enabled: true\n    failureThreshold: 30\n    periodSeconds: 5\n  # frr contains configuration specific to the MetalLB FRR container,\n  # for speaker running alongside FRR.\n  frr:\n    enabled: true\n    image:\n      repository: quay.io/frrouting/frr\n      tag: 8.4.2\n      pullPolicy:\n    metricsPort: 7473\n    resources: {}\n\n    # if set, enables a rbac proxy sidecar container on the speaker to\n    # expose the frr metrics via tls.\n    # secureMetricsPort: 9121\n\n  reloader:\n    resources: {}\n\n  frrMetrics:\n    resources: {}\n\ncrds:\n  enabled: true\n  validationFailurePolicy: Fail\n"
            ],
            "verify": false,
            "version": "0.14.5",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_namespace.metalb-namespace"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "metrics_name",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "metrics-server",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "metrics-server",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "0.7.1",
                "chart": "metrics-server",
                "name": "metrics-server",
                "namespace": "kube-system",
                "revision": 1,
                "values": "{\"addonResizer\":{\"enabled\":false,\"image\":{\"repository\":\"registry.k8s.io/autoscaling/addon-resizer\",\"tag\":\"1.8.14\"},\"nanny\":{\"cpu\":\"20m\",\"extraCpu\":\"1m\",\"extraMemory\":\"2Mi\",\"memory\":\"15Mi\",\"minClusterSize\":10,\"pollPeriod\":300000,\"threshold\":5},\"resources\":{\"limits\":{\"cpu\":\"40m\",\"memory\":\"25Mi\"},\"requests\":{\"cpu\":\"40m\",\"memory\":\"25Mi\"}}},\"affinity\":{},\"apiService\":{\"annotations\":{},\"caBundle\":\"\",\"create\":true,\"insecureSkipTLSVerify\":true},\"args\":[],\"commonLabels\":{},\"containerPort\":10250,\"defaultArgs\":[\"--cert-dir=/tmp\",\"--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\",\"--kubelet-use-node-status-port\",\"--metric-resolution=15s\",\"--kubelet-insecure-tls\",\"--kubelet-insecure-tls=true\"],\"deploymentAnnotations\":{},\"extraVolumeMounts\":[],\"extraVolumes\":[],\"fullnameOverride\":\"\",\"hostNetwork\":{\"enabled\":false},\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"registry.k8s.io/metrics-server/metrics-server\",\"tag\":\"\"},\"imagePullSecrets\":[],\"livenessProbe\":{\"failureThreshold\":3,\"httpGet\":{\"path\":\"/livez\",\"port\":\"https\",\"scheme\":\"HTTPS\"},\"initialDelaySeconds\":0,\"periodSeconds\":10},\"metrics\":{\"enabled\":false},\"nameOverride\":\"\",\"nodeSelector\":{},\"podAnnotations\":{},\"podDisruptionBudget\":{\"enabled\":false,\"maxUnavailable\":null,\"minAvailable\":null},\"podLabels\":{},\"podSecurityContext\":{},\"priorityClassName\":\"system-cluster-critical\",\"rbac\":{\"create\":true,\"pspEnabled\":false},\"readinessProbe\":{\"failureThreshold\":3,\"httpGet\":{\"path\":\"/readyz\",\"port\":\"https\",\"scheme\":\"HTTPS\"},\"initialDelaySeconds\":20,\"periodSeconds\":10},\"replicas\":1,\"resources\":{},\"schedulerName\":\"\",\"securityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"runAsUser\":1000,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"service\":{\"annotations\":{},\"labels\":{},\"port\":443,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":\"\",\"secrets\":[]},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"interval\":\"1m\",\"metricRelabelings\":[],\"relabelings\":[],\"scrapeTimeout\":\"10s\"},\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategy\":{}}",
                "version": "3.12.1"
              }
            ],
            "name": "metrics-server",
            "namespace": "kube-system",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://kubernetes-sigs.github.io/metrics-server",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "# Default values for metrics-server.\n# This is a YAML-formatted file.\n# Declare variables to be passed into your templates.\n\nimage:\n  repository: registry.k8s.io/metrics-server/metrics-server\n  # Overrides the image tag whose default is v{{ .Chart.AppVersion }}\n  tag: \"\"\n  pullPolicy: IfNotPresent\n\nimagePullSecrets: []\n# - name: registrySecretName\n\nnameOverride: \"\"\nfullnameOverride: \"\"\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # Annotations to add to the service account\n  annotations: {}\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: \"\"\n  # The list of secrets mountable by this service account.\n  # See https://kubernetes.io/docs/reference/labels-annotations-taints/#enforce-mountable-secrets\n  secrets: []\n\nrbac:\n  # Specifies whether RBAC resources should be created\n  create: true\n  pspEnabled: false\n\napiService:\n  # Specifies if the v1beta1.metrics.k8s.io API service should be created.\n  #\n  # You typically want this enabled! If you disable API service creation you have to\n  # manage it outside of this chart for e.g horizontal pod autoscaling to\n  # work with this release.\n  create: true\n  # Annotations to add to the API service\n  annotations: {}\n  # Specifies whether to skip TLS verification\n  insecureSkipTLSVerify: true\n  # The PEM encoded CA bundle for TLS verification\n  caBundle: \"\"\n\ncommonLabels: {}\npodLabels: {}\npodAnnotations: {}\n\npodSecurityContext: {}\n\nsecurityContext:\n  allowPrivilegeEscalation: false\n  readOnlyRootFilesystem: true\n  runAsNonRoot: true\n  runAsUser: 1000\n  seccompProfile:\n    type: RuntimeDefault\n  capabilities:\n    drop:\n      - ALL\n\npriorityClassName: system-cluster-critical\n\ncontainerPort: 10250\n\nhostNetwork:\n  # Specifies if metrics-server should be started in hostNetwork mode.\n  #\n  # You would require this enabled if you use alternate overlay networking for pods and\n  # API server unable to communicate with metrics-server. As an example, this is required\n  # if you use Weave network on EKS\n  enabled: false\n\nreplicas: 1\n\nupdateStrategy: {}\n#   type: RollingUpdate\n#   rollingUpdate:\n#     maxSurge: 0\n#     maxUnavailable: 1\n\npodDisruptionBudget:\n  # https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  enabled: false\n  minAvailable:\n  maxUnavailable:\n\ndefaultArgs:\n  - --cert-dir=/tmp\n  - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\n  - --kubelet-use-node-status-port\n  - --metric-resolution=15s\n  - --kubelet-insecure-tls\n  - --kubelet-insecure-tls=true\n\nargs: []\n\nlivenessProbe:\n  httpGet:\n    path: /livez\n    port: https\n    scheme: HTTPS\n  initialDelaySeconds: 0\n  periodSeconds: 10\n  failureThreshold: 3\n\nreadinessProbe:\n  httpGet:\n    path: /readyz\n    port: https\n    scheme: HTTPS\n  initialDelaySeconds: 20\n  periodSeconds: 10\n  failureThreshold: 3\n\nservice:\n  type: ClusterIP\n  port: 443\n  annotations: {}\n  labels: {}\n  #  Add these labels to have metrics-server show up in `kubectl cluster-info`\n  #  kubernetes.io/cluster-service: \"true\"\n  #  kubernetes.io/name: \"Metrics-server\"\n\naddonResizer:\n  enabled: false\n  image:\n    repository: registry.k8s.io/autoscaling/addon-resizer\n    tag: 1.8.14\n  resources:\n    limits:\n      cpu: 40m\n      memory: 25Mi\n    requests:\n      cpu: 40m\n      memory: 25Mi\n  nanny:\n    cpu: 20m\n    extraCpu: 1m\n    extraMemory: 2Mi\n    memory: 15Mi\n    minClusterSize: 10\n    pollPeriod: 300000\n    threshold: 5\n\nmetrics:\n  enabled: false\n\nserviceMonitor:\n  enabled: false\n  additionalLabels: {}\n  interval: 1m\n  scrapeTimeout: 10s\n  metricRelabelings: []\n  relabelings: []\n\n# See https://github.com/kubernetes-sigs/metrics-server#scaling\nresources: {}\n\nextraVolumeMounts: []\n\nextraVolumes: []\n\nnodeSelector: {}\n\ntolerations: []\n\naffinity: {}\n\ntopologySpreadConstraints: []\n\n# Annotations to add to the deployment\ndeploymentAnnotations: {}\n\nschedulerName: \"\""
            ],
            "verify": false,
            "version": "3.12.1",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "minio_operator",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "operator",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "minio-operator",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "v5.0.15",
                "chart": "operator",
                "name": "minio-operator",
                "namespace": "datalake",
                "revision": 1,
                "values": "{}",
                "version": "5.0.15"
              }
            ],
            "name": "minio-operator",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://operator.min.io",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "5.0.15",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "minio_tenant",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "tenant",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "tenant-production",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "v5.0.15",
                "chart": "tenant",
                "name": "tenant-production",
                "namespace": "datalake",
                "revision": 2,
                "values": "{\"existingSecret\":{\"name\":\"myminio-env-configuration\"},\"ingress\":{\"api\":{\"annotations\":{},\"enabled\":false,\"host\":\"minio.local\",\"ingressClassName\":\"\",\"labels\":{},\"path\":\"/\",\"pathType\":\"Prefix\",\"tls\":[]},\"console\":{\"annotations\":{},\"enabled\":false,\"host\":\"minio-console.local\",\"ingressClassName\":\"\",\"labels\":{},\"path\":\"/\",\"pathType\":\"Prefix\",\"tls\":[]}},\"secrets\":{\"accessKey\":\"jackcitoxp\",\"name\":\"myminio-env-configuration\",\"secretKey\":\"Maniac321.\"},\"tenant\":{\"additionalVolumeMounts\":[],\"additionalVolumes\":[],\"buckets\":[{\"name\":\"bifrost\"},{\"name\":\"bifrost-backup\"}],\"certificate\":{\"certConfig\":{},\"externalCaCertSecret\":[],\"externalCertSecret\":[],\"requestAutoCert\":true},\"configuration\":{\"name\":\"myminio-env-configuration\"},\"env\":[],\"exposeServices\":{},\"features\":{\"bucketDNS\":false,\"domains\":{},\"enableSFTP\":false},\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"quay.io/minio/minio\",\"tag\":\"RELEASE.2023-11-15T20-43-25Z\"},\"imagePullSecret\":{},\"liveness\":{},\"logging\":{},\"metrics\":{\"enabled\":false,\"port\":9000,\"protocol\":\"http\"},\"mountPath\":\"/export\",\"name\":\"bifrost\",\"podManagementPolicy\":\"Parallel\",\"pools\":[{\"affinity\":{},\"annotations\":{},\"containerSecurityContext\":{\"runAsGroup\":1000,\"runAsNonRoot\":true,\"runAsUser\":1000},\"labels\":{},\"name\":\"pool-0\",\"nodeSelector\":{},\"resources\":{},\"securityContext\":{\"fsGroup\":1000,\"fsGroupChangePolicy\":\"OnRootMismatch\",\"runAsGroup\":1000,\"runAsNonRoot\":true,\"runAsUser\":1000},\"servers\":4,\"size\":\"70Gi\",\"storageClassName\":\"openebs-hostpath\",\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumesPerServer\":4}],\"priorityClassName\":\"\",\"prometheusOperator\":false,\"readiness\":{},\"scheduler\":{},\"serviceAccountName\":\"\",\"serviceMetadata\":{},\"startup\":{},\"subPath\":\"/data\",\"users\":[]}}",
                "version": "5.0.15"
              }
            ],
            "name": "tenant-production",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://operator.min.io",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "###\n# Root key for dynamically creating a secret for use with configuring root MinIO User\n# Specify the ``name`` and then a list of environment variables. \n#\n# .. important::\n#\n#    Do not use this in production environments. \n#    This field is intended for use with rapid development or testing only.\n# \n# For example:\n#\n# .. code-block:: yaml\n#\n#    name: myminio-env-configuration\n#    accessKey: minio\n#    secretKey: minio123\n#\nsecrets:\n  name: myminio-env-configuration\n  accessKey: jackcitoxp\n  secretKey: Maniac321.\n###\n# The name of an existing Kubernetes secret to import to the MinIO Tenant\n# The secret must contain a key ``config.env``.\n# The values should be a series of export statements to set environment variables for the Tenant.\n# For example:\n#\n# .. code-block:: shell\n#\n#    stringData:\n#       config.env: | -\n#         export MINIO_ROOT_USER=ROOTUSERNAME\n#         export MINIO_ROOT_PASSWORD=ROOTUSERPASSWORD\n#\nexistingSecret:\n  name: myminio-env-configuration\n###\n# Root key for MinIO Tenant Chart\ntenant:\n  ###\n  # The Tenant name\n  #\n  # Change this to match your preferred MinIO Tenant name.\n  name: bifrost\n  ###\n  # Specify the Operator container image to use for the deployment.\n  # ``image.tag`` \n  # For example, the following sets the image to the ``quay.io/minio/operator`` repo and the v5.0.11 tag.\n  # The container pulls the image if not already present:\n  #\n  # .. code-block:: yaml\n  # \n  #    image:\n  #       repository: quay.io/minio/minio\n  #       tag: RELEASE.2023-11-15T20-43-25Z\n  #       pullPolicy: IfNotPresent\n  #\n  # The chart also supports specifying an image based on digest value:\n  # \n  # .. code-block:: yaml\n  # \n  #    image:\n  #       repository: quay.io/minio/minio@sha256\n  #       digest: 28c80b379c75242c6fe793dfbf212f43c602140a0de5ebe3d9c2a3a7b9f9f983\n  #       pullPolicy: IfNotPresent\n  #\n  #\n  image:\n    repository: quay.io/minio/minio\n    tag: RELEASE.2023-11-15T20-43-25Z\n    pullPolicy: IfNotPresent\n  ###\n  #\n  # An array of Kubernetes secrets to use for pulling images from a private ``image.repository``.\n  # Only one array element is supported at this time.\n  imagePullSecret: {}\n  ###\n  # The Kubernetes `Scheduler \u003chttps://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/\u003e`__ to use for dispatching Tenant pods.\n  #\n  # Specify an empty dictionary ``{}`` to dispatch pods with the default scheduler.\n  scheduler: {}\n  ###\n  # The Kubernetes secret name that contains MinIO environment variable configurations.\n  # The secret is expected to have a key named config.env containing environment variables exports.\n  configuration:\n    name: myminio-env-configuration\n  ###\n  # Top level key for configuring MinIO Pool(s) in this Tenant.\n  #\n  # See `Operator CRD: Pools \u003chttps://min.io/docs/minio/kubernetes/upstream/reference/operator-crd.html#pool\u003e`__ for more information on all subfields.\n  pools:\n  ###\n  # The number of MinIO Tenant Pods / Servers in this pool.\n  # For standalone mode, supply 1. For distributed mode, supply 4 or more.\n  # Note that the operator does not support upgrading from standalone to distributed mode.\n  - servers: 4\n    ###\n    # Custom name for the pool\n    name: pool-0\n    ###\n    # The number of volumes attached per MinIO Tenant Pod / Server.\n    volumesPerServer: 4\n    ###\n    # The capacity per volume requested per MinIO Tenant Pod.\n    size: 70Gi\n    ###\n    # The `storageClass \u003chttps://kubernetes.io/docs/concepts/storage/storage-classes/\u003e`__ to associate with volumes generated for this pool.\n    #\n    # If using Amazon Elastic Block Store (EBS) CSI driver\n    # Please make sure to set xfs for \"csi.storage.k8s.io/fstype\" parameter under StorageClass.parameters.\n    # Docs: https://github.com/kubernetes-sigs/aws-ebs-csi-driver/blob/master/docs/parameters.md\n    storageClassName: openebs-hostpath\n    ###\n    # Specify `annotations \u003chttps://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\u003e`__ to associate to Tenant pods.\n    annotations: {}\n    ###\n    # Specify `labels \u003chttps://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\u003e`__ to associate to Tenant pods.\n    labels: {}\n    ###\n    #\n    # An array of `Toleration labels \u003chttps://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\u003e`__ to associate to Tenant pods.\n    #\n    # These settings determine the distribution of pods across worker nodes.\n    tolerations: []\n    ###\n    # Any `Node Selectors \u003chttps://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/\u003e`__ to apply to Tenant pods.\n    #\n    # The Kubernetes scheduler uses these selectors to determine which worker nodes onto which it can deploy Tenant pods.\n    #\n    # If no worker nodes match the specified selectors, the Tenant deployment will fail.\n    nodeSelector: {}\n    ###\n    #\n    # The `affinity \u003chttps://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/\u003e`__ or anti-affinity settings to apply to Tenant pods.\n    #\n    # These settings determine the distribution of pods across worker nodes and can help prevent or allow colocating pods onto the same worker nodes.\n    affinity: {}\n    ###\n    # \n    # The `Requests or Limits \u003chttps://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\u003e`__ for resources to associate to Tenant pods.\n    #\n    # These settings can control the minimum and maximum resources requested for each pod.\n    # If no worker nodes can meet the specified requests, the Operator may fail to deploy.\n    resources: {}\n    ###\n    # The Kubernetes `SecurityContext \u003chttps://kubernetes.io/docs/tasks/configure-pod-container/security-context/\u003e`__ to use for deploying Tenant resources.\n    #\n    # You may need to modify these values to meet your cluster's security and access settings.\n    #\n    # We recommend disabling recursive permission changes by setting ``fsGroupChangePolicy`` to ``OnRootMismatch`` as those operations can be expensive for certain workloads (e.g. large volumes with many small files).\n    securityContext:\n      runAsUser: 1000\n      runAsGroup: 1000\n      fsGroup: 1000\n      fsGroupChangePolicy: \"OnRootMismatch\"\n      runAsNonRoot: true\n    ###\n    # The Kubernetes `SecurityContext \u003chttps://kubernetes.io/docs/tasks/configure-pod-container/security-context/\u003e`__ to use for deploying Tenant containers.\n    # You may need to modify these values to meet your cluster's security and access settings.\n    containerSecurityContext:\n      runAsUser: 1000\n      runAsGroup: 1000\n      runAsNonRoot: true\n    ###\n    #\n    # An array of `Topology Spread Constraints \u003chttps://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\u003e`__ to associate to Operator Console pods.\n    #\n    # These settings determine the distribution of pods across worker nodes.\n    topologySpreadConstraints: []\n    ###\n    #\n    # The name of a custom `Container Runtime \u003chttps://kubernetes.io/docs/concepts/containers/runtime-class/\u003e`__ to use for the Operator Console pods.\n    # runtimeClassName: \"\"\n  ###\n  # The mount path where Persistent Volumes are mounted inside Tenant container(s).\n  mountPath: /export\n  ###\n  # The Sub path inside Mount path where MinIO stores data.\n  #\n  # .. warning::\n  #\n  #    Treat the ``mountPath`` and ``subPath`` values as immutable once you deploy the Tenant.\n  #    If you change these values post-deployment, then you may have different paths for new and pre-existing data.\n  #    This can vastly increase operational complexity and may result in unpredictable data states.\n  subPath: /data\n  ###\n  # Configures a Prometheus-compatible scraping endpoint at the specified port.\n  metrics:\n    enabled: false\n    port: 9000\n    protocol: http\n  ###\n  # Configures external certificate settings for the Tenant.\n  certificate:\n    ###\n    # Specify an array of Kubernetes TLS secrets, where each entry corresponds to a secret the TLS private key and public certificate pair.\n    #\n    # This is used by MinIO to verify TLS connections from clients using those CAs\n    # If you omit this and have clients using TLS certificates minted by an external CA, those connections may fail with warnings around certificate verification.\n    # See `Operator CRD: TenantSpec \u003chttps://min.io/docs/minio/kubernetes/upstream/reference/operator-crd.html#tenantspec\u003e`__.\n    externalCaCertSecret: []\n    ###\n    # Specify an array of Kubernetes secrets, where each entry corresponds to a secret contains the TLS private key and public certificate pair.\n    #\n    # Omit this to use only the MinIO Operator autogenerated certificates.\n    # \n    # If you omit this field *and* set ``requestAutoCert`` to false, the Tenant starts without TLS.\n    #\n    # See `Operator CRD: TenantSpec \u003chttps://min.io/docs/minio/kubernetes/upstream/reference/operator-crd.html#tenantspec\u003e`__.\n    #\n    # .. important::\n    #\n    #    The MinIO Operator may output TLS connectivity errors if it cannot trust the Certificate Authority (CA) which minted the custom certificates.\n    #\n    #    You can pass the CA to the Operator to allow it to trust that cert.\n    #    See `Self-Signed, Internal, and Private Certificates \u003chttps://min.io/docs/minio/kubernetes/upstream/operations/network-encryption.html#self-signed-internal-and-private-certificates\u003e`__ for more information.\n    #    This step may also be necessary for globally trusted CAs where you must provide intermediate certificates to the Operator to help build the full chain of trust.\n    externalCertSecret: []\n    ###\n    # Enable automatic Kubernetes based `certificate generation and signing \u003chttps://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster\u003e`__\n    requestAutoCert: true\n    ###\n    # This field is used only when ``requestAutoCert: true``.\n    # Use this field to set CommonName for the auto-generated certificate. \n    # MinIO defaults to using the internal Kubernetes DNS name for the pod\n    # The default DNS name format is typically ``*.minio.default.svc.cluster.local``.\n    #\n    # See `Operator CRD: CertificateConfig \u003chttps://min.io/docs/minio/kubernetes/upstream/reference/operator-crd.html#certificateconfig\u003e`__\n    certConfig: {}\n  ###\n  # MinIO features to enable or disable in the MinIO Tenant\n  # See `Operator CRD: Features \u003chttps://min.io/docs/minio/kubernetes/upstream/reference/operator-crd.html#features\u003e`__.\n  features:\n    bucketDNS: false\n    domains: {}\n    enableSFTP: false\n  ###\n  # Array of objects describing one or more buckets to create during tenant provisioning.\n  # Example:\n  # \n  # .. code-block:: yaml\n  #\n  #    - name: my-minio-bucket\n  #         objectLock: false        # optional\n  #         region: us-east-1        # optional\n  buckets:\n  - name: bifrost\n  - name: bifrost-backup\n  ###\n  # Array of Kubernetes secrets from which the Operator generates MinIO users during tenant provisioning.\n  #\n  # Each secret should specify the ``CONSOLE_ACCESS_KEY`` and ``CONSOLE_SECRET_KEY`` as the access key and secret key for that user.\n  users: []\n  ###\n  # The `PodManagement \u003chttps://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy\u003e`__ policy for MinIO Tenant Pods. \n  # Can be \"OrderedReady\" or \"Parallel\"\n  podManagementPolicy: Parallel\n  # The `Liveness Probe \u003chttps://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes\u003e`__ for monitoring Tenant pod liveness. \n  # Tenant pods will be restarted if the probe fails.\n  liveness: {}\n  ###\n  # `Readiness Probe \u003chttps://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\u003e`__ for monitoring Tenant container readiness.\n  # Tenant pods will be removed from service endpoints if the probe fails.\n  readiness: {}\n  ###\n  # `Startup Probe \u003chttps://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\u003e`__ for monitoring container startup. \n  # Tenant pods will be restarted if the probe fails.\n  # Refer \n  startup: {}\n  ###\n  # Directs the Operator to deploy the MinIO S3 API and Console services as LoadBalancer objects.\n  #\n  # If the Kubernetes cluster has a configured LoadBalancer, it can attempt to route traffic to those services automatically.\n  #\n  # - Specify ``minio: true`` to expose the MinIO S3 API.\n  # - Specify ``console: true`` to expose the Console.\n  #\n  # Both fields default to ``false``.\n  exposeServices: {}\n  ###\n  # The `Kubernetes Service Account \u003chttps://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\u003e`__ associated with the Tenant.\n  serviceAccountName: \"\"\n  ###\n  # Directs the Operator to add the Tenant's metric scrape configuration to an existing Kubernetes Prometheus deployment managed by the Prometheus Operator.\n  prometheusOperator: false\n  ###\n  # Configure pod logging configuration for the MinIO Tenant.\n  #\n  # - Specify ``json`` for JSON-formatted logs.\n  # - Specify ``anonymous`` for anonymized logs.\n  # - Specify ``quiet`` to supress logging.\n  #\n  # An example of JSON-formatted logs is as follows:\n  #\n  # .. code-block:: shell\n  #\n  #    $ k logs myminio-pool-0-0 -n default\n  #    {\"level\":\"INFO\",\"errKind\":\"\",\"time\":\"2022-04-07T21:49:33.740058549Z\",\"message\":\"All MinIO sub-systems initialized successfully\"}\n  logging: {}\n  ###\n  # serviceMetadata allows passing additional labels and annotations to MinIO and Console specific\n  # services created by the operator.\n  serviceMetadata: {}\n  ###\n  # Add environment variables to be set in MinIO container (https://github.com/minio/minio/tree/master/docs/config)\n  env: []\n  ###\n  # PriorityClassName indicates the Pod priority and hence importance of a Pod relative to other Pods.\n  # This is applied to MinIO pods only.\n  # Refer Kubernetes documentation for details https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass/\n  priorityClassName: \"\"\n  ###\n  # An array of `Volumes \u003chttps://kubernetes.io/docs/concepts/storage/volumes/\u003e`__ which the Operator can mount to Tenant pods.\n  #\n  # The volumes must exist *and* be accessible to the Tenant pods.\n  additionalVolumes: []\n  ###\n  # An array of volume mount points associated to each Tenant container.\n  # \n  # Specify each item in the array as follows:\n  #\n  # .. code-block:: yaml\n  #\n  #    volumeMounts:\n  #    - name: volumename\n  #      mountPath: /path/to/mount\n  #\n  # The ``name`` field must correspond to an entry in the ``additionalVolumes`` array.\n  additionalVolumeMounts: []\n  # Define configuration for KES (stateless and distributed key-management system)\n  # Refer https://github.com/minio/kes\n  #kes:\n  #  ## Image field:\n  #  # Image from tag (original behavior), for example:\n  #  # image:\n  #  #   repository: quay.io/minio/kes\n  #  #   tag: 2023-11-10T10-44-28Z\n  #  # Image from digest (added after original behavior), for example:\n  #  # image:\n  #  #   repository: quay.io/minio/kes@sha256\n  #  #   digest: fb15af611149892f357a8a99d1bcd8bf5dae713bd64c15e6eb27fbdb88fc208b\n  #  image:\n  #    repository: quay.io/minio/kes\n  #    tag: 2023-11-10T10-44-28Z\n  #    pullPolicy: IfNotPresent\n  #  env: [ ]\n  #  replicas: 2\n  #  configuration: |-\n  #    address: :7373\n  #    root: _ # Effectively disabled since no root identity necessary.\n  #    tls:\n  #      key: /tmp/kes/server.key   # Path to the TLS private key\n  #      cert: /tmp/kes/server.crt # Path to the TLS certificate\n  #      proxy:\n  #        identities: []\n  #        header:\n  #          cert: X-Tls-Client-Cert\n  #    policy:\n  #      my-policy:\n  #        paths:\n  #        - /v1/key/create/*\n  #        - /v1/key/generate/*\n  #        - /v1/key/decrypt/*\n  #        identities:\n  #        - ${MINIO_KES_IDENTITY}\n  #    cache:\n  #      expiry:\n  #        any: 5m0s\n  #        unused: 20s\n  #    log:\n  #      error: on\n  #      audit: off\n  #    keys:\n  #      # KES configured with fs (File System mode) doesn't work in Kubernetes environments and is not recommended\n  #      # use a real KMS\n  #      # fs:\n  #      #   path: \"./keys\" # Path to directory. Keys will be stored as files. Not Recommended for Production.\n  #      vault:\n  #        endpoint: \"http://vault.default.svc.cluster.local:8200\" # The Vault endpoint\n  #        namespace: \"\" # An optional Vault namespace. See: https://www.vaultproject.io/docs/enterprise/namespaces/index.html\n  #        prefix: \"my-minio\"    # An optional K/V prefix. The server will store keys under this prefix.\n  #        approle:    # AppRole credentials. See: https://www.vaultproject.io/docs/auth/approle.html\n  #          id: \"\u003cYOUR APPROLE ID HERE\u003e\"      # Your AppRole Role ID\n  #          secret: \"\u003cYOUR APPROLE SECRET ID HERE\u003e\"  # Your AppRole Secret ID\n  #          retry: 15s  # Duration until the server tries to re-authenticate after connection loss.\n  #        tls:        # The Vault client TLS configuration for mTLS authentication and certificate verification\n  #          key: \"\"     # Path to the TLS client private key for mTLS authentication to Vault\n  #          cert: \"\"    # Path to the TLS client certificate for mTLS authentication to Vault\n  #          ca: \"\"      # Path to one or multiple PEM root CA certificates\n  #        status:     # Vault status configuration. The server will periodically reach out to Vault to check its status.\n  #          ping: 10s   # Duration until the server checks Vault's status again.\n  #      # aws:\n  #      #   # The AWS SecretsManager key store. The server will store\n  #      #   # secret keys at the AWS SecretsManager encrypted with\n  #      #   # AWS-KMS. See: https://aws.amazon.com/secrets-manager\n  #      #   secretsmanager:\n  #      #     endpoint: \"\"   # The AWS SecretsManager endpoint      - e.g.: secretsmanager.us-east-2.amazonaws.com\n  #      #     region: \"\"     # The AWS region of the SecretsManager - e.g.: us-east-2\n  #      #     kmskey: \"\"     # The AWS-KMS key ID used to en/decrypt secrets at the SecretsManager. By default (if not set) the default AWS-KMS key will be used.\n  #      #     credentials:   # The AWS credentials for accessing secrets at the AWS SecretsManager.\n  #      #       accesskey: \"\"  # Your AWS Access Key\n  #      #       secretkey: \"\"  # Your AWS Secret Key\n  #      #       token: \"\"      # Your AWS session token (usually optional)\n  #  imagePullPolicy: \"IfNotPresent\"\n  #  externalCertSecret: null\n  #  clientCertSecret: null\n  #  # Key name to be created on the KMS, default is \"my-minio-key\"\n  #  keyName: \"\"\n  #  resources: { }\n  #  nodeSelector: { }\n  #  affinity:\n  #    nodeAffinity: { }\n  #    podAffinity: { }\n  #    podAntiAffinity: { }\n  #  tolerations: [ ]\n  #  annotations: { }\n  #  labels: { }\n  #  serviceAccountName: \"\"\n  #  securityContext:\n  #    runAsUser: 1000\n  #    runAsGroup: 1000\n  #    runAsNonRoot: true\n  #    fsGroup: 1000\n###\n# Configures `Ingress \u003chttps://kubernetes.io/docs/concepts/services-networking/ingress/\u003e`__ for the Tenant S3 API and Console.\n#\n# Set the keys to conform to the Ingress controller and configuration of your choice.\ningress:\n  api:\n    enabled: false\n    ingressClassName: \"\"\n    labels: {}\n    annotations: {}\n    tls: []\n    host: minio.local\n    path: /\n    pathType: Prefix\n  console:\n    enabled: false\n    ingressClassName: \"\"\n    labels: {}\n    annotations: {}\n    tls: []\n    host: minio-console.local\n    path: /\n    pathType: Prefix\n# Use an extraResources template section to include additional Kubernetes resources\n# with the Helm deployment.\n#extraResources:\n#  - |\n#    apiVersion: v1\n#    kind: Secret\n#    type: Opaque\n#    metadata:\n#      name: {{ dig \"secrets\" \"existingSecret\" \"\" (.Values | merge (dict)) }}\n#    stringData:\n#      config.env: |-\n#        export MINIO_ROOT_USER='minio'\n#        export MINIO_ROOT_PASSWORD='minio123'\n"
            ],
            "verify": false,
            "version": "5.0.15",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "openebs",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "openebs",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "openebs",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "3.10.0",
                "chart": "openebs",
                "name": "openebs",
                "namespace": "openebs",
                "revision": 1,
                "values": "{\"analytics\":{\"enabled\":true,\"pingInterval\":\"24h\"},\"apiserver\":{\"affinity\":{},\"enabled\":true,\"healthCheck\":{\"initialDelaySeconds\":30,\"periodSeconds\":60},\"image\":\"openebs/m-apiserver\",\"imageTag\":\"2.12.2\",\"nodeSelector\":{},\"ports\":{\"externalPort\":5656,\"internalPort\":5656},\"replicas\":1,\"resources\":{},\"sparse\":{\"enabled\":\"false\"},\"tolerations\":[]},\"cleanup\":{\"image\":{\"imagePullSecrets\":[],\"registry\":null,\"repository\":\"bitnami/kubectl\",\"tag\":null}},\"crd\":{\"enableInstall\":true},\"cstor\":{\"enabled\":false,\"openebsNDM\":{\"enabled\":false},\"pool\":{\"image\":\"openebs/cstor-pool\",\"imageTag\":\"2.12.2\"},\"poolMgmt\":{\"image\":\"openebs/cstor-pool-mgmt\",\"imageTag\":\"2.12.2\"},\"target\":{\"image\":\"openebs/cstor-istgt\",\"imageTag\":\"2.12.2\"},\"volumeMgmt\":{\"image\":\"openebs/cstor-volume-mgmt\",\"imageTag\":\"2.12.2\"}},\"defaultStorageConfig\":{\"enabled\":\"true\"},\"featureGates\":{\"APIService\":{\"address\":\"0.0.0.0:9115\",\"enabled\":false,\"featureGateFlag\":\"APIService\"},\"ChangeDetection\":{\"enabled\":false,\"featureGateFlag\":\"ChangeDetection\"},\"GPTBasedUUID\":{\"enabled\":true,\"featureGateFlag\":\"GPTBasedUUID\"},\"PartitionTableUUID\":{\"enabled\":false,\"featureGateFlag\":\"PartitionTableUUID\"},\"UseOSDisk\":{\"enabled\":false,\"featureGateFlag\":\"UseOSDisk\"},\"enabled\":true},\"helper\":{\"image\":\"openebs/linux-utils\",\"imageTag\":\"3.4.0\"},\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"\"},\"imagePullSecrets\":[],\"jiva\":{\"defaultStoragePath\":\"/var/openebs\",\"enabled\":false,\"image\":\"openebs/jiva\",\"imageTag\":\"2.12.2\",\"localpv-provisioner\":{\"openebsNDM\":{\"enabled\":false}},\"openebsLocalpv\":{\"enabled\":false},\"replicas\":3},\"legacy\":{\"enabled\":true},\"localprovisioner\":{\"affinity\":{},\"basePath\":\"/var/openebs/local\",\"deviceClass\":{\"blockDeviceSelectors\":{},\"enabled\":true,\"fsType\":\"ext4\",\"isDefaultClass\":false,\"name\":\"openebs-device\",\"nodeAffinityLabels\":[],\"reclaimPolicy\":\"Delete\"},\"enableDeviceClass\":false,\"enableHostpathClass\":true,\"enableLeaderElection\":true,\"enabled\":true,\"healthCheck\":{\"initialDelaySeconds\":30,\"periodSeconds\":60},\"hostpathClass\":{\"basePath\":\"\",\"enabled\":true,\"ext4Quota\":{\"enabled\":false,\"hardLimitGrace\":\"0%\",\"softLimitGrace\":\"0%\"},\"isDefaultClass\":true,\"name\":\"openebs-hostpath\",\"nodeAffinityLabels\":[],\"reclaimPolicy\":\"Delete\",\"xfsQuota\":{\"enabled\":false,\"hardLimitGrace\":\"0%\",\"softLimitGrace\":\"0%\"}},\"image\":\"openebs/provisioner-localpv\",\"imageTag\":\"3.4.0\",\"nodeSelector\":{},\"replicas\":1,\"resources\":{},\"tolerations\":[],\"waitForBDBindTimeoutRetryCount\":\"12\"},\"localpv-provisioner\":{\"enabled\":false,\"openebsNDM\":{\"enabled\":false}},\"lvm-localpv\":{\"enabled\":false},\"mayastor\":{\"enabled\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"docker.io\",\"repo\":\"openebs\",\"tag\":\"v2.2.0\"}},\"ndm\":{\"enabled\":true,\"filters\":{\"enableOsDiskExcludeFilter\":true,\"enablePathFilter\":true,\"enableVendorFilter\":true,\"excludePaths\":\"/dev/loop,/dev/fd0,/dev/sr0,/dev/ram,/dev/dm-,/dev/md,/dev/rbd,/dev/zd\",\"excludeVendors\":\"CLOUDBYT,OpenEBS\",\"includePaths\":\"\",\"osDiskExcludePaths\":\"/,/etc/hosts,/boot\"},\"healthCheck\":{\"initialDelaySeconds\":30,\"periodSeconds\":60},\"image\":\"openebs/node-disk-manager\",\"imageTag\":\"2.1.0\",\"nodeSelector\":{},\"probes\":{\"enableSeachest\":false},\"resources\":{},\"sparse\":{\"count\":\"0\",\"path\":\"/var/openebs/sparse\",\"size\":\"10737418240\"},\"tolerations\":[]},\"ndmExporter\":{\"clusterExporter\":{\"metricsPort\":9100,\"name\":\"ndm-cluster-exporter\",\"podLabels\":{\"name\":\"openebs-ndm-cluster-exporter\"}},\"enabled\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":null,\"repository\":\"openebs/node-disk-exporter\",\"tag\":\"2.1.0\"},\"nodeExporter\":{\"metricsPort\":9101,\"name\":\"ndm-node-exporter\",\"podLabels\":{\"name\":\"openebs-ndm-node-exporter\"}}},\"ndmOperator\":{\"enabled\":true,\"healthCheck\":{\"initialDelaySeconds\":15,\"periodSeconds\":20},\"image\":\"openebs/node-disk-operator\",\"imageTag\":\"2.1.0\",\"nodeSelector\":{},\"readinessCheck\":{\"initialDelaySeconds\":5,\"periodSeconds\":10},\"replicas\":1,\"resources\":{},\"tolerations\":[],\"upgradeStrategy\":\"Recreate\"},\"nfs-provisioner\":{\"enabled\":false},\"openebs-ndm\":{\"enabled\":false},\"policies\":{\"monitoring\":{\"enabled\":true,\"image\":\"openebs/m-exporter\",\"imageTag\":\"2.12.2\"}},\"provisioner\":{\"affinity\":{},\"enableLeaderElection\":true,\"enabled\":true,\"healthCheck\":{\"initialDelaySeconds\":30,\"periodSeconds\":60},\"image\":\"openebs/openebs-k8s-provisioner\",\"imageTag\":\"2.12.2\",\"nodeSelector\":{},\"patchJivaNodeAffinity\":\"enabled\",\"replicas\":1,\"resources\":{},\"tolerations\":[]},\"rbac\":{\"create\":true,\"kyvernoEnabled\":false,\"pspEnabled\":false},\"release\":{\"version\":\"3.6.0\"},\"serviceAccount\":{\"create\":true,\"name\":\"openebs\"},\"snapshotOperator\":{\"affinity\":{},\"controller\":{\"image\":\"openebs/snapshot-controller\",\"imageTag\":\"2.12.2\",\"resources\":{}},\"enableLeaderElection\":true,\"enabled\":true,\"healthCheck\":{\"initialDelaySeconds\":30,\"periodSeconds\":60},\"nodeSelector\":{},\"provisioner\":{\"image\":\"openebs/snapshot-provisioner\",\"imageTag\":\"2.12.2\",\"resources\":{}},\"replicas\":1,\"tolerations\":[],\"upgradeStrategy\":\"Recreate\"},\"varDirectoryPath\":{\"baseDir\":\"/var/openebs\"},\"webhook\":{\"affinity\":{},\"enabled\":true,\"failurePolicy\":\"Fail\",\"healthCheck\":{\"initialDelaySeconds\":30,\"periodSeconds\":60},\"hostNetwork\":false,\"image\":\"openebs/admission-server\",\"imageTag\":\"2.12.2\",\"nodeSelector\":{},\"replicas\":1,\"resources\":{},\"tolerations\":[]},\"zfs-localpv\":{\"enabled\":false}}",
                "version": "3.10.0"
              }
            ],
            "name": "openebs",
            "namespace": "openebs",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://openebs.github.io/charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [
              {
                "name": "localprovisioner.enableDeviceClass",
                "type": "",
                "value": "false"
              }
            ],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "# Default values for openebs.\n# This is a YAML-formatted file.\n# Declare variables to be passed into your templates.\n\nrbac:\n  # Specifies whether RBAC resources should be created\n  create: true\n  pspEnabled: false\n  # rbac.kyvernoEnabled: `true` if Kyverno Policy resources should be created\n  kyvernoEnabled: false\n\nserviceAccount:\n  create: true\n  name: openebs\n\nimagePullSecrets: []\n  #  - name: image-pull-secret\n\nrelease:\n  # \"openebs.io/version\" label for control plane components\n  version: \"3.6.0\"\n\n# Legacy components will be installed if it is enabled.\n# Legacy components are - admission-server, maya api-server, snapshot-operator\n# and k8s-provisioner\nlegacy:\n  enabled: true\n\nimage:\n  pullPolicy: IfNotPresent\n  repository: \"\"\n\napiserver:\n  enabled: true\n  image: \"openebs/m-apiserver\"\n  imageTag: \"2.12.2\"\n  replicas: 1\n  ports:\n    externalPort: 5656\n    internalPort: 5656\n  sparse:\n    enabled: \"false\"\n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  healthCheck:\n    initialDelaySeconds: 30\n    periodSeconds: 60\n  ## apiserver resource requests and limits\n  ## Reference: http://kubernetes.io/docs/user-guide/compute-resources/\n  resources: {}\n    # limits:\n    #   cpu: 1000m\n    #   memory: 2Gi\n    # requests:\n    #   cpu: 500m\n    #   memory: 1Gi\n\n\ndefaultStorageConfig:\n  enabled: \"true\"\n\n# Directory used by the OpenEBS to store debug information and so forth\n# that are generated in the course of running OpenEBS containers.\nvarDirectoryPath:\n  baseDir: \"/var/openebs\"\n\nprovisioner:\n  enabled: true\n  image: \"openebs/openebs-k8s-provisioner\"\n  imageTag: \"2.12.2\"\n  replicas: 1\n  enableLeaderElection: true\n  patchJivaNodeAffinity: enabled\n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  healthCheck:\n    initialDelaySeconds: 30\n    periodSeconds: 60\n  ## provisioner resource requests and limits\n  ## Reference: http://kubernetes.io/docs/user-guide/compute-resources/\n  resources: {}\n    # limits:\n    #   cpu: 1000m\n    #   memory: 2Gi\n    # requests:\n    #   cpu: 500m\n    #   memory: 1Gi\n\n# If you want to enable local pv as a dependency chart then set\n# `localprovisioner.enabled: false` and enable it as dependency chart.\n# If you are using custom configuration then update those configuration\n# under `localpv-provisioner` key.\nlocalprovisioner:\n  enabled: true\n  image: \"openebs/provisioner-localpv\"\n  imageTag: \"3.4.0\"\n  replicas: 1\n  enableLeaderElection: true\n  # These fields are deprecated. Please use the fields (see below)\n  # - deviceClass.enabled\n  # - hostpathClass.enabled\n  enableDeviceClass: false\n  enableHostpathClass: true\n  # This sets default directory used by the provisioner to provision\n  # hostpath volumes.\n  basePath: \"/var/openebs/local\"\n  # This sets the number of times the provisioner should try\n  # with a polling interval of 5 seconds, to get the Blockdevice\n  # Name from a BlockDeviceClaim, before the BlockDeviceClaim\n  # is deleted. E.g. 12 * 5 seconds = 60 seconds timeout\n  waitForBDBindTimeoutRetryCount: \"12\"\n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  healthCheck:\n    initialDelaySeconds: 30\n    periodSeconds: 60\n  ## localprovisioner resource requests and limits\n  ## Reference: http://kubernetes.io/docs/user-guide/compute-resources/\n  resources: {}\n    # limits:\n    #   cpu: 1000m\n    #   memory: 2Gi\n    # requests:\n    #   cpu: 500m\n    #   memory: 1Gi\n\n  deviceClass:\n    # Name of default device StorageClass.\n    name: openebs-device\n    # If true, enables creation of the openebs-device StorageClass\n    enabled: true\n    # Available reclaim policies: Delete/Retain, defaults: Delete.\n    reclaimPolicy: Delete\n    # If true, sets the openebs-device StorageClass as the default StorageClass\n    isDefaultClass: false\n    # Custom node affinity label(s) for example \"openebs.io/node-affinity-value\"\n    # that will be used instead of hostnames\n    # This helps in cases where the hostname changes when the node is removed and\n    # added back with the disks still intact.\n    # Example:\n    #          nodeAffinityLabels:\n    #            - \"openebs.io/node-affinity-key-1\"\n    #            - \"openebs.io/node-affinity-key-2\"\n    nodeAffinityLabels: []\n    # Sets the filesystem to be written to the blockdevice before\n    # mounting (filesystem volumes)\n    # This is only usable if the selected BlockDevice does not already\n    # have a filesystem\n    # Valid values: \"ext4\", \"xfs\"\n    fsType: \"ext4\"\n    # Label block devices in the cluster that you would like the openEBS localPV\n    # Provisioner to pick up those specific block devices available on the node.\n    # Set the label key and value as shown in the example below.\n    #\n    # To read more: https://github.com/openebs/dynamic-localpv-provisioner/blob/develop/docs/tutorials/device/blockdevicetag.md\n    #\n    # Example:\n    #          blockDeviceSelectors:\n    #            ndm.io/driveType: \"SSD\"\n    #            ndm.io/fsType: \"none\"\n    blockDeviceSelectors: {}\n\n  hostpathClass:\n    # Name of the default hostpath StorageClass\n    name: openebs-hostpath\n    # If true, enables creation of the openebs-hostpath StorageClass\n    enabled: true\n    # Available reclaim policies: Delete/Retain, defaults: Delete.\n    reclaimPolicy: Delete\n    # If true, sets the openebs-hostpath StorageClass as the default StorageClass\n    isDefaultClass: true\n    # Path on the host where local volumes of this storage class are mounted under.\n    # NOTE: If not specified, this defaults to the value of localprovisioner.basePath.\n    basePath: \"\"\n    # Custom node affinity label(s) for example \"openebs.io/node-affinity-value\"\n    # that will be used instead of hostnames\n    # This helps in cases where the hostname changes when the node is removed and\n    # added back with the disks still intact.\n    # Example:\n    #          nodeAffinityLabels:\n    #            - \"openebs.io/node-affinity-key-1\"\n    #            - \"openebs.io/node-affinity-key-2\"\n    nodeAffinityLabels: []\n    # Prerequisite: XFS Quota requires an XFS filesystem mounted with\n    # the 'pquota' or 'prjquota' mount option.\n    xfsQuota:\n      # If true, enables XFS project quota\n      enabled: false\n      # Detailed configuration options for XFS project quota.\n      # If XFS Quota is enabled with the default values, the usage limit\n      # is set at the storage capacity specified in the PVC.\n      softLimitGrace: \"0%\"\n      hardLimitGrace: \"0%\"\n    # Prerequisite: EXT4 Quota requires an EXT4 filesystem mounted with\n    # the 'prjquota' mount option.\n    ext4Quota:\n      # If true, enables XFS project quota\n      enabled: false\n      # Detailed configuration options for EXT4 project quota.\n      # If EXT4 Quota is enabled with the default values, the usage limit\n      # is set at the storage capacity specified in the PVC.\n      softLimitGrace: \"0%\"\n      hardLimitGrace: \"0%\"\n\nsnapshotOperator:\n  enabled: true\n  controller:\n    image: \"openebs/snapshot-controller\"\n    imageTag: \"2.12.2\"\n    ## snapshot controller resource requests and limits\n    ## Reference: http://kubernetes.io/docs/user-guide/compute-resources/\n    resources: {}\n      # limits:\n      #   cpu: 1000m\n      #   memory: 2Gi\n      # requests:\n      #   cpu: 500m\n      #   memory: 1Gi\n  provisioner:\n    image: \"openebs/snapshot-provisioner\"\n    imageTag: \"2.12.2\"\n    ## snapshot provisioner resource requests and limits\n    ## Reference: http://kubernetes.io/docs/user-guide/compute-resources/\n    resources: {}\n      # limits:\n      #   cpu: 1000m\n      #   memory: 2Gi\n      # requests:\n      #   cpu: 500m\n      #   memory: 1Gi\n  replicas: 1\n  enableLeaderElection: true\n  upgradeStrategy: \"Recreate\"\n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  healthCheck:\n    initialDelaySeconds: 30\n    periodSeconds: 60\n\n# If you want to enable openebs as a dependency chart then set `ndm.enabled: false`,\n# `ndmOperator.enabled: false` and enable it as dependency chart. If you are using\n# custom configuration then update those configuration under `openebs-ndm` key.\nndm:\n  enabled: true\n  image: \"openebs/node-disk-manager\"\n  imageTag: \"2.1.0\"\n  sparse:\n    path: \"/var/openebs/sparse\"\n    size: \"10737418240\"\n    count: \"0\"\n  filters:\n    enableOsDiskExcludeFilter: true\n    osDiskExcludePaths: \"/,/etc/hosts,/boot\"\n    enableVendorFilter: true\n    excludeVendors: \"CLOUDBYT,OpenEBS\"\n    enablePathFilter: true\n    includePaths: \"\"\n    excludePaths: \"/dev/loop,/dev/fd0,/dev/sr0,/dev/ram,/dev/dm-,/dev/md,/dev/rbd,/dev/zd\"\n  probes:\n    enableSeachest: false\n  nodeSelector: {}\n  tolerations: []\n  healthCheck:\n    initialDelaySeconds: 30\n    periodSeconds: 60\n  ## ndm resource requests and limits\n  ## Reference: http://kubernetes.io/docs/user-guide/compute-resources/\n  resources: {}\n    # limits:\n    #   cpu: 1000m\n    #   memory: 2Gi\n    # requests:\n    #   cpu: 500m\n    #   memory: 1Gi\n\n# If you want to enable openebs as a dependency chart then set `ndm.enabled: false`,\n# `ndmOperator.enabled: false` and enable it as dependency chart. If you are using\n# custom configuration then update those configuration under `openebs-ndm` key.\nndmOperator:\n  enabled: true\n  image: \"openebs/node-disk-operator\"\n  imageTag: \"2.1.0\"\n  replicas: 1\n  upgradeStrategy: Recreate\n  nodeSelector: {}\n  tolerations: []\n  healthCheck:\n    initialDelaySeconds: 15\n    periodSeconds: 20\n  readinessCheck:\n    initialDelaySeconds: 5\n    periodSeconds: 10\n  ## ndmOperator resource requests and limits\n  ## Reference: http://kubernetes.io/docs/user-guide/compute-resources/\n  resources: {}\n    # limits:\n    #   cpu: 1000m\n    #   memory: 2Gi\n    # requests:\n    #   cpu: 500m\n    #   memory: 1Gi\n\nndmExporter:\n  enabled: false\n  image:\n    registry:\n    repository: openebs/node-disk-exporter\n    pullPolicy: IfNotPresent\n    # Overrides the image tag whose default is the chart appVersion.\n    tag: 2.1.0\n  nodeExporter:\n    name: ndm-node-exporter\n    podLabels:\n      name: openebs-ndm-node-exporter\n    # The TCP port number used for exposing ndm-node-exporter metrics.\n    # If not set, service will not be created to expose metrics endpoint to serviceMonitor\n    # and listen-port flag will not be set and container port will be empty.\n    metricsPort: 9101\n  clusterExporter:\n    name: ndm-cluster-exporter\n    podLabels:\n      name: openebs-ndm-cluster-exporter\n    # The TCP port number used for exposing ndm-cluster-exporter metrics.\n    # If not set, service will not be created to expose metrics endpoint to serviceMonitor\n    # and listen-port flag will not be set and container port will be empty.\n    metricsPort: 9100\n\nwebhook:\n  enabled: true\n  image: \"openebs/admission-server\"\n  imageTag: \"2.12.2\"\n  failurePolicy: \"Fail\"\n  replicas: 1\n  healthCheck:\n    initialDelaySeconds: 30\n    periodSeconds: 60\n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  hostNetwork: false\n  ## admission-server resource requests and limits\n  ## Reference: http://kubernetes.io/docs/user-guide/compute-resources/\n  resources: {}\n    # limits:\n    #   cpu: 500m\n    #   memory: 1Gi\n    # requests:\n    #   cpu: 250m\n    #   memory: 500Mi\n\n# If you are migrating from 2.x to 3.x and if you are using custom values\n# then put this configuration under `localpv-provisioner` and `openebs-ndm` key.\nhelper:\n  image: \"openebs/linux-utils\"\n  imageTag: \"3.4.0\"\n\n# These are ndm related configuration. If you want to enable openebs as a dependency\n# chart then set `ndm.enabled: false`, `ndmOperator.enabled: false` and enable it as\n# dependency chart. If you are using custom configuration then update those configuration\n# under `openebs-ndm` key.\nfeatureGates:\n  enabled: true\n  GPTBasedUUID:\n    enabled: true\n    featureGateFlag: \"GPTBasedUUID\"\n  APIService:\n    enabled: false\n    featureGateFlag: \"APIService\"\n    address: \"0.0.0.0:9115\"\n  UseOSDisk:\n    enabled: false\n    featureGateFlag: \"UseOSDisk\"\n  ChangeDetection:\n    enabled: false\n    featureGateFlag: \"ChangeDetection\"\n  PartitionTableUUID:\n    enabled: false\n    featureGateFlag: \"PartitionTableUUID\"\n\ncrd:\n  enableInstall: true\n\n# If you are migrating from 2.x to 3.x and if you are using custom values\n# then put these configuration under `cstor` key.\npolicies:\n  monitoring:\n    enabled: true\n    image: \"openebs/m-exporter\"\n    imageTag: \"2.12.2\"\n\nanalytics:\n  enabled: true\n  # Specify in hours the duration after which a ping event needs to be sent.\n  pingInterval: \"24h\"\n\nmayastor:\n  # -- Enable Mayastor storage engine\n  # Note: Enabling this will remove LocalPV Provisioner and NDM (default chart components).\n  enabled: false\n\n  # Sample configuration, if you want to configure mayastor with custom values.\n  # This is a small part of the full configuration. Full configuration available\n  # here - https://github.com/openebs/mayastor-extensions/blob/v2.2.0/chart/values.yaml\n\n  image:\n    # -- Image registry to pull Mayastor product images\n    registry: docker.io\n    # -- Image registry's namespace\n    repo: openebs\n    # -- Release tag for Mayastor images\n    tag: v2.2.0\n    # -- ImagePullPolicy for Mayastor images\n    pullPolicy: IfNotPresent\n\n  # -- Pod scheduling priority\n  # ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n  # priorityClassName: \"\"\n\n  # base:\n  #   # docker-secrets required to pull images if the container registry from image.Registry is protected\n  #   imagePullSecrets:\n  #     # -- Enable imagePullSecrets for pulling our container images\n  #     enabled: false\n  #     # Name of the imagePullSecret in the installed namespace\n  #     secrets:\n  #       - name: login\n\n  #   metrics:\n  #     # -- Enable the metrics exporter\n  #     enabled: true\n\n  #   jaeger:\n  #     # -- Enable jaeger tracing\n  #     enabled: false\n\n  # operators:\n  #   pool:\n  #     # -- Log level for diskpool operator service\n  #     logLevel: info\n\n  # jaeger-operator:\n  #   # Name of jaeger operator\n  #   name: \"{{ .Release.Name }}\"\n  #   crd:\n  #     # Install jaeger CRDs\n  #     install: false\n  #   jaeger:\n  #     # Install jaeger-operator\n  #     create: false\n  #   rbac:\n  #     # Create a clusterRole for Jaeger\n  #     clusterRole: true\n\n  # agents:\n  #   core:\n  #     # -- Log level for the core service\n  #     logLevel: info\n  #     capacity:\n  #       thin:\n  #       # -- The allowed pool commitment limit when dealing with thin provisioned volumes.\n  #       # Example: If the commitment is 250 and the pool is 10GiB we can overcommit the pool\n  #       # up to 25GiB (create 2 10GiB and 1 5GiB volume) but no further.\n  #       poolCommitment: \"250%\"\n  #       # -- When creating replicas for an existing volume, each replica pool must have at least\n  #       # this much free space percentage of the volume size.\n  #       # Example: if this value is 40, the pool has 40GiB free, then the max volume size allowed\n  #       # to be created on the pool is 100GiB.\n  #       volumeCommitment: \"40%\"\n  #       # -- Same as the `volumeCommitment` argument, but applicable only when creating replicas\n  #       # for a new volume.\n  #       volumeCommitmentInitial: \"40%\"\n  #   ha:\n  #     enabled: true\n  #     node:\n  #       # -- Log level for the ha node service\n  #       logLevel: info\n  #     cluster:\n  #       # -- Log level for the ha cluster service\n  #       logLevel: info\n\n  # apis:\n  #   rest:\n  #     # -- Log level for the rest service\n  #     logLevel: info\n  #     # -- Number of replicas of rest\n  #     replicaCount: 1\n\n  # csi:\n  #   image:\n  #     # -- Image registry to pull all CSI Sidecar images\n  #     registry: registry.k8s.io\n  #     # -- Image registry's namespace\n  #     repo: sig-storage\n  #     # -- imagePullPolicy for all CSI Sidecar images\n  #     pullPolicy: IfNotPresent\n  #     # -- csi-provisioner image release tag\n  #     provisionerTag: v2.2.1\n  #     # -- csi-attacher image release tag\n  #     attacherTag: v3.2.1\n  #     # -- csi-node-driver-registrar image release tag\n  #     registrarTag: v2.1.0\n\n  #   controller:\n  #     # -- Log level for the csi controller\n  #     logLevel: info\n\n  #   node:\n  #     logLevel: info\n  #     topology:\n  #       segments:\n  #         openebs.io/csi-node: mayastor\n  #       # -- Add topology segments to the csi-node daemonset node selector\n  #       nodeSelector: false\n  #     kubeletDir: /var/lib/kubelet\n\n  # io_engine:\n  #   # -- Log level for the io-engine service\n  #   logLevel: info\n  #   # -- Node selectors to designate storage nodes for diskpool creation\n  #   # Note that if multi-arch images support 'kubernetes.io/arch: amd64'\n  #   # should be removed.\n  #   nodeSelector:\n  #     openebs.io/engine: mayastor\n  #     kubernetes.io/arch: amd64\n\n  # etcd:\n  #   # Pod labels; okay to remove the openebs logging label if required\n  #   podLabels:\n  #     app: etcd\n  #     openebs.io/logging: \"true\"\n  #   # -- Number of replicas of etcd\n  #   replicaCount: 3\n  #   persistence:\n  #     # -- If true, use a Persistent Volume Claim. If false, use emptyDir.\n  #     enabled: true\n  #     # -- Will define which storageClass to use in etcd's StatefulSets\n  #     # a `manual` storageClass will provision a hostpath PV on the same node\n  #     # an empty storageClass will use the default StorageClass on the cluster\n  #     storageClass: \"\"\n  #     # -- Volume size\n  #     size: 2Gi\n  #   podAntiAffinityPreset: \"hard\"\n\n  # loki-stack:\n  #   # -- Enable loki log collection for Mayastor components\n  #   enabled: true\n\n  # obs:\n  #   callhome:\n  #     # -- Enable callhome\n  #     enabled: true\n  #     # -- Log level for callhome\n  #     logLevel: \"info\"\n\njiva:\n  # non csi configuration\n  image: \"openebs/jiva\"\n  imageTag: \"2.12.2\"\n  replicas: 3\n  defaultStoragePath: \"/var/openebs\"\n\n  # jiva csi driver configuration\n  # do not enable or configure any sub dependency here\n  # only jiva csi related settings can be added here\n  # ref - https://openebs.github.io/jiva-operator\n\n  # jiva chart dependency tree is here -\n  # jiva\n  # | - localpv-provisioner\n  # | | - openebs-ndm\n\n  # Enable localpv-provisioner and openebs-ndm as root dependency not as\n  # sub dependency.\n  # openebs\n  # | - jiva(enable)\n  # | | - localpv-provisioner(disable)\n  # | | | - openebs-ndm(disable)\n  # | - localpv-provisioner(enable)\n  # | - openebs-ndm(enable)\n\n  enabled: false\n  openebsLocalpv:\n    enabled: false\n  localpv-provisioner:\n    openebsNDM:\n      enabled: false\n\n  # Sample configuration if you want to configure jiva csi driver with custom values.\n  # This is a small part of the full configuration. Full configuration available\n  # here - https://openebs.github.io/jiva-operator\n\n#  rbac:\n#    create: true\n#    pspEnabled: false\n#\n#  jivaOperator:\n#    controller:\n#      image:\n#        registry: quay.io/\n#        repository: openebs/jiva\n#        tag: 3.4.0\n#    replica:\n#      image:\n#        registry: quay.io/\n#        repository: openebs/jiva\n#        tag: 3.4.0\n#    image:\n#      registry: quay.io/\n#      repository: openebs/jiva-operator\n#      pullPolicy: IfNotPresent\n#      tag: 3.4.0\n#\n#  jivaCSIPlugin:\n#    remount: \"true\"\n#    image:\n#      registry: quay.io/\n#      repository: openebs/jiva-csi\n#      pullPolicy: IfNotPresent\n#      tag: 3.4.0\n\ncstor:\n\n  # non csi configuration\n  pool:\n    image: \"openebs/cstor-pool\"\n    imageTag: \"2.12.2\"\n  poolMgmt:\n    image: \"openebs/cstor-pool-mgmt\"\n    imageTag: \"2.12.2\"\n  target:\n    image: \"openebs/cstor-istgt\"\n    imageTag: \"2.12.2\"\n  volumeMgmt:\n    image: \"openebs/cstor-volume-mgmt\"\n    imageTag: \"2.12.2\"\n\n  # cstor csi driver configuration\n  # do not enable or configure any sub dependency here\n  # only cstor csi related settings can be added here\n  # ref - https://openebs.github.io/cstor-operators\n\n  # cstor chart dependency tree is here -\n  # cstor\n  # | - openebs-ndm\n\n  # Enable openebs-ndm as root dependency not as sub dependency.\n  # openebs\n  # | - cstor(enable)\n  # | | - openebs-ndm(disable)\n  # | - openebs-ndm(enable)\n  enabled: false\n  openebsNDM:\n    enabled: false\n\n  # Sample configuration if you want to configure cstor csi driver with custom values.\n  # This is a small part of the full configuration. Full configuration available\n  # here - https://openebs.github.io/cstor-operators\n\n#  imagePullSecrets: []\n#\n#  rbac:\n#    create: true\n#    pspEnabled: false\n#\n#  cspcOperator:\n#    poolManager:\n#      image:\n#        registry: quay.io/\n#        repository: openebs/cstor-pool-manager\n#        tag: 3.4.0\n#    cstorPool:\n#      image:\n#        registry: quay.io/\n#        repository: openebs/cstor-pool\n#        tag: 3.4.0\n#    cstorPoolExporter:\n#      image:\n#        registry: quay.io/\n#        repository: openebs/m-exporter\n#        tag: 3.4.0\n#    image:\n#      registry: quay.io/\n#      repository: openebs/cspc-operator\n#      pullPolicy: IfNotPresent\n#      tag: 3.4.0\n#\n#  cvcOperator:\n#    target:\n#      image:\n#        registry: quay.io/\n#        repository: openebs/cstor-istgt\n#        tag: 3.4.0\n#    volumeMgmt:\n#      image:\n#        registry: quay.io/\n#        repository: openebs/cstor-volume-manager\n#        tag: 3.4.0\n#    volumeExporter:\n#      image:\n#        registry: quay.io/\n#        repository: openebs/m-exporter\n#        tag: 3.4.0\n#    image:\n#      registry: quay.io/\n#      repository: openebs/cvc-operator\n#      pullPolicy: IfNotPresent\n#      tag: 3.4.0\n#\n#  cstorCSIPlugin:\n#    image:\n#      registry: quay.io/\n#      repository: openebs/cstor-csi-driver\n#      pullPolicy: IfNotPresent\n#      tag: 3.4.0\n#\n#  admissionServer:\n#    componentName: cstor-admission-webhook\n#    image:\n#      registry: quay.io/\n#      repository: openebs/cstor-webhook\n#      pullPolicy: IfNotPresent\n#      tag: 3.4.0\n\n# ndm configuration goes here\n# https://openebs.github.io/node-disk-manager\nopenebs-ndm:\n  enabled: false\n\n  # Sample configuration if you want to configure openebs ndm with custom values.\n  # This is a small part of the full configuration. Full configuration available\n  # here - https://openebs.github.io/node-disk-manager\n\n#  imagePullSecrets: []\n#\n#  ndm:\n#    image:\n#      registry: quay.io/\n#      repository: openebs/node-disk-manager\n#      pullPolicy: IfNotPresent\n#      tag: 2.1.0\n#    sparse:\n#      path: \"/var/openebs/sparse\"\n#      size: \"10737418240\"\n#      count: \"0\"\n#    filters:\n#      enableOsDiskExcludeFilter: true\n#      osDiskExcludePaths: \"/,/etc/hosts,/boot\"\n#      enableVendorFilter: true\n#      excludeVendors: \"CLOUDBYT,OpenEBS\"\n#      enablePathFilter: true\n#      includePaths: \"\"\n#      excludePaths: \"loop,fd0,sr0,/dev/ram,/dev/dm-,/dev/md,/dev/rbd,/dev/zd\"\n#    probes:\n#      enableSeachest: false\n#      enableUdevProbe: true\n#      enableSmartProbe: true\n#\n#  ndmOperator:\n#    image:\n#      registry: quay.io/\n#      repository: openebs/node-disk-operator\n#      pullPolicy: IfNotPresent\n#      tag: 2.1.0\n#\n#  helperPod:\n#    image:\n#      registry: quay.io/\n#      repository: openebs/linux-utils\n#      pullPolicy: IfNotPresent\n#      tag: 3.4.0\n#\n#  featureGates:\n#    enabled: true\n#    GPTBasedUUID:\n#      enabled: true\n#      featureGateFlag: \"GPTBasedUUID\"\n#    APIService:\n#      enabled: false\n#      featureGateFlag: \"APIService\"\n#      address: \"0.0.0.0:9115\"\n#    UseOSDisk:\n#      enabled: false\n#      featureGateFlag: \"UseOSDisk\"\n#    ChangeDetection:\n#      enabled: false\n#      featureGateFlag: \"ChangeDetection\"\n#\n#  varDirectoryPath:\n#    baseDir: \"/var/openebs\"\n\n  # local pv provisioner configuration goes here\n  # do not enable or configure any sub dependency here\n  # ref - https://openebs.github.io/dynamic-localpv-provisioner\n\n  # local pv chart dependency tree is here -\n  # localpv-provisioner\n  # | - openebs-ndm\n\n  # Enable openebs-ndm as root dependency not as sub dependency.\n  # openebs\n  # | - localpv-provisioner(enable)\n  # | | - openebs-ndm(disable)\n  # | - openebs-ndm(enable)\nlocalpv-provisioner:\n  enabled: false\n  openebsNDM:\n    enabled: false\n\n  # Sample configuration if you want to configure openebs locapv with custom values.\n  # This is a small part of the full configuration. Full configuration available\n  # here - https://openebs.github.io/dynamic-localpv-provisioner\n\n#  imagePullSecrets: []\n#\n#  rbac:\n#    create: true\n#    pspEnabled: false\n#\n#  localpv:\n#    image:\n#      registry: quay.io/\n#      repository: openebs/provisioner-localpv\n#      tag: 3.4.0\n#      pullPolicy: IfNotPresent\n#    healthCheck:\n#      initialDelaySeconds: 30\n#      periodSeconds: 60\n#    replicas: 1\n#    enableLeaderElection: true\n#    basePath: \"/var/openebs/local\"\n#\n#  helperPod:\n#    image:\n#      registry: quay.io/\n#      repository: openebs/linux-utils\n#      pullPolicy: IfNotPresent\n#      tag: 3.4.0\n\n# zfs local pv configuration goes here\n# ref - https://openebs.github.io/zfs-localpv\nzfs-localpv:\n  enabled: false\n\n  # Sample configuration if you want to configure zfs locapv with custom values.\n  # This is a small part of the full configuration. Full configuration available\n  # here - https://openebs.github.io/zfs-localpv\n\n#  imagePullSecrets: []\n#\n#  rbac:\n#    pspEnabled: false\n#\n#  zfsPlugin:\n#    image:\n#      registry: quay.io/\n#      repository: openebs/zfs-driver\n#      pullPolicy: IfNotPresent\n#      tag: 2.2.0\n\n# lvm local pv configuration goes here\n# ref - https://openebs.github.io/lvm-localpv\nlvm-localpv:\n  enabled: false\n\n  # Sample configuration if you want to configure lvm localpv with custom values.\n  # This is a small part of the full configuration. Full configuration available\n  # here - https://openebs.github.io/lvm-localpv\n\n#  imagePullSecrets: []\n#\n#  rbac:\n#    pspEnabled: false\n#\n#  lvmPlugin:\n#    image:\n#      registry: quay.io/\n#      repository: openebs/lvm-driver\n#      pullPolicy: IfNotPresent\n#      tag: 1.1.0\n\n# openebs nfs provisioner configuration goes here\n# ref - https://openebs.github.io/dynamic-nfs-provisioner\nnfs-provisioner:\n  enabled: false\n\n  # Sample configuration if you want to configure nfs-provisioner with custom values.\n  # This is a small part of the full configuration. Full configuration available\n  # here - https://openebs.github.io/dynamic-nfs-provisioner\n\n#  imagePullSecrets: []\n#\n#  rbac:\n#    pspEnabled: false\n#\n#  nfsProvisioner:\n#    image:\n#      registry:\n#      repository: openebs/provisioner-nfs\n#      tag: 0.10.0\n#      pullPolicy: IfNotPresent\n#    enableLeaderElection: \"true\"\n#    nfsServerAlpineImage:\n#      registry:\n#      repository: openebs/nfs-server-alpine\n#      tag: 0.10.0\n\ncleanup:\n  image:\n    # Make sure that registry name end with a '/'.\n    # For example : quay.io/ is a correct value here and quay.io is incorrect\n    registry:\n    repository: bitnami/kubectl\n    tag:\n    imagePullSecrets: []\n      #  - name: image-pull-secret"
            ],
            "verify": false,
            "version": "3.10.0",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_namespace.openebs-namespace"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "percona_mongo",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "psmdb-db",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "percona-mongo",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.15.0",
                "chart": "psmdb-db",
                "name": "percona-mongo",
                "namespace": "datalake",
                "revision": 7,
                "values": "{\"expose\":{\"enabled\":true,\"exposeType\":\"ClusterIP\"},\"volumeSpec\":{\"pvc\":{\"resources\":{\"requests\":{\"storage\":\"30Gi\"}}}}}",
                "version": "1.15.3"
              }
            ],
            "name": "percona-mongo",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://percona.github.io/percona-helm-charts/",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [
              {
                "name": "expose.enabled",
                "type": "",
                "value": "true"
              },
              {
                "name": "expose.exposeType",
                "type": "",
                "value": "ClusterIP"
              },
              {
                "name": "volumeSpec.pvc.resources.requests.storage",
                "type": "",
                "value": "30Gi"
              }
            ],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "1.15.3",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "percona_mongo_auth",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "psmdb-db",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "percona-mongo-auth",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.15.0",
                "chart": "psmdb-db",
                "name": "percona-mongo-auth",
                "namespace": "datalake",
                "revision": 1,
                "values": "{\"expose\":{\"enabled\":true,\"exposeType\":\"ClusterIP\"}}",
                "version": "1.15.3"
              }
            ],
            "name": "percona-mongo-auth",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://percona.github.io/percona-helm-charts/",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [
              {
                "name": "expose.enabled",
                "type": "",
                "value": "true"
              },
              {
                "name": "expose.exposeType",
                "type": "",
                "value": "ClusterIP"
              }
            ],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "1.15.3",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "percona_mongo_operator",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "psmdb-operator",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "percona-mongo-operator",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.15.0",
                "chart": "psmdb-operator",
                "name": "percona-mongo-operator",
                "namespace": "datalake",
                "revision": 1,
                "values": "{}",
                "version": "1.15.4"
              }
            ],
            "name": "percona-mongo-operator",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://percona.github.io/percona-helm-charts/",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "1.15.4",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "postgres_airflow_operator",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "postgresql",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "postgres-airflow",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "16.3.0",
                "chart": "postgresql",
                "name": "postgres-airflow",
                "namespace": "datalake",
                "revision": 3,
                "values": "{\"architecture\":\"standalone\",\"audit\":{\"clientMinMessages\":\"error\",\"logConnections\":false,\"logDisconnections\":false,\"logHostname\":false,\"logLinePrefix\":\"\",\"logTimezone\":\"\",\"pgAuditLog\":\"\",\"pgAuditLogCatalog\":\"off\"},\"auth\":{\"database\":\"hdfs\",\"enablePostgresUser\":true,\"existingSecret\":\"\",\"password\":\"Maniac321.\",\"postgresPassword\":\"\",\"replicationPassword\":\"\",\"replicationUsername\":\"repl_user\",\"secretKeys\":{\"adminPasswordKey\":\"postgres-password\",\"replicationPasswordKey\":\"replication-password\",\"userPasswordKey\":\"password\"},\"usePasswordFiles\":false,\"username\":\"hdfs\"},\"clusterDomain\":\"cluster.local\",\"commonAnnotations\":{},\"commonLabels\":{},\"containerPorts\":{\"postgresql\":5432},\"diagnosticMode\":{\"args\":[\"infinity\"],\"command\":[\"sleep\"],\"enabled\":false},\"extraDeploy\":[],\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"postgresql\":{\"auth\":{\"database\":\"hdfs\",\"existingSecret\":\"\",\"password\":\"Maniac321.\",\"postgresPassword\":\"Maniac321.\",\"secretKeys\":{\"adminPasswordKey\":\"\",\"replicationPasswordKey\":\"\",\"userPasswordKey\":\"\"},\"username\":\"hdfs\"},\"service\":{\"ports\":{\"postgresql\":\"\"}}},\"storageClass\":\"\"},\"image\":{\"debug\":false,\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/postgresql\",\"tag\":\"15.3.0-debian-11-r7\"},\"kubeVersion\":\"\",\"ldap\":{\"basedn\":\"\",\"binddn\":\"\",\"bindpw\":\"\",\"enabled\":false,\"port\":\"\",\"prefix\":\"\",\"scheme\":\"\",\"searchAttribute\":\"\",\"searchFilter\":\"\",\"server\":\"\",\"suffix\":\"\",\"tls\":{\"enabled\":false},\"uri\":\"\"},\"metrics\":{\"containerPorts\":{\"metrics\":9187},\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customMetrics\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"enabled\":false,\"extraEnvVars\":[],\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/postgres-exporter\",\"tag\":\"0.12.0-debian-11-r91\"},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"prometheusRule\":{\"enabled\":false,\"labels\":{},\"namespace\":\"\",\"rules\":[]},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"resources\":{\"limits\":{},\"requests\":{}},\"service\":{\"annotations\":{\"prometheus.io/port\":\"{{ .Values.metrics.service.ports.metrics }}\",\"prometheus.io/scrape\":\"true\"},\"clusterIP\":\"\",\"ports\":{\"metrics\":9187},\"sessionAffinity\":\"None\"},\"serviceMonitor\":{\"enabled\":false,\"honorLabels\":false,\"interval\":\"\",\"jobLabel\":\"\",\"labels\":{},\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scrapeTimeout\":\"\",\"selector\":{}},\"startupProbe\":{\"enabled\":false,\"failureThreshold\":15,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1}},\"nameOverride\":\"\",\"networkPolicy\":{\"egressRules\":{\"customRules\":[],\"denyConnectionsToExternal\":false},\"enabled\":false,\"ingressRules\":{\"primaryAccessOnlyFrom\":{\"customRules\":[],\"enabled\":false,\"namespaceSelector\":{},\"podSelector\":{}},\"readReplicasAccessOnlyFrom\":{\"customRules\":[],\"enabled\":false,\"namespaceSelector\":{},\"podSelector\":{}}},\"metrics\":{\"enabled\":false,\"namespaceSelector\":{},\"podSelector\":{}}},\"postgresqlDataDir\":\"/bitnami/postgresql/data\",\"postgresqlSharedPreloadLibraries\":\"pgaudit\",\"primary\":{\"affinity\":{},\"annotations\":{},\"args\":[],\"command\":[],\"configuration\":\"\",\"containerSecurityContext\":{\"enabled\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"existingConfigmap\":\"\",\"existingExtendedConfigmap\":\"\",\"extendedConfiguration\":\"\",\"extraEnvVars\":[{\"name\":\"POSTGRESQL_MAX_CONNECTIONS\",\"value\":\"750\"}],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraPodSpec\":{},\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"hostIPC\":false,\"hostNetwork\":false,\"initContainers\":[],\"initdb\":{\"args\":\"\",\"password\":\"\",\"postgresqlWalDir\":\"\",\"scripts\":{},\"scriptsConfigMap\":\"\",\"scriptsSecret\":\"\",\"user\":\"\"},\"labels\":{},\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"name\":\"primary\",\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{\"airflow\":\"nodeok\"},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"dataSource\":{},\"enabled\":true,\"existingClaim\":\"\",\"labels\":{},\"mountPath\":\"/bitnami/postgresql\",\"selector\":{},\"size\":\"40Gi\",\"storageClass\":\"\",\"subPath\":\"\"},\"pgHbaConfiguration\":\"\",\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"resources\":{\"limits\":{\"cpu\":\"1500m\",\"memory\":\"2048Mi\"},\"requests\":{\"cpu\":\"750m\",\"memory\":\"750Mi\"}},\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"externalTrafficPolicy\":\"Cluster\",\"extraPorts\":[],\"headless\":{\"annotations\":{}},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"postgresql\":\"\"},\"ports\":{\"postgresql\":5432},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"sidecars\":[],\"standby\":{\"enabled\":false,\"primaryHost\":\"\",\"primaryPort\":\"\"},\"startupProbe\":{\"enabled\":false,\"failureThreshold\":15,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"terminationGracePeriodSeconds\":\"\",\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategy\":{\"rollingUpdate\":{},\"type\":\"RollingUpdate\"}},\"psp\":{\"create\":false},\"rbac\":{\"create\":false,\"rules\":[]},\"readReplicas\":{\"affinity\":{},\"annotations\":{},\"args\":[],\"command\":[],\"containerSecurityContext\":{\"enabled\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"extendedConfiguration\":\"\",\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraPodSpec\":{},\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"hostIPC\":false,\"hostNetwork\":false,\"initContainers\":[],\"labels\":{},\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"name\":\"read\",\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"dataSource\":{},\"enabled\":true,\"existingClaim\":\"\",\"labels\":{},\"mountPath\":\"/bitnami/postgresql\",\"selector\":{},\"size\":\"8Gi\",\"storageClass\":\"\",\"subPath\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"replicaCount\":1,\"resources\":{\"limits\":{},\"requests\":{\"cpu\":\"250m\",\"memory\":\"256Mi\"}},\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"externalTrafficPolicy\":\"Cluster\",\"extraPorts\":[],\"headless\":{\"annotations\":{}},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"postgresql\":\"\"},\"ports\":{\"postgresql\":5432},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"sidecars\":[],\"startupProbe\":{\"enabled\":false,\"failureThreshold\":15,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"terminationGracePeriodSeconds\":\"\",\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategy\":{\"rollingUpdate\":{},\"type\":\"RollingUpdate\"}},\"replication\":{\"applicationName\":\"bifrost\",\"numSynchronousReplicas\":2,\"synchronousCommit\":\"on\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":false,\"name\":\"\"},\"serviceBindings\":{\"enabled\":false},\"shmVolume\":{\"enabled\":true,\"sizeLimit\":\"\"},\"tls\":{\"autoGenerated\":false,\"certCAFilename\":\"\",\"certFilename\":\"\",\"certKeyFilename\":\"\",\"certificatesSecret\":\"\",\"crlFilename\":\"\",\"enabled\":false,\"preferServerCiphers\":true},\"volumePermissions\":{\"containerSecurityContext\":{\"runAsUser\":0},\"enabled\":false,\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/bitnami-shell\",\"tag\":\"11-debian-11-r120\"},\"resources\":{\"limits\":{},\"requests\":{}}}}",
                "version": "15.5.4"
              }
            ],
            "name": "postgres-airflow",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://charts.bitnami.com/bitnami",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "## @section Global parameters\n## Please, note that this will override the parameters, including dependencies, configured to use the global value\n##\nglobal:\n  ## @param global.imageRegistry Global Docker image registry\n  ##\n  imageRegistry: \"\"\n  ## @param global.imagePullSecrets Global Docker registry secret names as an array\n  ## e.g.\n  ## imagePullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  imagePullSecrets: []\n  ## @param global.storageClass Global StorageClass for Persistent Volume(s)\n  ##\n  storageClass: \"\"\n  postgresql:\n    ## @param global.postgresql.auth.postgresPassword Password for the \"postgres\" admin user (overrides `auth.postgresPassword`)\n    ## @param global.postgresql.auth.username Name for a custom user to create (overrides `auth.username`)\n    ## @param global.postgresql.auth.password Password for the custom user to create (overrides `auth.password`)\n    ## @param global.postgresql.auth.database Name for a custom database to create (overrides `auth.database`)\n    ## @param global.postgresql.auth.existingSecret Name of existing secret to use for PostgreSQL credentials (overrides `auth.existingSecret`).\n    ## @param global.postgresql.auth.secretKeys.adminPasswordKey Name of key in existing secret to use for PostgreSQL credentials (overrides `auth.secretKeys.adminPasswordKey`). Only used when `global.postgresql.auth.existingSecret` is set.\n    ## @param global.postgresql.auth.secretKeys.userPasswordKey Name of key in existing secret to use for PostgreSQL credentials (overrides `auth.secretKeys.userPasswordKey`). Only used when `global.postgresql.auth.existingSecret` is set.\n    ## @param global.postgresql.auth.secretKeys.replicationPasswordKey Name of key in existing secret to use for PostgreSQL credentials (overrides `auth.secretKeys.replicationPasswordKey`). Only used when `global.postgresql.auth.existingSecret` is set.\n    ##\n    auth:\n      postgresPassword: \"Maniac321.\"\n      username: \"hdfs\"\n      password: \"Maniac321.\"\n      database: \"hdfs\"\n      existingSecret: \"\"\n      secretKeys:\n        adminPasswordKey: \"\"\n        userPasswordKey: \"\"\n        replicationPasswordKey: \"\"\n    ## @param global.postgresql.service.ports.postgresql PostgreSQL service port (overrides `service.ports.postgresql`)\n    ##\n    service:\n      ports:\n        postgresql: \"\"\n\n## @section Common parameters\n##\n\n## @param kubeVersion Override Kubernetes version\n##\nkubeVersion: \"\"\n## @param nameOverride String to partially override common.names.fullname template (will maintain the release name)\n##\nnameOverride: \"\"\n## @param fullnameOverride String to fully override common.names.fullname template\n##\nfullnameOverride: \"\"\n## @param clusterDomain Kubernetes Cluster Domain\n##\nclusterDomain: cluster.local\n## @param extraDeploy Array of extra objects to deploy with the release (evaluated as a template)\n##\nextraDeploy: []\n## @param commonLabels Add labels to all the deployed resources\n##\ncommonLabels: {}\n## @param commonAnnotations Add annotations to all the deployed resources\n##\ncommonAnnotations: {}\n## Enable diagnostic mode in the statefulset\n##\ndiagnosticMode:\n  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)\n  ##\n  enabled: false\n  ## @param diagnosticMode.command Command to override all containers in the statefulset\n  ##\n  command:\n  - sleep\n  ## @param diagnosticMode.args Args to override all containers in the statefulset\n  ##\n  args:\n  - infinity\n\n## @section PostgreSQL common parameters\n##\n\n## Bitnami PostgreSQL image version\n## ref: https://hub.docker.com/r/bitnami/postgresql/tags/\n## @param image.registry PostgreSQL image registry\n## @param image.repository PostgreSQL image repository\n## @param image.tag PostgreSQL image tag (immutable tags are recommended)\n## @param image.digest PostgreSQL image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n## @param image.pullPolicy PostgreSQL image pull policy\n## @param image.pullSecrets Specify image pull secrets\n## @param image.debug Specify if debug values should be set\n##\nimage:\n  registry: docker.io\n  repository: bitnami/postgresql\n  tag: 15.3.0-debian-11-r7\n  digest: \"\"\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ## Example:\n  ## pullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  pullSecrets: []\n  ## Set to true if you would like to see extra information on logs\n  ##\n  debug: false\n## Authentication parameters\n## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#setting-the-root-password-on-first-run\n## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#creating-a-database-on-first-run\n## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#creating-a-database-user-on-first-run\n##\nauth:\n  ## @param auth.enablePostgresUser Assign a password to the \"postgres\" admin user. Otherwise, remote access will be blocked for this user\n  ##\n  enablePostgresUser: true\n  ## @param auth.postgresPassword Password for the \"postgres\" admin user. Ignored if `auth.existingSecret` is provided\n  ##\n  postgresPassword: \"\"\n  ## @param auth.username Name for a custom user to create\n  ##\n  username: \"hdfs\"\n  ## @param auth.password Password for the custom user to create. Ignored if `auth.existingSecret` is provided\n  ##\n  password: \"Maniac321.\"\n  ## @param auth.database Name for a custom database to create\n  ##\n  database: \"hdfs\"\n  ## @param auth.replicationUsername Name of the replication user\n  ##\n  replicationUsername: repl_user\n  ## @param auth.replicationPassword Password for the replication user. Ignored if `auth.existingSecret` is provided\n  ##\n  replicationPassword: \"\"\n  ## @param auth.existingSecret Name of existing secret to use for PostgreSQL credentials. `auth.postgresPassword`, `auth.password`, and `auth.replicationPassword` will be ignored and picked up from this secret. The secret might also contains the key `ldap-password` if LDAP is enabled. `ldap.bind_password` will be ignored and picked from this secret in this case.\n  ##\n  existingSecret: \"\"\n  ## @param auth.secretKeys.adminPasswordKey Name of key in existing secret to use for PostgreSQL credentials. Only used when `auth.existingSecret` is set.\n  ## @param auth.secretKeys.userPasswordKey Name of key in existing secret to use for PostgreSQL credentials. Only used when `auth.existingSecret` is set.\n  ## @param auth.secretKeys.replicationPasswordKey Name of key in existing secret to use for PostgreSQL credentials. Only used when `auth.existingSecret` is set.\n  ##\n  secretKeys:\n    adminPasswordKey: postgres-password\n    userPasswordKey: password\n    replicationPasswordKey: replication-password\n  ## @param auth.usePasswordFiles Mount credentials as a files instead of using an environment variable\n  ##\n  usePasswordFiles: false\n## @param architecture PostgreSQL architecture (`standalone` or `replication`)\n##\narchitecture: standalone\n## Replication configuration\n## Ignored if `architecture` is `standalone`\n##\nreplication:\n  ## @param replication.synchronousCommit Set synchronous commit mode. Allowed values: `on`, `remote_apply`, `remote_write`, `local` and `off`\n  ## @param replication.numSynchronousReplicas Number of replicas that will have synchronous replication. Note: Cannot be greater than `readReplicas.replicaCount`.\n  ## ref: https://www.postgresql.org/docs/current/runtime-config-wal.html#GUC-SYNCHRONOUS-COMMIT\n  ##\n  synchronousCommit: \"on\"\n  numSynchronousReplicas: 2\n  ## @param replication.applicationName Cluster application name. Useful for advanced replication settings\n  ##\n  applicationName: bifrost\n## @param containerPorts.postgresql PostgreSQL container port\n##\ncontainerPorts:\n  postgresql: 5432\n## Audit settings\n## https://github.com/bitnami/containers/tree/main/bitnami/postgresql#auditing\n## @param audit.logHostname Log client hostnames\n## @param audit.logConnections Add client log-in operations to the log file\n## @param audit.logDisconnections Add client log-outs operations to the log file\n## @param audit.pgAuditLog Add operations to log using the pgAudit extension\n## @param audit.pgAuditLogCatalog Log catalog using pgAudit\n## @param audit.clientMinMessages Message log level to share with the user\n## @param audit.logLinePrefix Template for log line prefix (default if not set)\n## @param audit.logTimezone Timezone for the log timestamps\n##\naudit:\n  logHostname: false\n  logConnections: false\n  logDisconnections: false\n  pgAuditLog: \"\"\n  pgAuditLogCatalog: \"off\"\n  clientMinMessages: error\n  logLinePrefix: \"\"\n  logTimezone: \"\"\n## LDAP configuration\n## @param ldap.enabled Enable LDAP support\n## DEPRECATED ldap.url It will removed in a future, please use 'ldap.uri' instead\n## @param ldap.server IP address or name of the LDAP server.\n## @param ldap.port Port number on the LDAP server to connect to\n## @param ldap.prefix String to prepend to the user name when forming the DN to bind\n## @param ldap.suffix String to append to the user name when forming the DN to bind\n## DEPRECATED ldap.baseDN It will removed in a future, please use 'ldap.basedn' instead\n## DEPRECATED ldap.bindDN It will removed in a future, please use 'ldap.binddn' instead\n## DEPRECATED ldap.bind_password It will removed in a future, please use 'ldap.bindpw' instead\n## @param ldap.basedn Root DN to begin the search for the user in\n## @param ldap.binddn DN of user to bind to LDAP\n## @param ldap.bindpw Password for the user to bind to LDAP\n## DEPRECATED ldap.search_attr It will removed in a future, please use 'ldap.searchAttribute' instead\n## DEPRECATED ldap.search_filter It will removed in a future, please use 'ldap.searchFilter' instead\n## @param ldap.searchAttribute Attribute to match against the user name in the search\n## @param ldap.searchFilter The search filter to use when doing search+bind authentication\n## @param ldap.scheme Set to `ldaps` to use LDAPS\n## DEPRECATED ldap.tls as string is deprecated，please use 'ldap.tls.enabled' instead\n## @param ldap.tls.enabled Se to true to enable TLS encryption\n##\nldap:\n  enabled: false\n  server: \"\"\n  port: \"\"\n  prefix: \"\"\n  suffix: \"\"\n  basedn: \"\"\n  binddn: \"\"\n  bindpw: \"\"\n  searchAttribute: \"\"\n  searchFilter: \"\"\n  scheme: \"\"\n  tls:\n    enabled: false\n  ## @param ldap.uri LDAP URL beginning in the form `ldap[s]://host[:port]/basedn`. If provided, all the other LDAP parameters will be ignored.\n  ## Ref: https://www.postgresql.org/docs/current/auth-ldap.html\n  ##\n  uri: \"\"\n## @param postgresqlDataDir PostgreSQL data dir folder\n##\npostgresqlDataDir: /bitnami/postgresql/data\n## @param postgresqlSharedPreloadLibraries Shared preload libraries (comma-separated list)\n##\npostgresqlSharedPreloadLibraries: \"pgaudit\"\n## Start PostgreSQL pod(s) without limitations on shm memory.\n## By default docker and containerd (and possibly other container runtimes) limit `/dev/shm` to `64M`\n## ref: https://github.com/docker-library/postgres/issues/416\n## ref: https://github.com/containerd/containerd/issues/3654\n##\nshmVolume:\n  ## @param shmVolume.enabled Enable emptyDir volume for /dev/shm for PostgreSQL pod(s)\n  ##\n  enabled: true\n  ## @param shmVolume.sizeLimit Set this to enable a size limit on the shm tmpfs\n  ## Note: the size of the tmpfs counts against container's memory limit\n  ## e.g:\n  ## sizeLimit: 1Gi\n  ##\n  sizeLimit: \"\"\n## TLS configuration\n##\ntls:\n  ## @param tls.enabled Enable TLS traffic support\n  ##\n  enabled: false\n  ## @param tls.autoGenerated Generate automatically self-signed TLS certificates\n  ##\n  autoGenerated: false\n  ## @param tls.preferServerCiphers Whether to use the server's TLS cipher preferences rather than the client's\n  ##\n  preferServerCiphers: true\n  ## @param tls.certificatesSecret Name of an existing secret that contains the certificates\n  ##\n  certificatesSecret: \"\"\n  ## @param tls.certFilename Certificate filename\n  ##\n  certFilename: \"\"\n  ## @param tls.certKeyFilename Certificate key filename\n  ##\n  certKeyFilename: \"\"\n  ## @param tls.certCAFilename CA Certificate filename\n  ## If provided, PostgreSQL will authenticate TLS/SSL clients by requesting them a certificate\n  ## ref: https://www.postgresql.org/docs/9.6/auth-methods.html\n  ##\n  certCAFilename: \"\"\n  ## @param tls.crlFilename File containing a Certificate Revocation List\n  ##\n  crlFilename: \"\"\n\n## @section PostgreSQL Primary parameters\n##\nprimary:\n  ## @param primary.name Name of the primary database (eg primary, master, leader, ...)\n  ##\n  name: primary\n  ## @param primary.configuration PostgreSQL Primary main configuration to be injected as ConfigMap\n  ## ref: https://www.postgresql.org/docs/current/static/runtime-config.html\n  ##\n  configuration: \"\"\n  ## @param primary.pgHbaConfiguration PostgreSQL Primary client authentication configuration\n  ## ref: https://www.postgresql.org/docs/current/static/auth-pg-hba-conf.html\n  ## e.g:#\n  ## pgHbaConfiguration: |-\n  ##   local all all trust\n  ##   host all all localhost trust\n  ##   host mydatabase mysuser 192.168.0.0/24 md5\n  ##\n  pgHbaConfiguration: \"\"\n  ## @param primary.existingConfigmap Name of an existing ConfigMap with PostgreSQL Primary configuration\n  ## NOTE: `primary.configuration` and `primary.pgHbaConfiguration` will be ignored\n  ##\n  existingConfigmap: \"\"\n  ## @param primary.extendedConfiguration Extended PostgreSQL Primary configuration (appended to main or default configuration)\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#allow-settings-to-be-loaded-from-files-other-than-the-default-postgresqlconf\n  ##\n  extendedConfiguration: \"\"\n  ## @param primary.existingExtendedConfigmap Name of an existing ConfigMap with PostgreSQL Primary extended configuration\n  ## NOTE: `primary.extendedConfiguration` will be ignored\n  ##\n  existingExtendedConfigmap: \"\"\n  ## Initdb configuration\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#specifying-initdb-arguments\n  ##\n  initdb:\n    ## @param primary.initdb.args PostgreSQL initdb extra arguments\n    ##\n    args: \"\"\n    ## @param primary.initdb.postgresqlWalDir Specify a custom location for the PostgreSQL transaction log\n    ##\n    postgresqlWalDir: \"\"\n    ## @param primary.initdb.scripts Dictionary of initdb scripts\n    ## Specify dictionary of scripts to be run at first boot\n    ## e.g:\n    ## scripts:\n    ##   my_init_script.sh: |\n    ##      #!/bin/sh\n    ##      echo \"Do something.\"\n    ##\n    scripts: {}\n    ## @param primary.initdb.scriptsConfigMap ConfigMap with scripts to be run at first boot\n    ## NOTE: This will override `primary.initdb.scripts`\n    ##\n    scriptsConfigMap: \"\"\n    ## @param primary.initdb.scriptsSecret Secret with scripts to be run at first boot (in case it contains sensitive information)\n    ## NOTE: This can work along `primary.initdb.scripts` or `primary.initdb.scriptsConfigMap`\n    ##\n    scriptsSecret: \"\"\n    ## @param primary.initdb.user Specify the PostgreSQL username to execute the initdb scripts\n    ##\n    user: \"\"\n    ## @param primary.initdb.password Specify the PostgreSQL password to execute the initdb scripts\n    ##\n    password: \"\"\n  ## Configure current cluster's primary server to be the standby server in other cluster.\n  ## This will allow cross cluster replication and provide cross cluster high availability.\n  ## You will need to configure pgHbaConfiguration if you want to enable this feature with local cluster replication enabled.\n  ## @param primary.standby.enabled Whether to enable current cluster's primary as standby server of another cluster or not\n  ## @param primary.standby.primaryHost The Host of replication primary in the other cluster\n  ## @param primary.standby.primaryPort The Port of replication primary in the other cluster\n  ##\n  standby:\n    enabled: false\n    primaryHost: \"\"\n    primaryPort: \"\"\n  ## @param primary.extraEnvVars Array with extra environment variables to add to PostgreSQL Primary nodes\n  ## e.g:\n  extraEnvVars:\n  - name: POSTGRESQL_MAX_CONNECTIONS\n    value: \"750\"\n  ##\n  #extraEnvVars: []\n  ## @param primary.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for PostgreSQL Primary nodes\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param primary.extraEnvVarsSecret Name of existing Secret containing extra env vars for PostgreSQL Primary nodes\n  ##\n  extraEnvVarsSecret: \"\"\n  ## @param primary.command Override default container command (useful when using custom images)\n  ##\n  command: []\n  ## @param primary.args Override default container args (useful when using custom images)\n  ##\n  args: []\n  ## Configure extra options for PostgreSQL Primary containers' liveness, readiness and startup probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes\n  ## @param primary.livenessProbe.enabled Enable livenessProbe on PostgreSQL Primary containers\n  ## @param primary.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param primary.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param primary.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param primary.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param primary.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  ## @param primary.readinessProbe.enabled Enable readinessProbe on PostgreSQL Primary containers\n  ## @param primary.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param primary.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param primary.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param primary.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param primary.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  ## @param primary.startupProbe.enabled Enable startupProbe on PostgreSQL Primary containers\n  ## @param primary.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param primary.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param primary.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param primary.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param primary.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: false\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 15\n    successThreshold: 1\n  ## @param primary.customLivenessProbe Custom livenessProbe that overrides the default one\n  ##\n  customLivenessProbe: {}\n  ## @param primary.customReadinessProbe Custom readinessProbe that overrides the default one\n  ##\n  customReadinessProbe: {}\n  ## @param primary.customStartupProbe Custom startupProbe that overrides the default one\n  ##\n  customStartupProbe: {}\n  ## @param primary.lifecycleHooks for the PostgreSQL Primary container to automate configuration before or after startup\n  ##\n  lifecycleHooks: {}\n  ## PostgreSQL Primary resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## @param primary.resources.limits The resources limits for the PostgreSQL Primary containers\n  ## @param primary.resources.requests.memory The requested memory for the PostgreSQL Primary containers\n  ## @param primary.resources.requests.cpu The requested cpu for the PostgreSQL Primary containers\n  ##\n  resources:\n    limits:\n      memory: 2048Mi\n      cpu: 1500m\n    requests:\n      memory: 750Mi\n      cpu: 750m\n  ## Pod Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n  ## @param primary.podSecurityContext.enabled Enable security context\n  ## @param primary.podSecurityContext.fsGroup Group ID for the pod\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## Container Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n  ## @param primary.containerSecurityContext.enabled Enable container security context\n  ## @param primary.containerSecurityContext.runAsUser User ID for the container\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n  ## @param primary.hostAliases PostgreSQL primary pods host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## @param primary.hostNetwork Specify if host network should be enabled for PostgreSQL pod (postgresql primary)\n  ##\n  hostNetwork: false\n  ## @param primary.hostIPC Specify if host IPC should be enabled for PostgreSQL pod (postgresql primary)\n  ##\n  hostIPC: false\n  ## @param primary.labels Map of labels to add to the statefulset (postgresql primary)\n  ##\n  labels: {}\n  ## @param primary.annotations Annotations for PostgreSQL primary pods\n  ##\n  annotations: {}\n  ## @param primary.podLabels Map of labels to add to the pods (postgresql primary)\n  ##\n  podLabels: {}\n  ## @param primary.podAnnotations Map of annotations to add to the pods (postgresql primary)\n  ##\n  podAnnotations: {}\n  ## @param primary.podAffinityPreset PostgreSQL primary pod affinity preset. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAffinityPreset: \"\"\n  ## @param primary.podAntiAffinityPreset PostgreSQL primary pod anti-affinity preset. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAntiAffinityPreset: soft\n  ## PostgreSQL Primary node affinity preset\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ##\n  nodeAffinityPreset:\n    ## @param primary.nodeAffinityPreset.type PostgreSQL primary node affinity preset type. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n    ##\n    type: \"\"\n    ## @param primary.nodeAffinityPreset.key PostgreSQL primary node label key to match Ignored if `primary.affinity` is set.\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## @param primary.nodeAffinityPreset.values PostgreSQL primary node label values to match. Ignored if `primary.affinity` is set.\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param primary.affinity Affinity for PostgreSQL primary pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ## Note: primary.podAffinityPreset, primary.podAntiAffinityPreset, and primary.nodeAffinityPreset will be ignored when it's set\n  ##\n  affinity: {}\n  ## @param primary.nodeSelector Node labels for PostgreSQL primary pods assignment\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector:\n    airflow: \"nodeok\"\n\n  ## @param primary.tolerations Tolerations for PostgreSQL primary pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param primary.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods\n  ##\n  topologySpreadConstraints: []\n  ## @param primary.priorityClassName Priority Class to use for each pod (postgresql primary)\n  ##\n  priorityClassName: \"\"\n  ## @param primary.schedulerName Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  schedulerName: \"\"\n  ## @param primary.terminationGracePeriodSeconds Seconds PostgreSQL primary pod needs to terminate gracefully\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods\n  ##\n  terminationGracePeriodSeconds: \"\"\n  ## @param primary.updateStrategy.type PostgreSQL Primary statefulset strategy type\n  ## @param primary.updateStrategy.rollingUpdate PostgreSQL Primary statefulset rolling update configuration parameters\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n  ##\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate: {}\n  ## @param primary.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the PostgreSQL Primary container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param primary.extraVolumes Optionally specify extra list of additional volumes for the PostgreSQL Primary pod(s)\n  ##\n  extraVolumes: []\n  ## @param primary.sidecars Add additional sidecar containers to the PostgreSQL Primary pod(s)\n  ## For example:\n  ## sidecars:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  sidecars: []\n  ## @param primary.initContainers Add additional init containers to the PostgreSQL Primary pod(s)\n  ## Example\n  ##\n  ## initContainers:\n  ##   - name: do-something\n  ##     image: busybox\n  ##     command: ['do', 'something']\n  ##\n  initContainers: []\n  ## @param primary.extraPodSpec Optionally specify extra PodSpec for the PostgreSQL Primary pod(s)\n  ##\n  extraPodSpec: {}\n  ## PostgreSQL Primary service configuration\n  ##\n  service:\n    ## @param primary.service.type Kubernetes Service type\n    ##\n    type: ClusterIP\n    ## @param primary.service.ports.postgresql PostgreSQL service port\n    ##\n    ports:\n      postgresql: 5432\n    ## Node ports to expose\n    ## NOTE: choose port between \u003c30000-32767\u003e\n    ## @param primary.service.nodePorts.postgresql Node port for PostgreSQL\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n    ##\n    nodePorts:\n      postgresql: \"\"\n    ## @param primary.service.clusterIP Static clusterIP or None for headless services\n    ## e.g:\n    ## clusterIP: None\n    ##\n    clusterIP: \"\"\n    ## @param primary.service.annotations Annotations for PostgreSQL primary service\n    ##\n    annotations: {}\n    ## @param primary.service.loadBalancerIP Load balancer IP if service type is `LoadBalancer`\n    ## Set the LoadBalancer service type to internal only\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n    ##\n    loadBalancerIP: \"\"\n    ## @param primary.service.externalTrafficPolicy Enable client source IP preservation\n    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n    ##\n    externalTrafficPolicy: Cluster\n    ## @param primary.service.loadBalancerSourceRanges Addresses that are allowed when service is LoadBalancer\n    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n    ##\n    ## loadBalancerSourceRanges:\n    ## - 10.10.10.0/24\n    ##\n    loadBalancerSourceRanges: []\n    ## @param primary.service.extraPorts Extra ports to expose in the PostgreSQL primary service\n    ##\n    extraPorts: []\n    ## @param primary.service.sessionAffinity Session Affinity for Kubernetes service, can be \"None\" or \"ClientIP\"\n    ## If \"ClientIP\", consecutive client requests will be directed to the same Pod\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies\n    ##\n    sessionAffinity: None\n    ## @param primary.service.sessionAffinityConfig Additional settings for the sessionAffinity\n    ## sessionAffinityConfig:\n    ##   clientIP:\n    ##     timeoutSeconds: 300\n    ##\n    sessionAffinityConfig: {}\n    ## Headless service properties\n    ##\n    headless:\n      ## @param primary.service.headless.annotations Additional custom annotations for headless PostgreSQL primary service\n      ##\n      annotations: {}\n  ## PostgreSQL Primary persistence configuration\n  ##\n  persistence:\n    ## @param primary.persistence.enabled Enable PostgreSQL Primary data persistence using PVC\n    ##\n    enabled: true\n    ## @param primary.persistence.existingClaim Name of an existing PVC to use\n    ##\n    existingClaim: \"\"\n    ## @param primary.persistence.mountPath The path the volume will be mounted at\n    ## Note: useful when using custom PostgreSQL images\n    ##\n    mountPath: /bitnami/postgresql\n    ## @param primary.persistence.subPath The subdirectory of the volume to mount to\n    ## Useful in dev environments and one PV for multiple services\n    ##\n    subPath: \"\"\n    ## @param primary.persistence.storageClass PVC Storage Class for PostgreSQL Primary data volume\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    storageClass: \"\"\n    ## @param primary.persistence.accessModes PVC Access Mode for PostgreSQL volume\n    ##\n    accessModes:\n    - ReadWriteOnce\n    ## @param primary.persistence.size PVC Storage Request for PostgreSQL volume\n    ##\n    size: 40Gi\n    ## @param primary.persistence.annotations Annotations for the PVC\n    ##\n    annotations: {}\n    ## @param primary.persistence.labels Labels for the PVC\n    ##\n    labels: {}\n    ## @param primary.persistence.selector Selector to match an existing Persistent Volume (this value is evaluated as a template)\n    ## selector:\n    ##   matchLabels:\n    ##     app: my-app\n    ##\n    selector: {}\n    ## @param primary.persistence.dataSource Custom PVC data source\n    ##\n    dataSource: {}\n\n## @section PostgreSQL read only replica parameters (only used when `architecture` is set to `replication`)\n##\nreadReplicas:\n  ## @param readReplicas.name Name of the read replicas database (eg secondary, slave, ...)\n  ##\n  name: read\n  ## @param readReplicas.replicaCount Number of PostgreSQL read only replicas\n  ##\n  replicaCount: 1\n  ## @param readReplicas.extendedConfiguration Extended PostgreSQL read only replicas configuration (appended to main or default configuration)\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#allow-settings-to-be-loaded-from-files-other-than-the-default-postgresqlconf\n  ##\n  extendedConfiguration: \"\"\n  ## @param readReplicas.extraEnvVars Array with extra environment variables to add to PostgreSQL read only nodes\n  ## e.g:\n  ## extraEnvVars:\n  ##   - name: FOO\n  ##     value: \"bar\"\n  ##\n  extraEnvVars: []\n  ## @param readReplicas.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for PostgreSQL read only nodes\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param readReplicas.extraEnvVarsSecret Name of existing Secret containing extra env vars for PostgreSQL read only nodes\n  ##\n  extraEnvVarsSecret: \"\"\n  ## @param readReplicas.command Override default container command (useful when using custom images)\n  ##\n  command: []\n  ## @param readReplicas.args Override default container args (useful when using custom images)\n  ##\n  args: []\n  ## Configure extra options for PostgreSQL read only containers' liveness, readiness and startup probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes\n  ## @param readReplicas.livenessProbe.enabled Enable livenessProbe on PostgreSQL read only containers\n  ## @param readReplicas.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param readReplicas.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param readReplicas.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param readReplicas.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param readReplicas.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  ## @param readReplicas.readinessProbe.enabled Enable readinessProbe on PostgreSQL read only containers\n  ## @param readReplicas.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param readReplicas.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param readReplicas.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param readReplicas.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param readReplicas.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  ## @param readReplicas.startupProbe.enabled Enable startupProbe on PostgreSQL read only containers\n  ## @param readReplicas.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param readReplicas.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param readReplicas.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param readReplicas.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param readReplicas.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: false\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 15\n    successThreshold: 1\n  ## @param readReplicas.customLivenessProbe Custom livenessProbe that overrides the default one\n  ##\n  customLivenessProbe: {}\n  ## @param readReplicas.customReadinessProbe Custom readinessProbe that overrides the default one\n  ##\n  customReadinessProbe: {}\n  ## @param readReplicas.customStartupProbe Custom startupProbe that overrides the default one\n  ##\n  customStartupProbe: {}\n  ## @param readReplicas.lifecycleHooks for the PostgreSQL read only container to automate configuration before or after startup\n  ##\n  lifecycleHooks: {}\n  ## PostgreSQL read only resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## @param readReplicas.resources.limits The resources limits for the PostgreSQL read only containers\n  ## @param readReplicas.resources.requests.memory The requested memory for the PostgreSQL read only containers\n  ## @param readReplicas.resources.requests.cpu The requested cpu for the PostgreSQL read only containers\n  ##\n  resources:\n    limits: {}\n    requests:\n      memory: 256Mi\n      cpu: 250m\n  ## Pod Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n  ## @param readReplicas.podSecurityContext.enabled Enable security context\n  ## @param readReplicas.podSecurityContext.fsGroup Group ID for the pod\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## Container Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n  ## @param readReplicas.containerSecurityContext.enabled Enable container security context\n  ## @param readReplicas.containerSecurityContext.runAsUser User ID for the container\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n  ## @param readReplicas.hostAliases PostgreSQL read only pods host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## @param readReplicas.hostNetwork Specify if host network should be enabled for PostgreSQL pod (PostgreSQL read only)\n  ##\n  hostNetwork: false\n  ## @param readReplicas.hostIPC Specify if host IPC should be enabled for PostgreSQL pod (postgresql primary)\n  ##\n  hostIPC: false\n  ## @param readReplicas.labels Map of labels to add to the statefulset (PostgreSQL read only)\n  ##\n  labels: {}\n  ## @param readReplicas.annotations Annotations for PostgreSQL read only pods\n  ##\n  annotations: {}\n  ## @param readReplicas.podLabels Map of labels to add to the pods (PostgreSQL read only)\n  ##\n  podLabels: {}\n  ## @param readReplicas.podAnnotations Map of annotations to add to the pods (PostgreSQL read only)\n  ##\n  podAnnotations: {}\n  ## @param readReplicas.podAffinityPreset PostgreSQL read only pod affinity preset. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAffinityPreset: \"\"\n  ## @param readReplicas.podAntiAffinityPreset PostgreSQL read only pod anti-affinity preset. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAntiAffinityPreset: soft\n  ## PostgreSQL read only node affinity preset\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ##\n  nodeAffinityPreset:\n    ## @param readReplicas.nodeAffinityPreset.type PostgreSQL read only node affinity preset type. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n    ##\n    type: \"\"\n    ## @param readReplicas.nodeAffinityPreset.key PostgreSQL read only node label key to match Ignored if `primary.affinity` is set.\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## @param readReplicas.nodeAffinityPreset.values PostgreSQL read only node label values to match. Ignored if `primary.affinity` is set.\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param readReplicas.affinity Affinity for PostgreSQL read only pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ## Note: primary.podAffinityPreset, primary.podAntiAffinityPreset, and primary.nodeAffinityPreset will be ignored when it's set\n  ##\n  affinity: {}\n  ## @param readReplicas.nodeSelector Node labels for PostgreSQL read only pods assignment\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param readReplicas.tolerations Tolerations for PostgreSQL read only pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param readReplicas.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods\n  ##\n  topologySpreadConstraints: []\n  ## @param readReplicas.priorityClassName Priority Class to use for each pod (PostgreSQL read only)\n  ##\n  priorityClassName: \"\"\n  ## @param readReplicas.schedulerName Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  schedulerName: \"\"\n  ## @param readReplicas.terminationGracePeriodSeconds Seconds PostgreSQL read only pod needs to terminate gracefully\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods\n  ##\n  terminationGracePeriodSeconds: \"\"\n  ## @param readReplicas.updateStrategy.type PostgreSQL read only statefulset strategy type\n  ## @param readReplicas.updateStrategy.rollingUpdate PostgreSQL read only statefulset rolling update configuration parameters\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n  ##\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate: {}\n  ## @param readReplicas.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the PostgreSQL read only container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param readReplicas.extraVolumes Optionally specify extra list of additional volumes for the PostgreSQL read only pod(s)\n  ##\n  extraVolumes: []\n  ## @param readReplicas.sidecars Add additional sidecar containers to the PostgreSQL read only pod(s)\n  ## For example:\n  ## sidecars:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  sidecars: []\n  ## @param readReplicas.initContainers Add additional init containers to the PostgreSQL read only pod(s)\n  ## Example\n  ##\n  ## initContainers:\n  ##   - name: do-something\n  ##     image: busybox\n  ##     command: ['do', 'something']\n  ##\n  initContainers: []\n  ## @param readReplicas.extraPodSpec Optionally specify extra PodSpec for the PostgreSQL read only pod(s)\n  ##\n  extraPodSpec: {}\n  ## PostgreSQL read only service configuration\n  ##\n  service:\n    ## @param readReplicas.service.type Kubernetes Service type\n    ##\n    type: ClusterIP\n    ## @param readReplicas.service.ports.postgresql PostgreSQL service port\n    ##\n    ports:\n      postgresql: 5432\n    ## Node ports to expose\n    ## NOTE: choose port between \u003c30000-32767\u003e\n    ## @param readReplicas.service.nodePorts.postgresql Node port for PostgreSQL\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n    ##\n    nodePorts:\n      postgresql: \"\"\n    ## @param readReplicas.service.clusterIP Static clusterIP or None for headless services\n    ## e.g:\n    ## clusterIP: None\n    ##\n    clusterIP: \"\"\n    ## @param readReplicas.service.annotations Annotations for PostgreSQL read only service\n    ##\n    annotations: {}\n    ## @param readReplicas.service.loadBalancerIP Load balancer IP if service type is `LoadBalancer`\n    ## Set the LoadBalancer service type to internal only\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n    ##\n    loadBalancerIP: \"\"\n    ## @param readReplicas.service.externalTrafficPolicy Enable client source IP preservation\n    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n    ##\n    externalTrafficPolicy: Cluster\n    ## @param readReplicas.service.loadBalancerSourceRanges Addresses that are allowed when service is LoadBalancer\n    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n    ##\n    ## loadBalancerSourceRanges:\n    ## - 10.10.10.0/24\n    ##\n    loadBalancerSourceRanges: []\n    ## @param readReplicas.service.extraPorts Extra ports to expose in the PostgreSQL read only service\n    ##\n    extraPorts: []\n    ## @param readReplicas.service.sessionAffinity Session Affinity for Kubernetes service, can be \"None\" or \"ClientIP\"\n    ## If \"ClientIP\", consecutive client requests will be directed to the same Pod\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies\n    ##\n    sessionAffinity: None\n    ## @param readReplicas.service.sessionAffinityConfig Additional settings for the sessionAffinity\n    ## sessionAffinityConfig:\n    ##   clientIP:\n    ##     timeoutSeconds: 300\n    ##\n    sessionAffinityConfig: {}\n    ## Headless service properties\n    ##\n    headless:\n      ## @param readReplicas.service.headless.annotations Additional custom annotations for headless PostgreSQL read only service\n      ##\n      annotations: {}\n  ## PostgreSQL read only persistence configuration\n  ##\n  persistence:\n    ## @param readReplicas.persistence.enabled Enable PostgreSQL read only data persistence using PVC\n    ##\n    enabled: true\n    ## @param readReplicas.persistence.existingClaim Name of an existing PVC to use\n    ##\n    existingClaim: \"\"\n    ## @param readReplicas.persistence.mountPath The path the volume will be mounted at\n    ## Note: useful when using custom PostgreSQL images\n    ##\n    mountPath: /bitnami/postgresql\n    ## @param readReplicas.persistence.subPath The subdirectory of the volume to mount to\n    ## Useful in dev environments and one PV for multiple services\n    ##\n    subPath: \"\"\n    ## @param readReplicas.persistence.storageClass PVC Storage Class for PostgreSQL read only data volume\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    storageClass: \"\"\n    ## @param readReplicas.persistence.accessModes PVC Access Mode for PostgreSQL volume\n    ##\n    accessModes:\n    - ReadWriteOnce\n    ## @param readReplicas.persistence.size PVC Storage Request for PostgreSQL volume\n    ##\n    size: 8Gi\n    ## @param readReplicas.persistence.annotations Annotations for the PVC\n    ##\n    annotations: {}\n    ## @param readReplicas.persistence.labels Labels for the PVC\n    ##\n    labels: {}\n    ## @param readReplicas.persistence.selector Selector to match an existing Persistent Volume (this value is evaluated as a template)\n    ## selector:\n    ##   matchLabels:\n    ##     app: my-app\n    ##\n    selector: {}\n    ## @param readReplicas.persistence.dataSource Custom PVC data source\n    ##\n    dataSource: {}\n\n## @section NetworkPolicy parameters\n##\n\n## Add networkpolicies\n##\nnetworkPolicy:\n  ## @param networkPolicy.enabled Enable network policies\n  ##\n  enabled: false\n  ## @param networkPolicy.metrics.enabled Enable network policies for metrics (prometheus)\n  ## @param networkPolicy.metrics.namespaceSelector [object] Monitoring namespace selector labels. These labels will be used to identify the prometheus' namespace.\n  ## @param networkPolicy.metrics.podSelector [object] Monitoring pod selector labels. These labels will be used to identify the Prometheus pods.\n  ##\n  metrics:\n    enabled: false\n    ## e.g:\n    ## namespaceSelector:\n    ##   label: monitoring\n    ##\n    namespaceSelector: {}\n    ## e.g:\n    ## podSelector:\n    ##   label: monitoring\n    ##\n    podSelector: {}\n  ## Ingress Rules\n  ##\n  ingressRules:\n    ## @param networkPolicy.ingressRules.primaryAccessOnlyFrom.enabled Enable ingress rule that makes PostgreSQL primary node only accessible from a particular origin.\n    ## @param networkPolicy.ingressRules.primaryAccessOnlyFrom.namespaceSelector [object] Namespace selector label that is allowed to access the PostgreSQL primary node. This label will be used to identified the allowed namespace(s).\n    ## @param networkPolicy.ingressRules.primaryAccessOnlyFrom.podSelector [object] Pods selector label that is allowed to access the PostgreSQL primary node. This label will be used to identified the allowed pod(s).\n    ## @param networkPolicy.ingressRules.primaryAccessOnlyFrom.customRules Custom network policy for the PostgreSQL primary node.\n    ##\n    primaryAccessOnlyFrom:\n      enabled: false\n      ## e.g:\n      ## namespaceSelector:\n      ##   label: ingress\n      ##\n      namespaceSelector: {}\n      ## e.g:\n      ## podSelector:\n      ##   label: access\n      ##\n      podSelector: {}\n      ## custom ingress rules\n      ## e.g:\n      ## customRules:\n      ##   - from:\n      ##       - namespaceSelector:\n      ##           matchLabels:\n      ##             label: example\n      ##\n      customRules: []\n    ## @param networkPolicy.ingressRules.readReplicasAccessOnlyFrom.enabled Enable ingress rule that makes PostgreSQL read-only nodes only accessible from a particular origin.\n    ## @param networkPolicy.ingressRules.readReplicasAccessOnlyFrom.namespaceSelector [object] Namespace selector label that is allowed to access the PostgreSQL read-only nodes. This label will be used to identified the allowed namespace(s).\n    ## @param networkPolicy.ingressRules.readReplicasAccessOnlyFrom.podSelector [object] Pods selector label that is allowed to access the PostgreSQL read-only nodes. This label will be used to identified the allowed pod(s).\n    ## @param networkPolicy.ingressRules.readReplicasAccessOnlyFrom.customRules Custom network policy for the PostgreSQL read-only nodes.\n    ##\n    readReplicasAccessOnlyFrom:\n      enabled: false\n      ## e.g:\n      ## namespaceSelector:\n      ##   label: ingress\n      ##\n      namespaceSelector: {}\n      ## e.g:\n      ## podSelector:\n      ##   label: access\n      ##\n      podSelector: {}\n      ## custom ingress rules\n      ## e.g:\n      ## CustomRules:\n      ##   - from:\n      ##       - namespaceSelector:\n      ##           matchLabels:\n      ##             label: example\n      ##\n      customRules: []\n  ## @param networkPolicy.egressRules.denyConnectionsToExternal Enable egress rule that denies outgoing traffic outside the cluster, except for DNS (port 53).\n  ## @param networkPolicy.egressRules.customRules Custom network policy rule\n  ##\n  egressRules:\n    # Deny connections to external. This is not compatible with an external database.\n    denyConnectionsToExternal: false\n    ## Additional custom egress rules\n    ## e.g:\n    ## customRules:\n    ##   - to:\n    ##       - namespaceSelector:\n    ##           matchLabels:\n    ##             label: example\n    ##\n    customRules: []\n\n## @section Volume Permissions parameters\n##\n\n## Init containers parameters:\n## volumePermissions: Change the owner and group of the persistent volume(s) mountpoint(s) to 'runAsUser:fsGroup' on each node\n##\nvolumePermissions:\n  ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume\n  ##\n  enabled: false\n  ## @param volumePermissions.image.registry Init container volume-permissions image registry\n  ## @param volumePermissions.image.repository Init container volume-permissions image repository\n  ## @param volumePermissions.image.tag Init container volume-permissions image tag (immutable tags are recommended)\n  ## @param volumePermissions.image.digest Init container volume-permissions image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n  ## @param volumePermissions.image.pullPolicy Init container volume-permissions image pull policy\n  ## @param volumePermissions.image.pullSecrets Init container volume-permissions image pull secrets\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/bitnami-shell\n    tag: 11-debian-11-r120\n    digest: \"\"\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## Example:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## Init container resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## @param volumePermissions.resources.limits Init container volume-permissions resource limits\n  ## @param volumePermissions.resources.requests Init container volume-permissions resource requests\n  ##\n  resources:\n    limits: {}\n    requests: {}\n  ## Init container' Security Context\n  ## Note: the chown of the data folder is done to containerSecurityContext.runAsUser\n  ## and not the below volumePermissions.containerSecurityContext.runAsUser\n  ## @param volumePermissions.containerSecurityContext.runAsUser User ID for the init container\n  ##\n  containerSecurityContext:\n    runAsUser: 0\n\n## @section Other Parameters\n##\n\n## @param serviceBindings.enabled Create secret for service binding (Experimental)\n## Ref: https://servicebinding.io/service-provider/\n##\nserviceBindings:\n  enabled: false\n\n## Service account for PostgreSQL to use.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n##\nserviceAccount:\n  ## @param serviceAccount.create Enable creation of ServiceAccount for PostgreSQL pod\n  ##\n  create: false\n  ## @param serviceAccount.name The name of the ServiceAccount to use.\n  ## If not set and create is true, a name is generated using the common.names.fullname template\n  ##\n  name: \"\"\n  ## @param serviceAccount.automountServiceAccountToken Allows auto mount of ServiceAccountToken on the serviceAccount created\n  ## Can be set to false if pods using this serviceAccount do not need to use K8s API\n  ##\n  automountServiceAccountToken: true\n  ## @param serviceAccount.annotations Additional custom annotations for the ServiceAccount\n  ##\n  annotations: {}\n## Creates role for ServiceAccount\n## @param rbac.create Create Role and RoleBinding (required for PSP to work)\n##\nrbac:\n  create: false\n  ## @param rbac.rules Custom RBAC rules to set\n  ## e.g:\n  ## rules:\n  ##   - apiGroups:\n  ##       - \"\"\n  ##     resources:\n  ##       - pods\n  ##     verbs:\n  ##       - get\n  ##       - list\n  ##\n  rules: []\n## Pod Security Policy\n## ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n## @param psp.create Whether to create a PodSecurityPolicy. WARNING: PodSecurityPolicy is deprecated in Kubernetes v1.21 or later, unavailable in v1.25 or later\n##\npsp:\n  create: false\n\n## @section Metrics Parameters\n##\n\nmetrics:\n  ## @param metrics.enabled Start a prometheus exporter\n  ##\n  enabled: false\n  ## @param metrics.image.registry PostgreSQL Prometheus Exporter image registry\n  ## @param metrics.image.repository PostgreSQL Prometheus Exporter image repository\n  ## @param metrics.image.tag PostgreSQL Prometheus Exporter image tag (immutable tags are recommended)\n  ## @param metrics.image.digest PostgreSQL image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n  ## @param metrics.image.pullPolicy PostgreSQL Prometheus Exporter image pull policy\n  ## @param metrics.image.pullSecrets Specify image pull secrets\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/postgres-exporter\n    tag: 0.12.0-debian-11-r91\n    digest: \"\"\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## Example:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## @param metrics.customMetrics Define additional custom metrics\n  ## ref: https://github.com/wrouesnel/postgres_exporter#adding-new-metrics-via-a-config-file\n  ## customMetrics:\n  ##   pg_database:\n  ##     query: \"SELECT d.datname AS name, CASE WHEN pg_catalog.has_database_privilege(d.datname, 'CONNECT') THEN pg_catalog.pg_database_size(d.datname) ELSE 0 END AS size_bytes FROM pg_catalog.pg_database d where datname not in ('template0', 'template1', 'postgres')\"\n  ##     metrics:\n  ##       - name:\n  ##           usage: \"LABEL\"\n  ##           description: \"Name of the database\"\n  ##       - size_bytes:\n  ##           usage: \"GAUGE\"\n  ##           description: \"Size of the database in bytes\"\n  ##\n  customMetrics: {}\n  ## @param metrics.extraEnvVars Extra environment variables to add to PostgreSQL Prometheus exporter\n  ## see: https://github.com/wrouesnel/postgres_exporter#environment-variables\n  ## For example:\n  ##  extraEnvVars:\n  ##  - name: PG_EXPORTER_DISABLE_DEFAULT_METRICS\n  ##    value: \"true\"\n  ##\n  extraEnvVars: []\n  ## PostgreSQL Prometheus exporter containers' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param metrics.containerSecurityContext.enabled Enable PostgreSQL Prometheus exporter containers' Security Context\n  ## @param metrics.containerSecurityContext.runAsUser Set PostgreSQL Prometheus exporter containers' Security Context runAsUser\n  ## @param metrics.containerSecurityContext.runAsNonRoot Set PostgreSQL Prometheus exporter containers' Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## Configure extra options for PostgreSQL Prometheus exporter containers' liveness, readiness and startup probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes\n  ## @param metrics.livenessProbe.enabled Enable livenessProbe on PostgreSQL Prometheus exporter containers\n  ## @param metrics.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param metrics.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param metrics.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param metrics.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param metrics.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  ## @param metrics.readinessProbe.enabled Enable readinessProbe on PostgreSQL Prometheus exporter containers\n  ## @param metrics.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param metrics.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param metrics.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param metrics.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param metrics.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  ## @param metrics.startupProbe.enabled Enable startupProbe on PostgreSQL Prometheus exporter containers\n  ## @param metrics.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param metrics.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param metrics.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param metrics.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param metrics.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: false\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 15\n    successThreshold: 1\n  ## @param metrics.customLivenessProbe Custom livenessProbe that overrides the default one\n  ##\n  customLivenessProbe: {}\n  ## @param metrics.customReadinessProbe Custom readinessProbe that overrides the default one\n  ##\n  customReadinessProbe: {}\n  ## @param metrics.customStartupProbe Custom startupProbe that overrides the default one\n  ##\n  customStartupProbe: {}\n  ## @param metrics.containerPorts.metrics PostgreSQL Prometheus exporter metrics container port\n  ##\n  containerPorts:\n    metrics: 9187\n  ## PostgreSQL Prometheus exporter resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## @param metrics.resources.limits The resources limits for the PostgreSQL Prometheus exporter container\n  ## @param metrics.resources.requests The requested resources for the PostgreSQL Prometheus exporter container\n  ##\n  resources:\n    limits: {}\n    requests: {}\n  ## Service configuration\n  ##\n  service:\n    ## @param metrics.service.ports.metrics PostgreSQL Prometheus Exporter service port\n    ##\n    ports:\n      metrics: 9187\n    ## @param metrics.service.clusterIP Static clusterIP or None for headless services\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#choosing-your-own-ip-address\n    ##\n    clusterIP: \"\"\n    ## @param metrics.service.sessionAffinity Control where client requests go, to the same pod or round-robin\n    ## Values: ClientIP or None\n    ## ref: https://kubernetes.io/docs/user-guide/services/\n    ##\n    sessionAffinity: None\n    ## @param metrics.service.annotations [object] Annotations for Prometheus to auto-discover the metrics endpoint\n    ##\n    annotations:\n      prometheus.io/scrape: \"true\"\n      prometheus.io/port: \"{{ .Values.metrics.service.ports.metrics }}\"\n  ## Prometheus Operator ServiceMonitor configuration\n  ##\n  serviceMonitor:\n    ## @param metrics.serviceMonitor.enabled Create ServiceMonitor Resource for scraping metrics using Prometheus Operator\n    ##\n    enabled: false\n    ## @param metrics.serviceMonitor.namespace Namespace for the ServiceMonitor Resource (defaults to the Release Namespace)\n    ##\n    namespace: \"\"\n    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped.\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint\n    ##\n    interval: \"\"\n    ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint\n    ##\n    scrapeTimeout: \"\"\n    ## @param metrics.serviceMonitor.labels Additional labels that can be used so ServiceMonitor will be discovered by Prometheus\n    ##\n    labels: {}\n    ## @param metrics.serviceMonitor.selector Prometheus instance selector labels\n    ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration\n    ##\n    selector: {}\n    ## @param metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping\n    ##\n    relabelings: []\n    ## @param metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before ingestion\n    ##\n    metricRelabelings: []\n    ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint\n    ##\n    honorLabels: false\n    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in prometheus.\n    ##\n    jobLabel: \"\"\n  ## Custom PrometheusRule to be defined\n  ## The value is evaluated as a template, so, for example, the value can depend on .Release or .Chart\n  ## ref: https://github.com/coreos/prometheus-operator#customresourcedefinitions\n  ##\n  prometheusRule:\n    ## @param metrics.prometheusRule.enabled Create a PrometheusRule for Prometheus Operator\n    ##\n    enabled: false\n    ## @param metrics.prometheusRule.namespace Namespace for the PrometheusRule Resource (defaults to the Release Namespace)\n    ##\n    namespace: \"\"\n    ## @param metrics.prometheusRule.labels Additional labels that can be used so PrometheusRule will be discovered by Prometheus\n    ##\n    labels: {}\n    ## @param metrics.prometheusRule.rules PrometheusRule definitions\n    ## Make sure to constraint the rules to the current postgresql service.\n    ## rules:\n    ##   - alert: HugeReplicationLag\n    ##     expr: pg_replication_lag{service=\"{{ printf \"%s-metrics\" (include \"common.names.fullname\" .) }}\"} / 3600 \u003e 1\n    ##     for: 1m\n    ##     labels:\n    ##       severity: critical\n    ##     annotations:\n    ##       description: replication for {{ include \"common.names.fullname\" . }} PostgreSQL is lagging by {{ \"{{ $value }}\" }} hour(s).\n    ##       summary: PostgreSQL replication is lagging by {{ \"{{ $value }}\" }} hour(s).\n    ##\n    rules: []\n"
            ],
            "verify": false,
            "version": "15.5.4",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_namespace.datalake_ns-namespace"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "telegraf_operator",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "telegraf",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "telegraf-prd",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.30.3",
                "chart": "telegraf",
                "name": "telegraf-prd",
                "namespace": "datalake",
                "revision": 1,
                "values": "{\"affinity\":{},\"args\":[],\"config\":{\"agent\":{\"collection_jitter\":\"0s\",\"debug\":false,\"flush_interval\":\"10s\",\"flush_jitter\":\"0s\",\"hostname\":\"$HOSTNAME\",\"interval\":\"10s\",\"logfile\":\"\",\"metric_batch_size\":1000,\"metric_buffer_limit\":10000,\"omit_hostname\":false,\"precision\":\"\",\"quiet\":false,\"round_interval\":true},\"inputs\":[{\"statsd\":{\"allowed_pending_messages\":10000,\"metric_separator\":\"_\",\"percentile_limit\":1000,\"percentiles\":[50,95,99],\"service_address\":\":8125\"}}],\"outputs\":[{\"influxdb\":{\"database\":\"telegraf\",\"urls\":[\"http://influxdb-influxdb2.datalake.svc.cluster.local:80\"]}}],\"processors\":[{\"enum\":{\"mapping\":{\"dest\":\"status_code\",\"field\":\"status\",\"value_mappings\":{\"critical\":3,\"healthy\":1,\"problem\":2}}}}]},\"env\":[{\"name\":\"HOSTNAME\",\"value\":\"telegraf-polling-service\"}],\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repo\":\"docker.io/library/telegraf\",\"tag\":\"1.30-alpine\"},\"imagePullSecrets\":[],\"metrics\":{\"health\":{\"enabled\":false,\"service_address\":\"http://:8888\",\"threshold\":5000},\"internal\":{\"collect_memstats\":false,\"enabled\":true}},\"nodeSelector\":{},\"pdb\":{\"create\":true,\"minAvailable\":1},\"podAnnotations\":{},\"podLabels\":{},\"rbac\":{\"clusterWide\":false,\"create\":true,\"rules\":[]},\"replicaCount\":1,\"resources\":{},\"service\":{\"annotations\":{},\"enabled\":true,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":null},\"tolerations\":[],\"updateStrategy\":{}}",
                "version": "1.8.48"
              }
            ],
            "name": "telegraf-prd",
            "namespace": "datalake",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://helm.influxdata.com",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "## Default values.yaml for Telegraf\n## This is a YAML-formatted file.\n## ref: https://hub.docker.com/r/library/telegraf/tags/\n\nreplicaCount: 1\nimage:\n  repo: \"docker.io/library/telegraf\"\n  tag: \"1.30-alpine\"\n  pullPolicy: IfNotPresent\npodAnnotations: {}\npodLabels: {}\nimagePullSecrets: []\n## Configure args passed to Telegraf containers\nargs: []\n# The name of a secret in the same kubernetes namespace which contains values to\n# be added to the environment (must be manually created)\n# This can be useful for auth tokens, etc.\n\n# envFromSecret: \"telegraf-tokens\"\nenv:\n- name: HOSTNAME\n  value: \"telegraf-polling-service\"\n# An older \"volumeMounts\" key was previously added which will likely\n# NOT WORK as you expect. Please use this newer configuration.\n\n# volumes:\n# - name: telegraf-output-influxdb2\n#   configMap:\n#     name: \"telegraf-output-influxdb2\"\n# mountPoints:\n# - name: telegraf-output-influxdb2\n#   mountPath: /etc/telegraf/conf.d\n#   subPath: influxdb2.conf\n\n## Configure resource requests and limits\n## ref: http://kubernetes.io/docs/user-guide/compute-resources/\nresources: {}\n# requests:\n#   memory: 128Mi\n#   cpu: 100m\n# limits:\n#   memory: 128Mi\n#   cpu: 100m\n\n## Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\nnodeSelector: {}\n## Affinity for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n## Tolerations for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n# - key: \"key\"\n#   operator: \"Equal|Exists\"\n#   value: \"value\"\n#   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n## Configure the updateStrategy used to replace Telegraf Pods\n## See https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/\nupdateStrategy: {}\n#  type: RollingUpdate|Recreate\n#  rollingUpdate:\n#    maxUnavailable: 1\n#    maxSurge: 1\n\nservice:\n  enabled: true\n  type: ClusterIP\n  annotations: {}\nrbac:\n  # Specifies whether RBAC resources should be created\n  create: true\n  # Create only for the release namespace or cluster wide (Role vs ClusterRole)\n  clusterWide: false\n  # Rules for the created rule\n  rules: []\n# When using the prometheus input to scrape all pods you need extra rules set to the ClusterRole to be\n# able to scan the pods for scraping labels. The following rules have been taken from:\n# https://github.com/helm/charts/blob/master/stable/prometheus/templates/server-clusterrole.yaml#L8-L46\n#    - apiGroups:\n#        - \"\"\n#      resources:\n#        - nodes\n#        - nodes/proxy\n#        - nodes/metrics\n#        - services\n#        - endpoints\n#        - pods\n#        - ingresses\n#        - configmaps\n#      verbs:\n#        - get\n#        - list\n#        - watch\n#    - apiGroups:\n#        - \"extensions\"\n#      resources:\n#        - ingresses/status\n#        - ingresses\n#      verbs:\n#        - get\n#        - list\n#        - watch\n#    - nonResourceURLs:\n#        - \"/metrics\"\n#      verbs:\n#        - get\n\nserviceAccount:\n  # Specifies whether a ServiceAccount should be created\n  create: true\n  # The name of the ServiceAccount to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name:\n  # Annotations for the ServiceAccount\n  annotations: {}\n## Exposed telegraf configuration\n## For full list of possible values see `/docs/all-config-values.yaml` and `/docs/all-config-values.toml`\n## ref: https://docs.influxdata.com/telegraf/v1.1/administration/configuration/\nconfig:\n  agent:\n    interval: \"10s\"\n    round_interval: true\n    metric_batch_size: 1000\n    metric_buffer_limit: 10000\n    collection_jitter: \"0s\"\n    flush_interval: \"10s\"\n    flush_jitter: \"0s\"\n    precision: \"\"\n    debug: false\n    quiet: false\n    logfile: \"\"\n    hostname: \"$HOSTNAME\"\n    omit_hostname: false\n  processors:\n  - enum:\n      mapping:\n        field: \"status\"\n        dest: \"status_code\"\n        value_mappings:\n          healthy: 1\n          problem: 2\n          critical: 3\n  outputs:\n  - influxdb:\n      urls:\n      - \"http://influxdb-influxdb2.datalake.svc.cluster.local:80\"\n      database: \"telegraf\"\n  inputs:\n  - statsd:\n      service_address: \":8125\"\n      percentiles:\n      - 50\n      - 95\n      - 99\n      metric_separator: \"_\"\n      allowed_pending_messages: 10000\n      percentile_limit: 1000\nmetrics:\n  health:\n    enabled: false\n    service_address: \"http://:8888\"\n    threshold: 5000.0\n  internal:\n    enabled: true\n    collect_memstats: false\n# Lifecycle hooks\n# hooks:\n#   postStart: [\"/bin/sh\", \"-c\", \"echo Telegraf started\"]\n#   preStop: [\"/bin/sh\", \"-c\", \"sleep 60\"]\n\n## Pod disruption budget configuration\n##\npdb:\n  ## Specifies whether a Pod disruption budget should be created\n  ##\n  create: true\n  minAvailable: 1\n  # maxUnavailable: 1\n"
            ],
            "verify": false,
            "version": "1.8.48",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "traefik_name",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "traefik",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "ingress-traefik",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "v3.0.0",
                "chart": "traefik",
                "name": "ingress-traefik",
                "namespace": "ingress-traefik",
                "revision": 8,
                "values": "{\"additionalArguments\":[\"--providers.kubernetesingress.ingressclass=ingress-traefik\",\"--log.level=DEBUG\",\"--providers.kubernetescrd\"],\"additionalVolumeMounts\":[],\"affinity\":{\"nodeAffinity\":{\"requiredDuringSchedulingIgnoredDuringExecution\":{\"nodeSelectorTerms\":[{\"matchExpressions\":[{\"key\":\"kubernetes.io/hostname\",\"operator\":\"In\",\"values\":[\"node3673\"]}]}]}}},\"autoscaling\":{\"enabled\":false},\"certResolvers\":{},\"commonLabels\":{},\"deployment\":{\"additionalContainers\":[],\"additionalVolumes\":[],\"annotations\":{},\"dnsConfig\":{},\"enabled\":true,\"imagePullSecrets\":[],\"initContainers\":[],\"kind\":\"Deployment\",\"labels\":{},\"lifecycle\":{},\"minReadySeconds\":0,\"podAnnotations\":{},\"podLabels\":{},\"replicas\":1,\"shareProcessNamespace\":false,\"terminationGracePeriodSeconds\":60},\"env\":[],\"envFrom\":[],\"experimental\":{\"kubernetesGateway\":{\"enabled\":false,\"gateway\":{\"enabled\":false}},\"plugins\":{},\"v3\":{\"enabled\":true}},\"extraObjects\":[],\"globalArguments\":[\"--global.checknewversion\",\"--global.sendanonymoususage\",\"--global.sendanonymoususage=false\",\"--global.checknewversion=false\"],\"hostNetwork\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"docker.io\",\"repository\":\"traefik\",\"tag\":\"\"},\"ingressClass\":{\"enabled\":true,\"isDefaultClass\":false},\"ingressRoute\":{\"dashboard\":{\"annotations\":{},\"enabled\":true,\"entryPoints\":[\"web\"],\"labels\":{},\"matchRule\":\"PathPrefix(`/dashboard`) || PathPrefix(`/api`)\",\"middlewares\":[],\"tls\":{}}},\"livenessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":2,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":2},\"logs\":{\"access\":{\"enabled\":true,\"fields\":{\"general\":{\"defaultmode\":\"keep\",\"names\":{}},\"headers\":{\"defaultmode\":\"drop\",\"names\":{}}},\"filters\":{}},\"general\":{\"level\":\"INFO\"}},\"metrics\":{\"prometheus\":{\"entryPoint\":\"metrics\"}},\"persistence\":{\"accessMode\":\"ReadWriteOnce\",\"annotations\":{},\"enabled\":true,\"name\":\"data\",\"path\":\"/data\",\"size\":\"512Mi\"},\"podDisruptionBudget\":{\"enabled\":false},\"podSecurityContext\":{\"fsGroupChangePolicy\":\"OnRootMismatch\",\"runAsGroup\":65532,\"runAsNonRoot\":true,\"runAsUser\":65532},\"podSecurityPolicy\":{\"enabled\":false},\"ports\":{\"airflow\":{\"expose\":{\"default\":true},\"exposedPort\":9999,\"port\":9999,\"protocol\":\"TCP\"},\"apm\":{\"expose\":{\"default\":true},\"exposedPort\":8200,\"port\":8200,\"protocol\":\"TCP\"},\"influx\":{\"expose\":{\"default\":true},\"exposedPort\":8079,\"port\":8079,\"protocol\":\"TCP\"},\"jupyterhub\":{\"expose\":{\"default\":true},\"exposedPort\":8103,\"port\":8103,\"protocol\":\"TCP\"},\"kibana\":{\"expose\":{\"default\":true},\"exposedPort\":5601,\"port\":5601,\"protocol\":\"TCP\"},\"loki\":{\"expose\":{\"default\":true},\"exposedPort\":9477,\"port\":9477,\"protocol\":\"TCP\"},\"metrics\":{\"expose\":{\"default\":true},\"exposedPort\":9100,\"port\":9100,\"protocol\":\"TCP\"},\"minio\":{\"expose\":{\"default\":true},\"exposedPort\":8102,\"port\":8102,\"protocol\":\"TCP\"},\"mongodb\":{\"expose\":{\"default\":true},\"exposedPort\":27017,\"port\":27017,\"protocol\":\"TCP\"},\"mongodbauth\":{\"expose\":{\"default\":true},\"exposedPort\":27019,\"port\":27019,\"protocol\":\"TCP\"},\"mysql\":{\"expose\":{\"default\":true},\"exposedPort\":3306,\"port\":3306,\"protocol\":\"TCP\"},\"mysqlaws\":{\"expose\":{\"default\":true},\"exposedPort\":4306,\"port\":4306,\"protocol\":\"TCP\"},\"prometheus\":{\"expose\":{\"default\":true},\"exposedPort\":9090,\"port\":9090,\"protocol\":\"TCP\"},\"redis\":{\"expose\":{\"default\":true},\"exposedPort\":6379,\"port\":6379,\"protocol\":\"TCP\"},\"tcp1\":{\"expose\":{\"default\":true},\"exposedPort\":8080,\"port\":8080,\"protocol\":\"TCP\"},\"tcp10\":{\"expose\":{\"default\":true},\"exposedPort\":8089,\"port\":8089,\"protocol\":\"TCP\"},\"tcp11\":{\"expose\":{\"default\":true},\"exposedPort\":8090,\"port\":8090,\"protocol\":\"TCP\"},\"tcp12\":{\"expose\":{\"default\":true},\"exposedPort\":8091,\"port\":8091,\"protocol\":\"TCP\"},\"tcp13\":{\"expose\":{\"default\":true},\"exposedPort\":8092,\"port\":8092,\"protocol\":\"TCP\"},\"tcp14\":{\"expose\":{\"default\":true},\"exposedPort\":8093,\"port\":8093,\"protocol\":\"TCP\"},\"tcp15\":{\"expose\":{\"default\":true},\"exposedPort\":8094,\"port\":8094,\"protocol\":\"TCP\"},\"tcp16\":{\"expose\":{\"default\":true},\"exposedPort\":8095,\"port\":8095,\"protocol\":\"TCP\"},\"tcp17\":{\"expose\":{\"default\":true},\"exposedPort\":8096,\"port\":8096,\"protocol\":\"TCP\"},\"tcp18\":{\"expose\":{\"default\":true},\"exposedPort\":8097,\"port\":8097,\"protocol\":\"TCP\"},\"tcp19\":{\"expose\":{\"default\":true},\"exposedPort\":8098,\"port\":8098,\"protocol\":\"TCP\"},\"tcp2\":{\"expose\":{\"default\":true},\"exposedPort\":8081,\"port\":8081,\"protocol\":\"TCP\"},\"tcp20\":{\"expose\":{\"default\":true},\"exposedPort\":8099,\"port\":8099,\"protocol\":\"TCP\"},\"tcp3\":{\"expose\":{\"default\":true},\"exposedPort\":8082,\"port\":8082,\"protocol\":\"TCP\"},\"tcp4\":{\"expose\":{\"default\":true},\"exposedPort\":8083,\"port\":8083,\"protocol\":\"TCP\"},\"tcp5\":{\"expose\":{\"default\":true},\"exposedPort\":8084,\"port\":8084,\"protocol\":\"TCP\"},\"tcp6\":{\"expose\":{\"default\":true},\"exposedPort\":8085,\"port\":8085,\"protocol\":\"TCP\"},\"tcp7\":{\"expose\":{\"default\":true},\"exposedPort\":8086,\"port\":8086,\"protocol\":\"TCP\"},\"tcp8\":{\"expose\":{\"default\":true},\"exposedPort\":8087,\"port\":8087,\"protocol\":\"TCP\"},\"tcp9\":{\"expose\":{\"default\":true},\"exposedPort\":8088,\"port\":8088,\"protocol\":\"TCP\"},\"telegraf\":{\"expose\":{\"default\":true},\"exposedPort\":8101,\"port\":8101,\"protocol\":\"TCP\"},\"telemetry14250\":{\"expose\":{\"default\":true},\"exposedPort\":14250,\"port\":14250,\"protocol\":\"TCP\"},\"telemetry14268\":{\"expose\":{\"default\":true},\"exposedPort\":14268,\"port\":14268,\"protocol\":\"TCP\"},\"telemetry4317\":{\"expose\":{\"default\":true},\"exposedPort\":4317,\"port\":4317,\"protocol\":\"TCP\"},\"telemetry4318\":{\"expose\":{\"default\":true},\"exposedPort\":4318,\"port\":4318,\"protocol\":\"TCP\"},\"telemetry6831\":{\"expose\":{\"default\":true},\"exposedPort\":6831,\"port\":6831,\"protocol\":\"UDP\"},\"telemetry9411\":{\"expose\":{\"default\":true},\"exposedPort\":9411,\"port\":9411,\"protocol\":\"TCP\"},\"tempo\":{\"expose\":{\"default\":true},\"exposedPort\":9600,\"port\":9600,\"protocol\":\"TCP\"},\"tempozipkin\":{\"expose\":{\"default\":true},\"exposedPort\":9700,\"port\":9700,\"protocol\":\"TCP\"},\"traefik\":{\"expose\":{\"default\":true},\"exposedPort\":9000,\"port\":9000,\"protocol\":\"TCP\"},\"udp1\":{\"expose\":{\"default\":true},\"exposedPort\":8001,\"port\":8001,\"protocol\":\"UDP\"},\"udp2\":{\"expose\":{\"default\":true},\"exposedPort\":8002,\"port\":8002,\"protocol\":\"UDP\"},\"udp3\":{\"expose\":{\"default\":true},\"exposedPort\":8003,\"port\":8003,\"protocol\":\"UDP\"},\"web\":{\"expose\":{\"default\":true},\"exposedPort\":8000,\"port\":8000,\"protocol\":\"TCP\"},\"websecure\":{\"expose\":{\"default\":true},\"exposedPort\":8443,\"http3\":{\"enabled\":false},\"middlewares\":[],\"port\":8443,\"protocol\":\"TCP\",\"tls\":{\"certResolver\":\"\",\"domains\":[],\"enabled\":true,\"options\":\"\"}},\"zipkin\":{\"expose\":{\"default\":true},\"exposedPort\":19411,\"port\":19411,\"protocol\":\"TCP\"}},\"priorityClassName\":\"\",\"providers\":{\"kubernetesCRD\":{\"allowCrossNamespace\":true,\"allowEmptyServices\":true,\"allowExternalNameServices\":true,\"enabled\":true,\"namespaces\":[]},\"kubernetesIngress\":{\"allowEmptyServices\":true,\"allowExternalNameServices\":true,\"enabled\":true,\"namespaces\":[],\"publishedService\":{\"enabled\":true}}},\"rbac\":{\"enabled\":true,\"namespaced\":false},\"readinessProbe\":{\"failureThreshold\":1,\"initialDelaySeconds\":2,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":2},\"resources\":{},\"securityContext\":{\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true},\"service\":{\"annotations\":{},\"annotationsTCP\":{},\"annotationsUDP\":{},\"enabled\":true,\"externalIPs\":[\"192.168.36.90\"],\"labels\":{},\"loadBalancerSourceRanges\":[],\"single\":true,\"spec\":{},\"type\":\"LoadBalancer\"},\"serviceAccount\":{\"name\":\"\"},\"serviceAccountAnnotations\":{},\"tlsOptions\":{},\"tlsStore\":{},\"tolerations\":[{\"effect\":\"NoSchedule\",\"key\":\"node-role.kubernetes.io/control-plane\",\"operator\":\"Exists\"}],\"topologySpreadConstraints\":[],\"tracing\":{},\"updateStrategy\":{\"rollingUpdate\":{\"maxSurge\":1,\"maxUnavailable\":0},\"type\":\"RollingUpdate\"},\"volumes\":[]}",
                "version": "28.0.0"
              }
            ],
            "name": "ingress-traefik",
            "namespace": "ingress-traefik",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://traefik.github.io/charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "# Default values for Traefik\nimage:\n  # -- Traefik image host registry\n  registry: docker.io\n  # -- Traefik image repository\n  repository: traefik\n  # -- defaults to appVersion\n  tag: \"\"\n  # -- Traefik image pull policy\n  pullPolicy: IfNotPresent\n\n# -- Add additional label to all resources\ncommonLabels: {}\n\n#\n# Configure the deployment\n#\ndeployment:\n  # -- Enable deployment\n  enabled: true\n  # -- Deployment or DaemonSet\n  kind: Deployment\n  # -- Number of pods of the deployment (only applies when kind == Deployment)\n  replicas: 1\n  # -- Number of old history to retain to allow rollback (If not set, default Kubernetes value is set to 10)\n  # revisionHistoryLimit: 1\n  # -- Amount of time (in seconds) before Kubernetes will send the SIGKILL signal if Traefik does not shut down\n  terminationGracePeriodSeconds: 60\n  # -- The minimum number of seconds Traefik needs to be up and running before the DaemonSet/Deployment controller considers it available\n  minReadySeconds: 0\n  # -- Additional deployment annotations (e.g. for jaeger-operator sidecar injection)\n  annotations: {}\n  # -- Additional deployment labels (e.g. for filtering deployment by custom labels)\n  labels: {}\n  # -- Additional pod annotations (e.g. for mesh injection or prometheus scraping)\n  podAnnotations: {}\n  # -- Additional Pod labels (e.g. for filtering Pod by custom labels)\n  podLabels: {}\n  # -- Additional containers (e.g. for metric offloading sidecars)\n  additionalContainers: []\n  # https://docs.datadoghq.com/developers/dogstatsd/unix_socket/?tab=host\n  # - name: socat-proxy\n  #   image: alpine/socat:1.0.5\n  #   args: [\"-s\", \"-u\", \"udp-recv:8125\", \"unix-sendto:/socket/socket\"]\n  #   volumeMounts:\n  #     - name: dsdsocket\n  #       mountPath: /socket\n  # -- Additional volumes available for use with initContainers and additionalContainers\n  additionalVolumes: []\n  # - name: dsdsocket\n  #   hostPath:\n  #     path: /var/run/statsd-exporter\n  # -- Additional initContainers (e.g. for setting file permission as shown below)\n  initContainers: []\n  # The \"volume-permissions\" init container is required if you run into permission issues.\n  # Related issue: https://github.com/traefik/traefik-helm-chart/issues/396\n  # - name: volume-permissions\n  #   image: busybox:latest\n  #   command: [\"sh\", \"-c\", \"touch /data/acme.json; chmod -v 600 /data/acme.json\"]\n  #   securityContext:\n  #     runAsNonRoot: true\n  #     runAsGroup: 65532\n  #     runAsUser: 65532\n  #   volumeMounts:\n  #     - name: data\n  #       mountPath: /data\n  # -- Use process namespace sharing\n  shareProcessNamespace: false\n  # -- Custom pod DNS policy. Apply if `hostNetwork: true`\n  # dnsPolicy: ClusterFirstWithHostNet\n  dnsConfig: {}\n  # nameservers:\n  #   - 192.0.2.1 # this is an example\n  # searches:\n  #   - ns1.svc.cluster-domain.example\n  #   - my.dns.search.suffix\n  # options:\n  #   - name: ndots\n  #     value: \"2\"\n  #   - name: edns0\n  # -- Additional imagePullSecrets\n  imagePullSecrets: []\n  # - name: myRegistryKeySecretName\n  # -- Pod lifecycle actions\n  lifecycle: {}\n  # preStop:\n  #   exec:\n  #     command: [\"/bin/sh\", \"-c\", \"sleep 40\"]\n  # postStart:\n  #   httpGet:\n  #     path: /ping\n  #     port: 9000\n  #     host: localhost\n  #     scheme: HTTP\n\n# -- Pod disruption budget\npodDisruptionBudget:\n  enabled: false\n  # maxUnavailable: 1\n  # maxUnavailable: 33%\n  # minAvailable: 0\n  # minAvailable: 25%\n\n# -- Create a default IngressClass for Traefik\ningressClass:\n  enabled: true\n  isDefaultClass: false\n\n# Traefik experimental features\nexperimental:\n  v3:\n    # -- Enable traefik version 3\n    enabled: true\n  plugins: {}\n  kubernetesGateway:\n    # -- Enable traefik experimental GatewayClass CRD\n    enabled: false\n    gateway:\n      # -- Enable traefik regular kubernetes gateway\n      enabled: false\n      # certificate:\n      #   group: \"core\"\n      #   kind: \"Secret\"\n      #   name: \"mysecret\"\n      # -- By default, Gateway would be created to the Namespace you are deploying Traefik to.\n      # You may create that Gateway in another namespace, setting its name below:\n      # namespace: default\n      # Additional gateway annotations (e.g. for cert-manager.io/issuer)\n      # annotations:\n      #   cert-manager.io/issuer: letsencrypt\n\n## Create an IngressRoute for the dashboard\ningressRoute:\n  dashboard:\n    # -- Create an IngressRoute for the dashboard\n    enabled: true\n    # -- Additional ingressRoute annotations (e.g. for kubernetes.io/ingress.class)\n    annotations: {}\n    # -- Additional ingressRoute labels (e.g. for filtering IngressRoute by custom labels)\n    labels: {}\n    # -- The router match rule used for the dashboard ingressRoute\n    matchRule: PathPrefix(`/dashboard`) || PathPrefix(`/api`)\n    # -- Specify the allowed entrypoints to use for the dashboard ingress route, (e.g. traefik, web, websecure).\n    # By default, it's using traefik entrypoint, which is not exposed.\n    # /!\\ Do not expose your dashboard without any protection over the internet /!\\\n    entryPoints: [\"web\"]\n    # -- Additional ingressRoute middlewares (e.g. for authentication)\n    middlewares: []\n    # -- TLS options (e.g. secret containing certificate)\n    tls: {}\n\nupdateStrategy:\n  # -- Customize updateStrategy: RollingUpdate or OnDelete\n  type: RollingUpdate\n  rollingUpdate:\n    maxUnavailable: 0\n    maxSurge: 1\n\nreadinessProbe:\n  # -- The number of consecutive failures allowed before considering the probe as failed.\n  failureThreshold: 1\n  # -- The number of seconds to wait before starting the first probe.\n  initialDelaySeconds: 2\n  # -- The number of seconds to wait between consecutive probes.\n  periodSeconds: 10\n  # -- The minimum consecutive successes required to consider the probe successful.\n  successThreshold: 1\n  # -- The number of seconds to wait for a probe response before considering it as failed.\n  timeoutSeconds: 2\nlivenessProbe:\n  # -- The number of consecutive failures allowed before considering the probe as failed.\n  failureThreshold: 3\n  # -- The number of seconds to wait before starting the first probe.\n  initialDelaySeconds: 2\n  # -- The number of seconds to wait between consecutive probes.\n  periodSeconds: 10\n  # -- The minimum consecutive successes required to consider the probe successful.\n  successThreshold: 1\n  # -- The number of seconds to wait for a probe response before considering it as failed.\n  timeoutSeconds: 2\n\nproviders:\n  kubernetesCRD:\n    # -- Load Kubernetes IngressRoute provider\n    enabled: true\n    # -- Allows IngressRoute to reference resources in namespace other than theirs\n    allowCrossNamespace: true\n    # -- Allows to reference ExternalName services in IngressRoute\n    allowExternalNameServices: true\n    # -- Allows to return 503 when there is no endpoints available\n    allowEmptyServices: true\n    # ingressClass: traefik-internal\n    # labelSelector: environment=production,method=traefik\n    # -- Array of namespaces to watch. If left empty, Traefik watches all namespaces.\n    namespaces: []\n    # - \"default\"\n\n  kubernetesIngress:\n    # -- Load Kubernetes IngressRoute provider\n    enabled: true\n    # -- Allows to reference ExternalName services in Ingress\n    allowExternalNameServices: true\n    # -- Allows to return 503 when there is no endpoints available\n    allowEmptyServices: true\n    # ingressClass: traefik-internal\n    # labelSelector: environment=production,method=traefik\n    # -- Array of namespaces to watch. If left empty, Traefik watches all namespaces.\n    namespaces: []\n    # - \"default\"\n    # IP used for Kubernetes Ingress endpoints\n    publishedService:\n      enabled: true\n      # Published Kubernetes Service to copy status from. Format: namespace/servicename\n      # By default this Traefik service\n      # pathOverride: \"\"\n\n#\n# -- Add volumes to the traefik pod. The volume name will be passed to tpl.\n# This can be used to mount a cert pair or a configmap that holds a config.toml file.\n# After the volume has been mounted, add the configs into traefik by using the `additionalArguments` list below, eg:\n# `additionalArguments:\n# - \"--providers.file.filename=/config/dynamic.toml\"\n# - \"--ping\"\n# - \"--ping.entrypoint=web\"`\nvolumes: []\n# - name: public-cert\n#   mountPath: \"/certs\"\n#   type: secret\n# - name: '{{ printf \"%s-configs\" .Release.Name }}'\n#   mountPath: \"/config\"\n#   type: configMap\n\n# -- Additional volumeMounts to add to the Traefik container\nadditionalVolumeMounts: []\n# -- For instance when using a logshipper for access logs\n# - name: traefik-logs\n#   mountPath: /var/log/traefik\n\nlogs:\n  general:\n    # -- By default, the logs use a text format (common), but you can\n    # also ask for the json format in the format option\n    # format: json\n    # By default, the level is set to ERROR.\n    # -- Alternative logging levels are DEBUG, PANIC, FATAL, ERROR, WARN, and INFO.\n    level: INFO\n  access:\n    # -- To enable access logs\n    enabled: true\n    ## By default, logs are written using the Common Log Format (CLF) on stdout.\n    ## To write logs in JSON, use json in the format option.\n    ## If the given format is unsupported, the default (CLF) is used instead.\n    # format: json\n    # filePath: \"/var/log/traefik/access.log\n    ## To write the logs in an asynchronous fashion, specify a bufferingSize option.\n    ## This option represents the number of log lines Traefik will keep in memory before writing\n    ## them to the selected output. In some cases, this option can greatly help performances.\n    # bufferingSize: 100\n    ## Filtering\n    # -- https://docs.traefik.io/observability/access-logs/#filtering\n    filters: {}\n    # statuscodes: \"200,300-302\"\n    # retryattempts: true\n    # minduration: 10ms\n    fields:\n      general:\n        # -- Available modes: keep, drop, redact.\n        defaultmode: keep\n        # -- Names of the fields to limit.\n        names: {}\n        ## Examples:\n        # ClientUsername: drop\n      headers:\n        # -- Available modes: keep, drop, redact.\n        defaultmode: drop\n        # -- Names of the headers to limit.\n        names: {}\n        ## Examples:\n        # User-Agent: redact\n        # Authorization: drop\n        # Content-Type: keep\n\nmetrics:\n  ## -- Prometheus is enabled by default.\n  ## -- It can be disabled by setting \"prometheus: null\"\n  prometheus:\n    # -- Entry point used to expose metrics.\n    entryPoint: metrics\n    ## Enable metrics on entry points. Default=true\n    # addEntryPointsLabels: false\n    ## Enable metrics on routers. Default=false\n    # addRoutersLabels: true\n    ## Enable metrics on services. Default=true\n    # addServicesLabels: false\n    ## Buckets for latency metrics. Default=\"0.1,0.3,1.2,5.0\"\n    # buckets: \"0.5,1.0,2.5\"\n    ## When manualRouting is true, it disables the default internal router in\n    ## order to allow creating a custom router for prometheus@internal service.\n    # manualRouting: true\n  #  datadog:\n  #    ## Address instructs exporter to send metrics to datadog-agent at this address.\n  #    address: \"127.0.0.1:8125\"\n  #    ## The interval used by the exporter to push metrics to datadog-agent. Default=10s\n  #    # pushInterval: 30s\n  #    ## The prefix to use for metrics collection. Default=\"traefik\"\n  #    # prefix: traefik\n  #    ## Enable metrics on entry points. Default=true\n  #    # addEntryPointsLabels: false\n  #    ## Enable metrics on routers. Default=false\n  #    # addRoutersLabels: true\n  #    ## Enable metrics on services. Default=true\n  #    # addServicesLabels: false\n  #  influxdb:\n  #    ## Address instructs exporter to send metrics to influxdb at this address.\n  #    address: localhost:8089\n  #    ## InfluxDB's address protocol (udp or http). Default=\"udp\"\n  #    protocol: udp\n  #    ## InfluxDB database used when protocol is http. Default=\"\"\n  #    # database: \"\"\n  #    ## InfluxDB retention policy used when protocol is http. Default=\"\"\n  #    # retentionPolicy: \"\"\n  #    ## InfluxDB username (only with http). Default=\"\"\n  #    # username: \"\"\n  #    ## InfluxDB password (only with http). Default=\"\"\n  #    # password: \"\"\n  #    ## The interval used by the exporter to push metrics to influxdb. Default=10s\n  #    # pushInterval: 30s\n  #    ## Additional labels (influxdb tags) on all metrics.\n  #    # additionalLabels:\n  #    #   env: production\n  #    #   foo: bar\n  #    ## Enable metrics on entry points. Default=true\n  #    # addEntryPointsLabels: false\n  #    ## Enable metrics on routers. Default=false\n  #    # addRoutersLabels: true\n  #    ## Enable metrics on services. Default=true\n  #    # addServicesLabels: false\n  #  influxdb2:\n  #    ## Address instructs exporter to send metrics to influxdb v2 at this address.\n  #    address: localhost:8086\n  #    ## Token with which to connect to InfluxDB v2.\n  #    token: xxx\n  #    ## Organisation where metrics will be stored.\n  #    org: \"\"\n  #    ## Bucket where metrics will be stored.\n  #    bucket: \"\"\n  #    ## The interval used by the exporter to push metrics to influxdb. Default=10s\n  #    # pushInterval: 30s\n  #    ## Additional labels (influxdb tags) on all metrics.\n  #    # additionalLabels:\n  #    #   env: production\n  #    #   foo: bar\n  #    ## Enable metrics on entry points. Default=true\n  #    # addEntryPointsLabels: false\n  #    ## Enable metrics on routers. Default=false\n  #    # addRoutersLabels: true\n  #    ## Enable metrics on services. Default=true\n  #    # addServicesLabels: false\n  #  statsd:\n  #    ## Address instructs exporter to send metrics to statsd at this address.\n  #    address: localhost:8125\n  #    ## The interval used by the exporter to push metrics to influxdb. Default=10s\n  #    # pushInterval: 30s\n  #    ## The prefix to use for metrics collection. Default=\"traefik\"\n  #    # prefix: traefik\n  #    ## Enable metrics on entry points. Default=true\n  #    # addEntryPointsLabels: false\n  #    ## Enable metrics on routers. Default=false\n  #    # addRoutersLabels: true\n  #    ## Enable metrics on services. Default=true\n  #    # addServicesLabels: false\n  #  openTelemetry:\n  #    ## Address of the OpenTelemetry Collector to send metrics to.\n  #    address: \"localhost:4318\"\n  #    ## Enable metrics on entry points.\n  #    addEntryPointsLabels: true\n  #    ## Enable metrics on routers.\n  #    addRoutersLabels: true\n  #    ## Enable metrics on services.\n  #    addServicesLabels: true\n  #    ## Explicit boundaries for Histogram data points.\n  #    explicitBoundaries:\n  #      - \"0.1\"\n  #      - \"0.3\"\n  #      - \"1.2\"\n  #      - \"5.0\"\n  #    ## Additional headers sent with metrics by the reporter to the OpenTelemetry Collector.\n  #    headers:\n  #      foo: bar\n  #      test: test\n  #    ## Allows reporter to send metrics to the OpenTelemetry Collector without using a secured protocol.\n  #    insecure: true\n  #    ## Interval at which metrics are sent to the OpenTelemetry Collector.\n  #    pushInterval: 10s\n  #    ## Allows to override the default URL path used for sending metrics. This option has no effect when using gRPC transport.\n  #    path: /foo/v1/traces\n  #    ## Defines the TLS configuration used by the reporter to send metrics to the OpenTelemetry Collector.\n  #    tls:\n  #      ## The path to the certificate authority, it defaults to the system bundle.\n  #      ca: path/to/ca.crt\n  #      ## The path to the public certificate. When using this option, setting the key option is required.\n  #      cert: path/to/foo.cert\n  #      ## The path to the private key. When using this option, setting the cert option is required.\n  #      key: path/to/key.key\n  #      ## If set to true, the TLS connection accepts any certificate presented by the server regardless of the hostnames it covers.\n  #      insecureSkipVerify: true\n  #    ## This instructs the reporter to send metrics to the OpenTelemetry Collector using gRPC.\n  #    grpc: true\n\n  ## -- enable optional CRDs for Prometheus Operator\n  ##\n  ## Create a dedicated metrics service for use with ServiceMonitor\n  #  service:\n  #    enabled: false\n  #    labels: {}\n  #    annotations: {}\n  ## When set to true, it won't check if Prometheus Operator CRDs are deployed\n  #  disableAPICheck: false\n  #  serviceMonitor:\n  #    metricRelabelings: []\n  #      - sourceLabels: [__name__]\n  #        separator: ;\n  #        regex: ^fluentd_output_status_buffer_(oldest|newest)_.+\n  #        replacement: $1\n  #        action: drop\n  #    relabelings: []\n  #      - sourceLabels: [__meta_kubernetes_pod_node_name]\n  #        separator: ;\n  #        regex: ^(.*)$\n  #        targetLabel: nodename\n  #        replacement: $1\n  #        action: replace\n  #    jobLabel: traefik\n  #    interval: 30s\n  #    honorLabels: true\n  #    # (Optional)\n  #    # scrapeTimeout: 5s\n  #    # honorTimestamps: true\n  #    # enableHttp2: true\n  #    # followRedirects: true\n  #    # additionalLabels:\n  #    #   foo: bar\n  #    # namespace: \"another-namespace\"\n  #    # namespaceSelector: {}\n  #  prometheusRule:\n  #    additionalLabels: {}\n  #    namespace: \"another-namespace\"\n  #    rules:\n  #      - alert: TraefikDown\n  #        expr: up{job=\"traefik\"} == 0\n  #        for: 5m\n  #        labels:\n  #          context: traefik\n  #          severity: warning\n  #        annotations:\n  #          summary: \"Traefik Down\"\n  #          description: \"{{ $labels.pod }} on {{ $labels.nodename }} is down\"\n\n## Tracing\n# -- https://doc.traefik.io/traefik/observability/tracing/overview/\ntracing: {}\n# instana:\n#   localAgentHost: 127.0.0.1\n#   localAgentPort: 42699\n#   logLevel: info\n#   enableAutoProfile: true\n# datadog:\n#   localAgentHostPort: 127.0.0.1:8126\n#   debug: false\n#   globalTag: \"\"\n#   prioritySampling: false\n# jaeger:\n#   samplingServerURL: http://localhost:5778/sampling\n#   samplingType: const\n#   samplingParam: 1.0\n#   localAgentHostPort: 127.0.0.1:6831\n#   gen128Bit: false\n#   propagation: jaeger\n#   traceContextHeaderName: uber-trace-id\n#   disableAttemptReconnecting: true\n#   collector:\n#      endpoint: \"\"\n#      user: \"\"\n#      password: \"\"\n# zipkin:\n#   httpEndpoint: http://localhost:9411/api/v2/spans\n#   sameSpan: false\n#   id128Bit: true\n#   sampleRate: 1.0\n# haystack:\n#   localAgentHost: 127.0.0.1\n#   localAgentPort: 35000\n#   globalTag: \"\"\n#   traceIDHeaderName: \"\"\n#   parentIDHeaderName: \"\"\n#   spanIDHeaderName: \"\"\n#   baggagePrefixHeaderName: \"\"\n# elastic:\n#   serverURL: http://localhost:8200\n#   secretToken: \"\"\n#   serviceEnvironment: \"\"\n\n# -- Global command arguments to be passed to all traefik's pods\nglobalArguments:\n- \"--global.checknewversion\"\n- \"--global.sendanonymoususage\"\n- \"--global.sendanonymoususage=false\"\n- \"--global.checknewversion=false\"\n#\n# Configure Traefik static configuration\n# -- Additional arguments to be passed at Traefik's binary\n# All available options available on https://docs.traefik.io/reference/static-configuration/cli/\n## Use curly braces to pass values: `helm install --set=\"additionalArguments={--providers.kubernetesingress.ingressclass=traefik-internal,--log.level=DEBUG}\"`\nadditionalArguments:\n- \"--providers.kubernetesingress.ingressclass=ingress-traefik\"\n- \"--log.level=DEBUG\"\n- \"--providers.kubernetescrd\"\n\n# -- Environment variables to be passed to Traefik's binary\nenv: []\n# - name: SOME_VAR\n#   value: some-var-value\n# - name: SOME_VAR_FROM_CONFIG_MAP\n#   valueFrom:\n#     configMapRef:\n#       name: configmap-name\n#       key: config-key\n# - name: SOME_SECRET\n#   valueFrom:\n#     secretKeyRef:\n#       name: secret-name\n#       key: secret-key\n\n# -- Environment variables to be passed to Traefik's binary from configMaps or secrets\nenvFrom: []\n# - configMapRef:\n#     name: config-map-name\n# - secretRef:\n#     name: secret-name\n\nports:\n  traefik:\n    port: 9000\n    # -- Use hostPort if set.\n    # hostPort: 9000\n    #\n    # -- Use hostIP if set. If not set, Kubernetes will default to 0.0.0.0, which\n    # means it's listening on all your interfaces and all your IPs. You may want\n    # to set this value if you need traefik to listen on specific interface\n    # only.\n    # hostIP: 192.168.100.10\n\n    # Defines whether the port is exposed if service.type is LoadBalancer or\n    # NodePort.\n    #\n    # -- You SHOULD NOT expose the traefik port on production deployments.\n    # If you want to access it from outside your cluster,\n    # use `kubectl port-forward` or create a secure ingress\n    expose:\n      default: true\n    # -- The exposed port for this service\n    exposedPort: 9000\n    # -- The port protocol (TCP/UDP)\n    protocol: TCP\n  web:\n    ## -- Enable this entrypoint as a default entrypoint. When a service doesn't explicity set an entrypoint it will only use this entrypoint.\n    # asDefault: true\n    port: 8000\n    # hostPort: 8000\n    # containerPort: 8000\n    expose:\n      default: true\n    exposedPort: 8000\n    ## -- Different target traefik port on the cluster, useful for IP type LB\n    # targetPort: 80\n    # The port protocol (TCP/UDP)\n    protocol: TCP\n    # -- Use nodeport if set. This is useful if you have configured Traefik in a\n    # LoadBalancer.\n    # nodePort: 32080\n    # Port Redirections\n    # Added in 2.2, you can make permanent redirects via entrypoints.\n    # https://docs.traefik.io/routing/entrypoints/#redirection\n    # redirectTo: websecure\n    #\n    # Trust forwarded  headers information (X-Forwarded-*).\n    # forwardedHeaders:\n    #   trustedIPs: []\n    #   insecure: false\n    #\n    # Enable the Proxy Protocol header parsing for the entry point\n    # proxyProtocol:\n    #   trustedIPs: []\n    #   insecure: false\n  websecure:\n    ## -- Enable this entrypoint as a default entrypoint. When a service doesn't explicity set an entrypoint it will only use this entrypoint.\n    # asDefault: true\n    port: 8443\n    # hostPort: 8443\n    # containerPort: 8443\n    expose:\n      default: true\n    exposedPort: 8443\n    ## -- Different target traefik port on the cluster, useful for IP type LB\n    # targetPort: 80\n    ## -- The port protocol (TCP/UDP)\n    protocol: TCP\n    # nodePort: 32443\n    ## -- Specify an application protocol. This may be used as a hint for a Layer 7 load balancer.\n    # appProtocol: https\n    #\n    ## -- Enable HTTP/3 on the entrypoint\n    ## Enabling it will also enable http3 experimental feature\n    ## https://doc.traefik.io/traefik/routing/entrypoints/#http3\n    ## There are known limitations when trying to listen on same ports for\n    ## TCP \u0026 UDP (Http3). There is a workaround in this chart using dual Service.\n    ## https://github.com/kubernetes/kubernetes/issues/47249#issuecomment-587960741\n    http3:\n      enabled: false\n    # advertisedPort: 4443\n    #\n    ## -- Trust forwarded  headers information (X-Forwarded-*).\n    #forwardedHeaders:\n    #  trustedIPs: []\n    #  insecure: false\n    #\n    ## -- Enable the Proxy Protocol header parsing for the entry point\n    #proxyProtocol:\n    #  trustedIPs: []\n    #  insecure: false\n    #\n    ## Set TLS at the entrypoint\n    ## https://doc.traefik.io/traefik/routing/entrypoints/#tls\n    tls:\n      enabled: true\n      # this is the name of a TLSOption definition\n      options: \"\"\n      certResolver: \"\"\n      domains: []\n      # - main: example.com\n      #   sans:\n      #     - foo.example.com\n      #     - bar.example.com\n    #\n    # -- One can apply Middlewares on an entrypoint\n    # https://doc.traefik.io/traefik/middlewares/overview/\n    # https://doc.traefik.io/traefik/routing/entrypoints/#middlewares\n    # -- /!\\ It introduces here a link between your static configuration and your dynamic configuration /!\\\n    # It follows the provider naming convention: https://doc.traefik.io/traefik/providers/overview/#provider-namespace\n    # middlewares:\n    #   - namespace-name1@kubernetescrd\n    #   - namespace-name2@kubernetescrd\n    middlewares: []\n  metrics:\n    # -- When using hostNetwork, use another port to avoid conflict with node exporter:\n    # https://github.com/prometheus/prometheus/wiki/Default-port-allocations\n    port: 9100\n    # hostPort: 9100\n    # Defines whether the port is exposed if service.type is LoadBalancer or\n    # NodePort.\n    #\n    # -- You may not want to expose the metrics port on production deployments.\n    # If you want to access it from outside of your cluster,\n    # use `kubectl port-forward` or create a secure ingress\n    expose:\n      default: true\n    # -- The exposed port for this service\n    exposedPort: 9100\n    # -- The port protocol (TCP/UDP)\n    protocol: TCP\n\n  telegraf:\n    port: 8101\n    expose:\n      default: true\n    exposedPort: 8101\n    protocol: TCP\n\n  jupyterhub:\n    port: 8103\n    expose:\n      default: true\n    exposedPort: 8103\n    protocol: TCP\n\n  mongodb:\n    port: 27017\n    expose:\n      default: true\n    exposedPort: 27017\n    protocol: TCP\n\n  mongodbauth:\n    port: 27019\n    expose:\n      default: true\n    exposedPort: 27019\n    protocol: TCP\n\n  redis:\n    port: 6379\n    expose:\n      default: true\n    exposedPort: 6379\n    protocol: TCP\n\n  mysql:\n    port: 3306\n    expose:\n      default: true\n    exposedPort: 3306\n    protocol: TCP\n\n\n\n  mysqlaws:\n    port: 4306\n\n    expose:\n      default: true\n    exposedPort: 4306\n    protocol: TCP\n\n  zipkin:\n    port: 19411\n\n    expose:\n      default: true\n    exposedPort: 19411\n    protocol: TCP\n\n  prometheus:\n    port: 9090\n\n    expose:\n      default: true\n    exposedPort: 9090\n    protocol: TCP\n\n  kibana:\n    port: 5601\n\n    expose:\n      default: true\n    exposedPort: 5601\n    protocol: TCP\n\n  airflow:\n    port: 9999\n    expose:\n      default: true\n    exposedPort: 9999\n    protocol: TCP\n\n\n  tempo:\n    port: 9600\n\n    expose:\n      default: true\n    exposedPort: 9600\n    protocol: TCP\n\n  tempozipkin:\n    port: 9700\n\n    expose:\n      default: true\n    exposedPort: 9700\n    protocol: TCP\n\n  apm:\n    port: 8200\n\n    expose:\n      default: true\n    exposedPort: 8200\n    protocol: TCP\n\n  minio:\n    port: 8102\n\n    expose:\n      default: true\n    exposedPort: 8102\n    protocol: TCP\n\n  influx:\n    port: 8079\n    expose:\n      default: true\n    exposedPort: 8079\n    protocol: TCP\n\n  telemetry6831:\n    port: 6831\n\n    expose:\n      default: true\n    exposedPort: 6831\n    protocol: UDP\n\n  telemetry14250:\n    port: 14250\n\n    expose:\n      default: true\n    exposedPort: 14250\n    protocol: TCP\n\n  telemetry14268:\n    port: 14268\n\n    expose:\n      default: true\n    exposedPort: 14268\n    protocol: TCP\n\n  telemetry4317:\n    port: 4317\n\n    expose:\n      default: true\n    exposedPort: 4317\n    protocol: TCP\n\n  telemetry4318:\n    port: 4318\n\n    expose:\n      default: true\n    exposedPort: 4318\n    protocol: TCP\n\n\n  telemetry9411:\n    port: 9411\n\n    expose:\n      default: true\n    exposedPort: 9411\n    protocol: TCP\n\n  loki:\n    port: 9477\n    expose:\n      default: true\n    exposedPort: 9477\n    protocol: TCP\n\n  tcp1:\n    port: 8080\n\n    expose:\n      default: true\n    exposedPort: 8080\n    protocol: TCP\n\n  tcp2:\n    port: 8081\n\n    expose:\n      default: true\n    exposedPort: 8081\n    protocol: TCP\n\n  tcp3:\n    port: 8082\n\n    expose:\n      default: true\n    exposedPort: 8082\n    protocol: TCP\n\n  tcp4:\n    port: 8083\n\n    expose:\n      default: true\n    exposedPort: 8083\n    protocol: TCP\n\n  tcp5:\n    port: 8084\n\n    expose:\n      default: true\n    exposedPort: 8084\n    protocol: TCP\n\n  tcp6:\n    port: 8085\n\n    expose:\n      default: true\n    exposedPort: 8085\n    protocol: TCP\n\n  tcp7:\n    port: 8086\n\n    expose:\n      default: true\n    exposedPort: 8086\n    protocol: TCP\n\n  tcp8:\n    port: 8087\n\n    expose:\n      default: true\n    exposedPort: 8087\n    protocol: TCP\n\n  tcp9:\n    port: 8088\n\n    expose:\n      default: true\n    exposedPort: 8088\n    protocol: TCP\n\n  tcp10:\n    port: 8089\n\n    expose:\n      default: true\n    exposedPort: 8089\n    protocol: TCP\n\n  tcp11:\n    port: 8090\n\n    expose:\n      default: true\n    exposedPort: 8090\n    protocol: TCP\n\n  tcp12:\n    port: 8091\n\n    expose:\n      default: true\n    exposedPort: 8091\n    protocol: TCP\n\n  tcp13:\n    port: 8092\n\n    expose:\n      default: true\n    exposedPort: 8092\n    protocol: TCP\n\n  tcp14:\n    port: 8093\n\n    expose:\n      default: true\n    exposedPort: 8093\n    protocol: TCP\n\n  tcp15:\n    port: 8094\n\n    expose:\n      default: true\n    exposedPort: 8094\n    protocol: TCP\n\n  tcp16:\n    port: 8095\n\n    expose:\n      default: true\n    exposedPort: 8095\n    protocol: TCP\n\n  tcp17:\n    port: 8096\n\n    expose:\n      default: true\n    exposedPort: 8096\n    protocol: TCP\n\n  tcp18:\n    port: 8097\n\n    expose:\n      default: true\n    exposedPort: 8097\n    protocol: TCP\n\n  tcp19:\n    port: 8098\n\n    expose:\n      default: true\n    exposedPort: 8098\n    protocol: TCP\n\n  tcp20:\n    port: 8099\n\n    expose:\n      default: true\n    exposedPort: 8099\n    protocol: TCP\n\n  udp1:\n    port: 8001\n\n    expose:\n      default: true\n    exposedPort: 8001\n    protocol: UDP\n\n  udp2:\n    port: 8002\n\n    expose:\n      default: true\n    exposedPort: 8002\n    protocol: UDP\n\n  udp3:\n    port: 8003\n\n    expose:\n      default: true\n    exposedPort: 8003\n    protocol: UDP\n\n\n# -- TLS Options are created as TLSOption CRDs\n# https://doc.traefik.io/traefik/https/tls/#tls-options\n# When using `labelSelector`, you'll need to set labels on tlsOption accordingly.\n# Example:\n# tlsOptions:\n#   default:\n#     labels: {}\n#     sniStrict: true\n#     preferServerCipherSuites: true\n#   customOptions:\n#     labels: {}\n#     curvePreferences:\n#       - CurveP521\n#       - CurveP384\ntlsOptions: {}\n\n# -- TLS Store are created as TLSStore CRDs. This is useful if you want to set a default certificate\n# https://doc.traefik.io/traefik/https/tls/#default-certificate\n# Example:\n# tlsStore:\n#   default:\n#     defaultCertificate:\n#       secretName: tls-cert\ntlsStore: {}\n\nservice:\n  enabled: true\n  ## -- Single service is using `MixedProtocolLBService` feature gate.\n  ## -- When set to false, it will create two Service, one for TCP and one for UDP.\n  single: true\n  type: LoadBalancer\n  # -- Additional annotations applied to both TCP and UDP services (e.g. for cloud provider specific config)\n  annotations: {}\n  # -- Additional annotations for TCP service only\n  annotationsTCP: {}\n  # -- Additional annotations for UDP service only\n  annotationsUDP: {}\n  # -- Additional service labels (e.g. for filtering Service by custom labels)\n  labels: {}\n  # -- Additional entries here will be added to the service spec.\n  # -- Cannot contain type, selector or ports entries.\n  spec: {}\n  # externalTrafficPolicy: Cluster\n  # loadBalancerIP: \"1.2.3.4\"\n  # clusterIP: \"2.3.4.5\"\n  loadBalancerSourceRanges: []\n  # - 192.168.0.1/32\n  # - 172.16.0.0/16\n  ## -- Class of the load balancer implementation\n  # loadBalancerClass: service.k8s.aws/nlb\n  externalIPs:\n  - 192.168.36.90\n  ## One of SingleStack, PreferDualStack, or RequireDualStack.\n  # ipFamilyPolicy: SingleStack\n  ## List of IP families (e.g. IPv4 and/or IPv6).\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/dual-stack/#services\n  # ipFamilies:\n  #   - IPv4\n  #   - IPv6\n  ##\n  ## -- An additionnal and optional internal Service.\n  ## Same parameters as external Service\n  # internal:\n  #   type: ClusterIP\n  #   # labels: {}\n  #   # annotations: {}\n  #   # spec: {}\n  #   # loadBalancerSourceRanges: []\n  #   # externalIPs: []\n  #   # ipFamilies: [ \"IPv4\",\"IPv6\" ]\n\nautoscaling:\n  # -- Create HorizontalPodAutoscaler object.\n  enabled: false\n#   minReplicas: 1\n#   maxReplicas: 10\n#   metrics:\n#   - type: Resource\n#     resource:\n#       name: cpu\n#       target:\n#         type: Utilization\n#         averageUtilization: 60\n#   - type: Resource\n#     resource:\n#       name: memory\n#       target:\n#         type: Utilization\n#         averageUtilization: 60\n#   behavior:\n#     scaleDown:\n#       stabilizationWindowSeconds: 300\n#       policies:\n#       - type: Pods\n#         value: 1\n#         periodSeconds: 60\n\npersistence:\n  # -- Enable persistence using Persistent Volume Claims\n  # ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n  # It can be used to store TLS certificates, see `storage` in certResolvers\n  enabled: true\n  name: data\n  #  existingClaim: \"\"\n  accessMode: ReadWriteOnce\n  size: 512Mi\n  # storageClass: \"\"\n  # volumeName: \"\"\n  path: /data\n  annotations: {}\n  # -- Only mount a subpath of the Volume into the pod\n  # subPath: \"\"\n\n# -- Certificates resolvers configuration\ncertResolvers: {}\n#   letsencrypt:\n#     # for challenge options cf. https://doc.traefik.io/traefik/https/acme/\n#     email: email@example.com\n#     dnsChallenge:\n#       # also add the provider's required configuration under env\n#       # or expand then from secrets/configmaps with envfrom\n#       # cf. https://doc.traefik.io/traefik/https/acme/#providers\n#       provider: digitalocean\n#       # add futher options for the dns challenge as needed\n#       # cf. https://doc.traefik.io/traefik/https/acme/#dnschallenge\n#       delayBeforeCheck: 30\n#       resolvers:\n#         - 1.1.1.1\n#         - 8.8.8.8\n#     tlsChallenge: true\n#     httpChallenge:\n#       entryPoint: \"web\"\n#     # It has to match the path with a persistent volume\n#     storage: /data/acme.json\n\n# -- If hostNetwork is true, runs traefik in the host network namespace\n# To prevent unschedulabel pods due to port collisions, if hostNetwork=true\n# and replicas\u003e1, a pod anti-affinity is recommended and will be set if the\n# affinity is left as default.\nhostNetwork: false\n\n# -- Whether Role Based Access Control objects like roles and rolebindings should be created\nrbac:\n  enabled: true\n  # If set to false, installs ClusterRole and ClusterRoleBinding so Traefik can be used across namespaces.\n  # If set to true, installs Role and RoleBinding. Providers will only watch target namespace.\n  namespaced: false\n  # Enable user-facing roles\n  # https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles\n  # aggregateTo: [ \"admin\" ]\n\n# -- Enable to create a PodSecurityPolicy and assign it to the Service Account via RoleBinding or ClusterRoleBinding\npodSecurityPolicy:\n  enabled: false\n\n# -- The service account the pods will use to interact with the Kubernetes API\nserviceAccount:\n  # If set, an existing service account is used\n  # If not set, a service account is created automatically using the fullname template\n  name: \"\"\n\n# -- Additional serviceAccount annotations (e.g. for oidc authentication)\nserviceAccountAnnotations: {}\n\n# -- The resources parameter defines CPU and memory requirements and limits for Traefik's containers.\nresources: {}\n# requests:\n#   cpu: \"100m\"\n#   memory: \"50Mi\"\n# limits:\n#   cpu: \"300m\"\n#   memory: \"150Mi\"\n\n# -- This example pod anti-affinity forces the scheduler to put traefik pods\n# -- on nodes where no other traefik pods are scheduled.\n# It should be used when hostNetwork: true to prevent port conflicts\naffinity:\n  nodeAffinity:\n    requiredDuringSchedulingIgnoredDuringExecution:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - node3673\n#  podAntiAffinity:\n#    requiredDuringSchedulingIgnoredDuringExecution:\n#      - labelSelector:\n#          matchLabels:\n#            app.kubernetes.io/name: '{{ template \"traefik.name\" . }}'\n#            app.kubernetes.io/instance: '{{ .Release.Name }}-{{ .Release.Namespace }}'\n#        topologyKey: kubernetes.io/hostname\n\n# -- nodeSelector is the simplest recommended form of node selection constraint.\n# nodeSelector:\n#   node-type: \"master\"\n\n#  kubernetes.io/hostname: \"kubenode-master-01\"\n# -- Tolerations allow the scheduler to schedule pods with matching taints.\ntolerations:\n- key: node-role.kubernetes.io/control-plane\n  operator: Exists\n  effect: NoSchedule\n# -- You can use topology spread constraints to control \n# how Pods are spread across your cluster among failure-domains.\ntopologySpreadConstraints: []\n# This example topologySpreadConstraints forces the scheduler to put traefik pods\n# on nodes where no other traefik pods are scheduled.\n#  - labelSelector:\n#      matchLabels:\n#        app: '{{ template \"traefik.name\" . }}'\n#    maxSkew: 1\n#    topologyKey: kubernetes.io/hostname\n#    whenUnsatisfiable: DoNotSchedule\n\n# -- Pods can have priority.\n# -- Priority indicates the importance of a Pod relative to other Pods.\npriorityClassName: \"\"\n\n# -- Set the container security context\n# -- To run the container with ports below 1024 this will need to be adjust to run as root\nsecurityContext:\n  capabilities:\n    drop: [ALL]\n  readOnlyRootFilesystem: true\n\npodSecurityContext:\n  # /!\\ When setting fsGroup, Kubernetes will recursively changes ownership and\n  # permissions for the contents of each volume to match the fsGroup. This can\n  # be an issue when storing sensitive content like TLS Certificates /!\\\n  # fsGroup: 65532\n  # -- Specifies the policy for changing ownership and permissions of volume contents to match the fsGroup.\n  fsGroupChangePolicy: \"OnRootMismatch\"\n  # -- The ID of the group for all containers in the pod to run as.\n  runAsGroup: 65532\n  # -- Specifies whether the containers should run as a non-root user.\n  runAsNonRoot: true\n  # -- The ID of the user for all containers in the pod to run as.\n  runAsUser: 65532\n\n#\n# -- Extra objects to deploy (value evaluated as a template)\n#\n# In some cases, it can avoid the need for additional, extended or adhoc deployments.\n# See #595 for more details and traefik/tests/values/extra.yaml for example.\nextraObjects: []\n\n# This will override the default Release Namespace for Helm.\n# It will not affect optional CRDs such as `ServiceMonitor` and `PrometheusRules`\n# namespaceOverride: traefik\n#\n## -- This will override the default app.kubernetes.io/instance label for all Objects.\n# instanceLabelOverride: traefik\n"
            ],
            "verify": false,
            "version": "28.0.0",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_namespace.traefik-namespace"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_ingress_v1",
      "name": "example_ingress",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "datalake/airflow",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 1,
                "labels": {},
                "name": "airflow",
                "namespace": "datalake",
                "resource_version": "197950",
                "uid": "cf07b150-d10e-42a4-a5da-2b9fcd82a45f"
              }
            ],
            "spec": [
              {
                "default_backend": [
                  {
                    "resource": [],
                    "service": [
                      {
                        "name": "airflow-prd-web",
                        "port": [
                          {
                            "name": "",
                            "number": 8080
                          }
                        ]
                      }
                    ]
                  }
                ],
                "ingress_class_name": "ingress-traefik",
                "rule": [],
                "tls": []
              }
            ],
            "status": [
              {
                "load_balancer": [
                  {
                    "ingress": []
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_load_balancer": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "first_metallb_bgp",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "metallb.io/v1beta1",
                "kind": "L2Advertisement",
                "metadata": {
                  "name": "external",
                  "namespace": "metalb"
                },
                "spec": {
                  "interfaces": [
                    "ens160"
                  ],
                  "ipAddressPools": [
                    "external-pool"
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "interfaces": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "ipAddressPools": [
                        "tuple",
                        [
                          "string"
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "metallb.io/v1beta1",
                "kind": "L2Advertisement",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "external",
                  "namespace": "metalb",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "interfaces": [
                    "ens160"
                  ],
                  "ipAddressPoolSelectors": null,
                  "ipAddressPools": [
                    "external-pool"
                  ],
                  "nodeSelectors": null
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "interfaces": [
                        "list",
                        "string"
                      ],
                      "ipAddressPoolSelectors": [
                        "list",
                        [
                          "object",
                          {
                            "matchExpressions": [
                              "list",
                              [
                                "object",
                                {
                                  "key": "string",
                                  "operator": "string",
                                  "values": [
                                    "list",
                                    "string"
                                  ]
                                }
                              ]
                            ],
                            "matchLabels": [
                              "map",
                              "string"
                            ]
                          }
                        ]
                      ],
                      "ipAddressPools": [
                        "list",
                        "string"
                      ],
                      "nodeSelectors": [
                        "list",
                        [
                          "object",
                          {
                            "matchExpressions": [
                              "list",
                              [
                                "object",
                                {
                                  "key": "string",
                                  "operator": "string",
                                  "values": [
                                    "list",
                                    "string"
                                  ]
                                }
                              ]
                            ],
                            "matchLabels": [
                              "map",
                              "string"
                            ]
                          }
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": [],
          "dependencies": [
            "helm_release.metalb",
            "kubernetes_namespace.metalb-namespace"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "first_metallb_pooladdress",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "metallb.io/v1beta1",
                "kind": "IPAddressPool",
                "metadata": {
                  "name": "external-pool",
                  "namespace": "metalb"
                },
                "spec": {
                  "addresses": [
                    "192.168.10.0/24"
                  ],
                  "autoAssign": true
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "addresses": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "autoAssign": "bool"
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "metallb.io/v1beta1",
                "kind": "IPAddressPool",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "external-pool",
                  "namespace": "metalb",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "addresses": [
                    "192.168.10.0/24"
                  ],
                  "autoAssign": true,
                  "avoidBuggyIPs": false,
                  "serviceAllocation": {
                    "namespaceSelectors": null,
                    "namespaces": null,
                    "priority": null,
                    "serviceSelectors": null
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "addresses": [
                        "list",
                        "string"
                      ],
                      "autoAssign": "bool",
                      "avoidBuggyIPs": "bool",
                      "serviceAllocation": [
                        "object",
                        {
                          "namespaceSelectors": [
                            "list",
                            [
                              "object",
                              {
                                "matchExpressions": [
                                  "list",
                                  [
                                    "object",
                                    {
                                      "key": "string",
                                      "operator": "string",
                                      "values": [
                                        "list",
                                        "string"
                                      ]
                                    }
                                  ]
                                ],
                                "matchLabels": [
                                  "map",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "namespaces": [
                            "list",
                            "string"
                          ],
                          "priority": "number",
                          "serviceSelectors": [
                            "list",
                            [
                              "object",
                              {
                                "matchExpressions": [
                                  "list",
                                  [
                                    "object",
                                    {
                                      "key": "string",
                                      "operator": "string",
                                      "values": [
                                        "list",
                                        "string"
                                      ]
                                    }
                                  ]
                                ],
                                "matchLabels": [
                                  "map",
                                  "string"
                                ]
                              }
                            ]
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": [],
          "dependencies": [
            "helm_release.metalb",
            "kubernetes_namespace.metalb-namespace"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "ingressroutetcp_airflow",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "name": "airflow",
                  "namespace": "datalake"
                },
                "spec": {
                  "entryPoints": [
                    "airflow"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "services": [
                        {
                          "name": "airflow-v3-webserver",
                          "port": 8080
                        }
                      ]
                    }
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "routes": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "match": "string",
                              "services": [
                                "tuple",
                                [
                                  [
                                    "object",
                                    {
                                      "name": "string",
                                      "port": "number"
                                    }
                                  ]
                                ]
                              ]
                            }
                          ]
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "airflow",
                  "namespace": "datalake",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "entryPoints": [
                    "airflow"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "middlewares": null,
                      "priority": null,
                      "services": [
                        {
                          "name": "airflow-v3-webserver",
                          "namespace": null,
                          "nativeLB": null,
                          "port": "8080",
                          "proxyProtocol": {
                            "version": null
                          },
                          "serversTransport": null,
                          "terminationDelay": null,
                          "tls": null,
                          "weight": null
                        }
                      ],
                      "syntax": null
                    }
                  ],
                  "tls": {
                    "certResolver": null,
                    "domains": null,
                    "options": {
                      "name": null,
                      "namespace": null
                    },
                    "passthrough": null,
                    "secretName": null,
                    "store": {
                      "name": null,
                      "namespace": null
                    }
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "list",
                        "string"
                      ],
                      "routes": [
                        "list",
                        [
                          "object",
                          {
                            "match": "string",
                            "middlewares": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string"
                                }
                              ]
                            ],
                            "priority": "number",
                            "services": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string",
                                  "nativeLB": "bool",
                                  "port": "string",
                                  "proxyProtocol": [
                                    "object",
                                    {
                                      "version": "number"
                                    }
                                  ],
                                  "serversTransport": "string",
                                  "terminationDelay": "number",
                                  "tls": "bool",
                                  "weight": "number"
                                }
                              ]
                            ],
                            "syntax": "string"
                          }
                        ]
                      ],
                      "tls": [
                        "object",
                        {
                          "certResolver": "string",
                          "domains": [
                            "list",
                            [
                              "object",
                              {
                                "main": "string",
                                "sans": [
                                  "list",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "options": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ],
                          "passthrough": "bool",
                          "secretName": "string",
                          "store": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "ingressroutetcp_influxdb",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "name": "influx",
                  "namespace": "datalake"
                },
                "spec": {
                  "entryPoints": [
                    "influx"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "services": [
                        {
                          "name": "influxdb-influxdb2",
                          "port": 80
                        }
                      ]
                    }
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "routes": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "match": "string",
                              "services": [
                                "tuple",
                                [
                                  [
                                    "object",
                                    {
                                      "name": "string",
                                      "port": "number"
                                    }
                                  ]
                                ]
                              ]
                            }
                          ]
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "influx",
                  "namespace": "datalake",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "entryPoints": [
                    "influx"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "middlewares": null,
                      "priority": null,
                      "services": [
                        {
                          "name": "influxdb-influxdb2",
                          "namespace": null,
                          "nativeLB": null,
                          "port": "80",
                          "proxyProtocol": {
                            "version": null
                          },
                          "serversTransport": null,
                          "terminationDelay": null,
                          "tls": null,
                          "weight": null
                        }
                      ],
                      "syntax": null
                    }
                  ],
                  "tls": {
                    "certResolver": null,
                    "domains": null,
                    "options": {
                      "name": null,
                      "namespace": null
                    },
                    "passthrough": null,
                    "secretName": null,
                    "store": {
                      "name": null,
                      "namespace": null
                    }
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "list",
                        "string"
                      ],
                      "routes": [
                        "list",
                        [
                          "object",
                          {
                            "match": "string",
                            "middlewares": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string"
                                }
                              ]
                            ],
                            "priority": "number",
                            "services": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string",
                                  "nativeLB": "bool",
                                  "port": "string",
                                  "proxyProtocol": [
                                    "object",
                                    {
                                      "version": "number"
                                    }
                                  ],
                                  "serversTransport": "string",
                                  "terminationDelay": "number",
                                  "tls": "bool",
                                  "weight": "number"
                                }
                              ]
                            ],
                            "syntax": "string"
                          }
                        ]
                      ],
                      "tls": [
                        "object",
                        {
                          "certResolver": "string",
                          "domains": [
                            "list",
                            [
                              "object",
                              {
                                "main": "string",
                                "sans": [
                                  "list",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "options": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ],
                          "passthrough": "bool",
                          "secretName": "string",
                          "store": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "ingressroutetcp_loki",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "name": "loki",
                  "namespace": "monitoring"
                },
                "spec": {
                  "entryPoints": [
                    "loki"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "services": [
                        {
                          "name": "loki-loki-distributed-gateway",
                          "port": 80
                        }
                      ]
                    }
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "routes": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "match": "string",
                              "services": [
                                "tuple",
                                [
                                  [
                                    "object",
                                    {
                                      "name": "string",
                                      "port": "number"
                                    }
                                  ]
                                ]
                              ]
                            }
                          ]
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "loki",
                  "namespace": "monitoring",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "entryPoints": [
                    "loki"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "middlewares": null,
                      "priority": null,
                      "services": [
                        {
                          "name": "loki-loki-distributed-gateway",
                          "namespace": null,
                          "nativeLB": null,
                          "port": "80",
                          "proxyProtocol": {
                            "version": null
                          },
                          "serversTransport": null,
                          "terminationDelay": null,
                          "tls": null,
                          "weight": null
                        }
                      ],
                      "syntax": null
                    }
                  ],
                  "tls": {
                    "certResolver": null,
                    "domains": null,
                    "options": {
                      "name": null,
                      "namespace": null
                    },
                    "passthrough": null,
                    "secretName": null,
                    "store": {
                      "name": null,
                      "namespace": null
                    }
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "list",
                        "string"
                      ],
                      "routes": [
                        "list",
                        [
                          "object",
                          {
                            "match": "string",
                            "middlewares": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string"
                                }
                              ]
                            ],
                            "priority": "number",
                            "services": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string",
                                  "nativeLB": "bool",
                                  "port": "string",
                                  "proxyProtocol": [
                                    "object",
                                    {
                                      "version": "number"
                                    }
                                  ],
                                  "serversTransport": "string",
                                  "terminationDelay": "number",
                                  "tls": "bool",
                                  "weight": "number"
                                }
                              ]
                            ],
                            "syntax": "string"
                          }
                        ]
                      ],
                      "tls": [
                        "object",
                        {
                          "certResolver": "string",
                          "domains": [
                            "list",
                            [
                              "object",
                              {
                                "main": "string",
                                "sans": [
                                  "list",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "options": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ],
                          "passthrough": "bool",
                          "secretName": "string",
                          "store": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "ingressroutetcp_minio",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "name": "minio",
                  "namespace": "datalake"
                },
                "spec": {
                  "entryPoints": [
                    "minio"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "services": [
                        {
                          "name": "minio",
                          "port": 443
                        }
                      ]
                    }
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "routes": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "match": "string",
                              "services": [
                                "tuple",
                                [
                                  [
                                    "object",
                                    {
                                      "name": "string",
                                      "port": "number"
                                    }
                                  ]
                                ]
                              ]
                            }
                          ]
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "minio",
                  "namespace": "datalake",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "entryPoints": [
                    "minio"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "middlewares": null,
                      "priority": null,
                      "services": [
                        {
                          "name": "minio",
                          "namespace": null,
                          "nativeLB": null,
                          "port": "443",
                          "proxyProtocol": {
                            "version": null
                          },
                          "serversTransport": null,
                          "terminationDelay": null,
                          "tls": null,
                          "weight": null
                        }
                      ],
                      "syntax": null
                    }
                  ],
                  "tls": {
                    "certResolver": null,
                    "domains": null,
                    "options": {
                      "name": null,
                      "namespace": null
                    },
                    "passthrough": null,
                    "secretName": null,
                    "store": {
                      "name": null,
                      "namespace": null
                    }
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "list",
                        "string"
                      ],
                      "routes": [
                        "list",
                        [
                          "object",
                          {
                            "match": "string",
                            "middlewares": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string"
                                }
                              ]
                            ],
                            "priority": "number",
                            "services": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string",
                                  "nativeLB": "bool",
                                  "port": "string",
                                  "proxyProtocol": [
                                    "object",
                                    {
                                      "version": "number"
                                    }
                                  ],
                                  "serversTransport": "string",
                                  "terminationDelay": "number",
                                  "tls": "bool",
                                  "weight": "number"
                                }
                              ]
                            ],
                            "syntax": "string"
                          }
                        ]
                      ],
                      "tls": [
                        "object",
                        {
                          "certResolver": "string",
                          "domains": [
                            "list",
                            [
                              "object",
                              {
                                "main": "string",
                                "sans": [
                                  "list",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "options": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ],
                          "passthrough": "bool",
                          "secretName": "string",
                          "store": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "ingressroutetcp_mongo",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "name": "mongodb",
                  "namespace": "datalake"
                },
                "spec": {
                  "entryPoints": [
                    "mongodb"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "services": [
                        {
                          "name": "percona-mongo-psmdb-d-mongos",
                          "port": 27017
                        }
                      ]
                    }
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "routes": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "match": "string",
                              "services": [
                                "tuple",
                                [
                                  [
                                    "object",
                                    {
                                      "name": "string",
                                      "port": "number"
                                    }
                                  ]
                                ]
                              ]
                            }
                          ]
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "mongodb",
                  "namespace": "datalake",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "entryPoints": [
                    "mongodb"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "middlewares": null,
                      "priority": null,
                      "services": [
                        {
                          "name": "percona-mongo-psmdb-d-mongos",
                          "namespace": null,
                          "nativeLB": null,
                          "port": "27017",
                          "proxyProtocol": {
                            "version": null
                          },
                          "serversTransport": null,
                          "terminationDelay": null,
                          "tls": null,
                          "weight": null
                        }
                      ],
                      "syntax": null
                    }
                  ],
                  "tls": {
                    "certResolver": null,
                    "domains": null,
                    "options": {
                      "name": null,
                      "namespace": null
                    },
                    "passthrough": null,
                    "secretName": null,
                    "store": {
                      "name": null,
                      "namespace": null
                    }
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "list",
                        "string"
                      ],
                      "routes": [
                        "list",
                        [
                          "object",
                          {
                            "match": "string",
                            "middlewares": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string"
                                }
                              ]
                            ],
                            "priority": "number",
                            "services": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string",
                                  "nativeLB": "bool",
                                  "port": "string",
                                  "proxyProtocol": [
                                    "object",
                                    {
                                      "version": "number"
                                    }
                                  ],
                                  "serversTransport": "string",
                                  "terminationDelay": "number",
                                  "tls": "bool",
                                  "weight": "number"
                                }
                              ]
                            ],
                            "syntax": "string"
                          }
                        ]
                      ],
                      "tls": [
                        "object",
                        {
                          "certResolver": "string",
                          "domains": [
                            "list",
                            [
                              "object",
                              {
                                "main": "string",
                                "sans": [
                                  "list",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "options": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ],
                          "passthrough": "bool",
                          "secretName": "string",
                          "store": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "ingressroutetcp_mongo_auth",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "name": "mongodbauth",
                  "namespace": "datalake"
                },
                "spec": {
                  "entryPoints": [
                    "mongodbauth"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "services": [
                        {
                          "name": "percona-mongo-auth-ps-mongos",
                          "port": 27017
                        }
                      ]
                    }
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "routes": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "match": "string",
                              "services": [
                                "tuple",
                                [
                                  [
                                    "object",
                                    {
                                      "name": "string",
                                      "port": "number"
                                    }
                                  ]
                                ]
                              ]
                            }
                          ]
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "mongodbauth",
                  "namespace": "datalake",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "entryPoints": [
                    "mongodbauth"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "middlewares": null,
                      "priority": null,
                      "services": [
                        {
                          "name": "percona-mongo-auth-ps-mongos",
                          "namespace": null,
                          "nativeLB": null,
                          "port": "27017",
                          "proxyProtocol": {
                            "version": null
                          },
                          "serversTransport": null,
                          "terminationDelay": null,
                          "tls": null,
                          "weight": null
                        }
                      ],
                      "syntax": null
                    }
                  ],
                  "tls": {
                    "certResolver": null,
                    "domains": null,
                    "options": {
                      "name": null,
                      "namespace": null
                    },
                    "passthrough": null,
                    "secretName": null,
                    "store": {
                      "name": null,
                      "namespace": null
                    }
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "list",
                        "string"
                      ],
                      "routes": [
                        "list",
                        [
                          "object",
                          {
                            "match": "string",
                            "middlewares": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string"
                                }
                              ]
                            ],
                            "priority": "number",
                            "services": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string",
                                  "nativeLB": "bool",
                                  "port": "string",
                                  "proxyProtocol": [
                                    "object",
                                    {
                                      "version": "number"
                                    }
                                  ],
                                  "serversTransport": "string",
                                  "terminationDelay": "number",
                                  "tls": "bool",
                                  "weight": "number"
                                }
                              ]
                            ],
                            "syntax": "string"
                          }
                        ]
                      ],
                      "tls": [
                        "object",
                        {
                          "certResolver": "string",
                          "domains": [
                            "list",
                            [
                              "object",
                              {
                                "main": "string",
                                "sans": [
                                  "list",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "options": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ],
                          "passthrough": "bool",
                          "secretName": "string",
                          "store": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "ingressroutetcp_redis",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "name": "redis",
                  "namespace": "datalake"
                },
                "spec": {
                  "entryPoints": [
                    "redis"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "services": [
                        {
                          "name": "authv3-redis-master",
                          "port": 6379
                        }
                      ]
                    }
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "routes": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "match": "string",
                              "services": [
                                "tuple",
                                [
                                  [
                                    "object",
                                    {
                                      "name": "string",
                                      "port": "number"
                                    }
                                  ]
                                ]
                              ]
                            }
                          ]
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "redis",
                  "namespace": "datalake",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "entryPoints": [
                    "redis"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "middlewares": null,
                      "priority": null,
                      "services": [
                        {
                          "name": "authv3-redis-master",
                          "namespace": null,
                          "nativeLB": null,
                          "port": "6379",
                          "proxyProtocol": {
                            "version": null
                          },
                          "serversTransport": null,
                          "terminationDelay": null,
                          "tls": null,
                          "weight": null
                        }
                      ],
                      "syntax": null
                    }
                  ],
                  "tls": {
                    "certResolver": null,
                    "domains": null,
                    "options": {
                      "name": null,
                      "namespace": null
                    },
                    "passthrough": null,
                    "secretName": null,
                    "store": {
                      "name": null,
                      "namespace": null
                    }
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "list",
                        "string"
                      ],
                      "routes": [
                        "list",
                        [
                          "object",
                          {
                            "match": "string",
                            "middlewares": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string"
                                }
                              ]
                            ],
                            "priority": "number",
                            "services": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string",
                                  "nativeLB": "bool",
                                  "port": "string",
                                  "proxyProtocol": [
                                    "object",
                                    {
                                      "version": "number"
                                    }
                                  ],
                                  "serversTransport": "string",
                                  "terminationDelay": "number",
                                  "tls": "bool",
                                  "weight": "number"
                                }
                              ]
                            ],
                            "syntax": "string"
                          }
                        ]
                      ],
                      "tls": [
                        "object",
                        {
                          "certResolver": "string",
                          "domains": [
                            "list",
                            [
                              "object",
                              {
                                "main": "string",
                                "sans": [
                                  "list",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "options": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ],
                          "passthrough": "bool",
                          "secretName": "string",
                          "store": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_manifest",
      "name": "ingressroutetcp_telegraf",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "computed_fields": null,
            "field_manager": [],
            "manifest": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "name": "intelegrafflux",
                  "namespace": "datalake"
                },
                "spec": {
                  "entryPoints": [
                    "telegraf"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "services": [
                        {
                          "name": "telegraf-prd",
                          "port": 8125
                        }
                      ]
                    }
                  ]
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "name": "string",
                      "namespace": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "tuple",
                        [
                          "string"
                        ]
                      ],
                      "routes": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "match": "string",
                              "services": [
                                "tuple",
                                [
                                  [
                                    "object",
                                    {
                                      "name": "string",
                                      "port": "number"
                                    }
                                  ]
                                ]
                              ]
                            }
                          ]
                        ]
                      ]
                    }
                  ]
                }
              ]
            },
            "object": {
              "value": {
                "apiVersion": "traefik.io/v1alpha1",
                "kind": "IngressRouteTCP",
                "metadata": {
                  "annotations": null,
                  "creationTimestamp": null,
                  "deletionGracePeriodSeconds": null,
                  "deletionTimestamp": null,
                  "finalizers": null,
                  "generateName": null,
                  "generation": null,
                  "labels": null,
                  "managedFields": null,
                  "name": "intelegrafflux",
                  "namespace": "datalake",
                  "ownerReferences": null,
                  "resourceVersion": null,
                  "selfLink": null,
                  "uid": null
                },
                "spec": {
                  "entryPoints": [
                    "telegraf"
                  ],
                  "routes": [
                    {
                      "match": "HostSNI(`*`)",
                      "middlewares": null,
                      "priority": null,
                      "services": [
                        {
                          "name": "telegraf-prd",
                          "namespace": null,
                          "nativeLB": null,
                          "port": "8125",
                          "proxyProtocol": {
                            "version": null
                          },
                          "serversTransport": null,
                          "terminationDelay": null,
                          "tls": null,
                          "weight": null
                        }
                      ],
                      "syntax": null
                    }
                  ],
                  "tls": {
                    "certResolver": null,
                    "domains": null,
                    "options": {
                      "name": null,
                      "namespace": null
                    },
                    "passthrough": null,
                    "secretName": null,
                    "store": {
                      "name": null,
                      "namespace": null
                    }
                  }
                }
              },
              "type": [
                "object",
                {
                  "apiVersion": "string",
                  "kind": "string",
                  "metadata": [
                    "object",
                    {
                      "annotations": [
                        "map",
                        "string"
                      ],
                      "creationTimestamp": "string",
                      "deletionGracePeriodSeconds": "number",
                      "deletionTimestamp": "string",
                      "finalizers": [
                        "list",
                        "string"
                      ],
                      "generateName": "string",
                      "generation": "number",
                      "labels": [
                        "map",
                        "string"
                      ],
                      "managedFields": [
                        "tuple",
                        [
                          [
                            "object",
                            {
                              "apiVersion": "string",
                              "fieldsType": "string",
                              "fieldsV1": "dynamic",
                              "manager": "string",
                              "operation": "string",
                              "subresource": "string",
                              "time": "string"
                            }
                          ]
                        ]
                      ],
                      "name": "string",
                      "namespace": "string",
                      "ownerReferences": [
                        "list",
                        [
                          "object",
                          {
                            "apiVersion": "string",
                            "blockOwnerDeletion": "bool",
                            "controller": "bool",
                            "kind": "string",
                            "name": "string",
                            "uid": "string"
                          }
                        ]
                      ],
                      "resourceVersion": "string",
                      "selfLink": "string",
                      "uid": "string"
                    }
                  ],
                  "spec": [
                    "object",
                    {
                      "entryPoints": [
                        "list",
                        "string"
                      ],
                      "routes": [
                        "list",
                        [
                          "object",
                          {
                            "match": "string",
                            "middlewares": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string"
                                }
                              ]
                            ],
                            "priority": "number",
                            "services": [
                              "list",
                              [
                                "object",
                                {
                                  "name": "string",
                                  "namespace": "string",
                                  "nativeLB": "bool",
                                  "port": "string",
                                  "proxyProtocol": [
                                    "object",
                                    {
                                      "version": "number"
                                    }
                                  ],
                                  "serversTransport": "string",
                                  "terminationDelay": "number",
                                  "tls": "bool",
                                  "weight": "number"
                                }
                              ]
                            ],
                            "syntax": "string"
                          }
                        ]
                      ],
                      "tls": [
                        "object",
                        {
                          "certResolver": "string",
                          "domains": [
                            "list",
                            [
                              "object",
                              {
                                "main": "string",
                                "sans": [
                                  "list",
                                  "string"
                                ]
                              }
                            ]
                          ],
                          "options": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ],
                          "passthrough": "bool",
                          "secretName": "string",
                          "store": [
                            "object",
                            {
                              "name": "string",
                              "namespace": "string"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "timeouts": [],
            "wait": [],
            "wait_for": null
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "datalake_ns-namespace",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "datalake",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "datalake",
                "resource_version": "8730",
                "uid": "40f24ecb-1220-4e71-9047-c22e058dc96c"
              }
            ],
            "timeouts": null,
            "wait_for_default_service_account": false
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "letsencrypt-namespace",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "cert-manager",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "cert-manager",
                "resource_version": "8731",
                "uid": "0d0cba18-1759-4246-b471-f17ecaf92de7"
              }
            ],
            "timeouts": null,
            "wait_for_default_service_account": false
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "metalb-namespace",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "metalb",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "metalb",
                "resource_version": "8728",
                "uid": "fd0da82e-6ae7-4bc3-b4e3-5f004b062c67"
              }
            ],
            "timeouts": null,
            "wait_for_default_service_account": false
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "openebs-namespace",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "openebs",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "openebs",
                "resource_version": "27130",
                "uid": "2369109f-2cb9-403c-b7fb-35794272c58b"
              }
            ],
            "timeouts": null,
            "wait_for_default_service_account": false
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "prometheus-namespace",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "monitoring",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "monitoring",
                "resource_version": "8732",
                "uid": "b62bcbbf-f804-48ec-9c0a-d96ebf2a8fb9"
              }
            ],
            "timeouts": null,
            "wait_for_default_service_account": false
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "traefik-namespace",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "ingress-traefik",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "ingress-traefik",
                "resource_version": "8729",
                "uid": "50318b66-127b-4ee4-bbac-ef45e825a447"
              }
            ],
            "timeouts": null,
            "wait_for_default_service_account": false
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_secret_v1",
      "name": "airflow",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "httpSecretPasswordKey": "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",
              "httpSecretUsernameKey": "JACKT72xp"
            },
            "id": "datalake/airflow-git-https-secret",
            "immutable": false,
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "airflow-git-https-secret",
                "namespace": "datalake",
                "resource_version": "197949",
                "uid": "de06b877-8646-4147-9c75-498c3d50bf2e"
              }
            ],
            "timeouts": null,
            "type": "Opaque",
            "wait_for_service_account_token": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMH19"
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_secret_v1",
      "name": "airflow_production",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "GITSYNC_PASSWORD": "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",
              "GITSYNC_USERNAME": "JACKT72xp",
              "GIT_SYNC_PASSWORD": "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",
              "GIT_SYNC_USERNAME": "JACKT72xp"
            },
            "id": "datalake/git-credentials",
            "immutable": false,
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "git-credentials",
                "namespace": "datalake",
                "resource_version": "2084659",
                "uid": "e0a297d1-5ac1-4ab0-9361-080115e86a1c"
              }
            ],
            "timeouts": null,
            "type": "Opaque",
            "wait_for_service_account_token": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMH19"
        }
      ]
    }
  ],
  "check_results": null
}
